{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6K-Ijmo7VceT"
   },
   "source": [
    "# üëΩüëæ `print(fiction)` üìöüõ∏\n",
    "\n",
    "> #### A data science project by _Tobias Reaper_\n",
    "\n",
    "#### üìì Notebook 3: Modeling üß†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_K7zk62hIT4-"
   },
   "source": [
    "---\n",
    "\n",
    "### Notebook Outline\n",
    "\n",
    "[explanation of this notebook in context of project]\n",
    "\n",
    "* Intro\n",
    "* Imports and Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "`print(fiction)` is a solo project I worked on to explore the data on and around stories‚Äîspecifically, the stories contained in print books.\n",
    "\n",
    "I used Scrapy to scrape metadata for over 20,000 books from GoodReads and used it to train a gradient-boosted random forest classifier. The final version of the model classified books as either fiction or nonfiction with 88% accuracy.\n",
    "\n",
    "The dataset is freely available for download from GitHub or Kaggle (link to come).\n",
    "I built an interactive dashboard using Plotly Dash that can be used to tinker with the model parameters and view the resulting prediction in real time.\n",
    "\n",
    "You can find the current live version of the app here: [print(fiction)](http://print-fiction.herokuapp.com/)\n",
    "\n",
    "The notebooks detailing the entire process of data gathering, wrangling, modeling, and deployment, can be found here: [print(fiction) notebooks](https://github.com/tobias-fyi/print-fiction/tree/master/notebooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NCMU9Y5DVvT5"
   },
   "source": [
    "---\n",
    "\n",
    "### Imports and Configuration\n",
    "\n",
    "‚öôÔ∏èüì• "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "cOS1Wyo0VZQM",
    "outputId": "c8cf3f18-b0e1-4cf3-e6eb-8fda07f48def"
   },
   "outputs": [],
   "source": [
    "# === General Imports === #\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import randint, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sgtmOkO6IT5Q"
   },
   "outputs": [],
   "source": [
    "# === Configure === #\n",
    "%matplotlib inline\n",
    "pd.options.display.max_rows = 200\n",
    "pd.options.display.max_columns = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gGwq5WRwI6ty"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install category-encoders\n",
    "# !pip install eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "f01v7xNdIT5W",
    "outputId": "c8c09332-0f42-488e-ca0f-0f601510be12"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tobias/.vega/vela-_qIiF1eP/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Tobias/.vega/vela-_qIiF1eP/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# === ML Imports === #\n",
    "\n",
    "# Preprocessing\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "\n",
    "# Model validation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Interpretations\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yInEDKOEIT5c"
   },
   "source": [
    "---\n",
    "\n",
    "## üìà Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "colab_type": "code",
    "id": "ndvQA9x5WtnB",
    "outputId": "c3f6ca83-af13-4502-dcb7-cf71cdcfffa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18344, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>language</th>\n",
       "      <th>series</th>\n",
       "      <th>1_rating_count</th>\n",
       "      <th>2_rating_count</th>\n",
       "      <th>3_rating_count</th>\n",
       "      <th>4_rating_count</th>\n",
       "      <th>5_rating_count</th>\n",
       "      <th>publish_year</th>\n",
       "      <th>publish_month</th>\n",
       "      <th>publish_day</th>\n",
       "      <th>fiction</th>\n",
       "      <th>republish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Book of Mormon: Another Testament of Jesus...</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>71355.0</td>\n",
       "      <td>5704.0</td>\n",
       "      <td>4.37</td>\n",
       "      <td>531.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>7520.0</td>\n",
       "      <td>2697.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>56654.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Prince</td>\n",
       "      <td>Niccol√≤ Machiavelli</td>\n",
       "      <td>229715.0</td>\n",
       "      <td>7261.0</td>\n",
       "      <td>3.81</td>\n",
       "      <td>140.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>5254.0</td>\n",
       "      <td>16827.0</td>\n",
       "      <td>61182.0</td>\n",
       "      <td>80221.0</td>\n",
       "      <td>66231.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Foundation Trilogy</td>\n",
       "      <td>Isaac Asimov</td>\n",
       "      <td>83933.0</td>\n",
       "      <td>1331.0</td>\n",
       "      <td>4.40</td>\n",
       "      <td>679.0</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "      <td>477.0</td>\n",
       "      <td>1521.0</td>\n",
       "      <td>9016.0</td>\n",
       "      <td>25447.0</td>\n",
       "      <td>47472.0</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title               author  \\\n",
       "0  The Book of Mormon: Another Testament of Jesus...            Anonymous   \n",
       "1                                         The Prince  Niccol√≤ Machiavelli   \n",
       "2                             The Foundation Trilogy         Isaac Asimov   \n",
       "\n",
       "   num_ratings  num_reviews  avg_rating  num_pages language  series  \\\n",
       "0      71355.0       5704.0        4.37      531.0  English       0   \n",
       "1     229715.0       7261.0        3.81      140.0  English       0   \n",
       "2      83933.0       1331.0        4.40      679.0  English       1   \n",
       "\n",
       "   1_rating_count  2_rating_count  3_rating_count  4_rating_count  \\\n",
       "0          7520.0          2697.0          2521.0          1963.0   \n",
       "1          5254.0         16827.0         61182.0         80221.0   \n",
       "2           477.0          1521.0          9016.0         25447.0   \n",
       "\n",
       "   5_rating_count  publish_year  publish_month  publish_day  fiction  \\\n",
       "0         56654.0        2013.0           10.0         22.0        0   \n",
       "1         66231.0        2003.0            6.0          1.0        0   \n",
       "2         47472.0        1974.0            1.0          1.0        1   \n",
       "\n",
       "   republish  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Load the dataset === #\n",
    "# This version was exported from the previous notebook\n",
    "# after doing some initial wrangling\n",
    "data_path = \"https://raw.githubusercontent.com/tobias-fyi/vela/master/ds/interview_prep/practice/print-fiction/assets/must_read_books-02.csv\"\n",
    "\n",
    "books = pd.read_csv(data_path, na_values=\"?\")\n",
    "print(books.shape)\n",
    "books.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "colab_type": "code",
    "id": "ynTpCxezIT5l",
    "outputId": "ed5090be-ec2a-438e-9d3f-d9b524086f12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                0\n",
       "author               0\n",
       "num_ratings          0\n",
       "num_reviews          0\n",
       "avg_rating           0\n",
       "num_pages          666\n",
       "language          1332\n",
       "series               0\n",
       "1_rating_count      83\n",
       "2_rating_count      83\n",
       "3_rating_count      83\n",
       "4_rating_count      83\n",
       "5_rating_count      83\n",
       "publish_year       282\n",
       "publish_month      282\n",
       "publish_day        282\n",
       "fiction              0\n",
       "republish            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Confirm null values were read in correctly === #\n",
    "books.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6YxTVzcUIT5s"
   },
   "source": [
    "---\n",
    "\n",
    "## Model validation\n",
    "\n",
    "* Split data into train, validation, and test sets\n",
    "* Choose an appropriate evaluation metric\n",
    "* Get a baseline accuracy (or precision/recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "KLQb9YurIT5u",
    "outputId": "bb38642f-6279-4971-ac5a-91a71502e44c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11740, 18), (2935, 18), (3669, 18))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Split data into train / val / test === #\n",
    "train, test = train_test_split(books, stratify=books[\"fiction\"], test_size=0.2, random_state=92)\n",
    "train, val = train_test_split(train, stratify=train[\"fiction\"], test_size=0.2, random_state=92)\n",
    "\n",
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "d80Z_YY-IT5y",
    "outputId": "f85f4b48-0679-49d9-8328-6ba49afe867f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11740,) (2935,) (3669,)\n",
      "(11740, 17) (2935, 17) (3669, 17)\n"
     ]
    }
   ],
   "source": [
    "# === Set up target and features === #\n",
    "target = \"fiction\"\n",
    "\n",
    "# Arrange y vector\n",
    "y_train = train[target]\n",
    "y_val = val[target]\n",
    "y_test = test[target]\n",
    "\n",
    "print(y_train.shape, y_val.shape, y_test.shape)\n",
    "\n",
    "# Arrange X matrices\n",
    "X_train = train.drop(columns=[target])\n",
    "X_val = val.drop(columns=[target])\n",
    "X_test = test.drop(columns=[target])\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "id": "ax4SYWEYIT52",
    "outputId": "d9e44b93-dc36-416e-c5b2-b63cd769c1e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    6145\n",
      "0    5595\n",
      "Name: fiction, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEGCAYAAABM7t/CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dd3hcd53v8fdXzZJsWcWWLFvFcnccN9mK7YQ0p3fSIAkJm0CCCeSyYdldFnafuw8XLgsb2NxdWAJkQxIS0sBJNsYhnQSnuci9F7nIkixLtmQ1W/13/5hREF7ZGslTzow+r+fRk5HmaOaTkfTxmd/5nd8x5xwiIuJdcZEOICIip6eiFhHxOBW1iIjHqahFRDxORS0i4nEJoXjQ0aNHu6KiolA8tIhITFq7du0R51x2X/eFpKiLioooLS0NxUOLiMQkMztwqvs09CEi4nEqahERj1NRi4h4nIpaRMTjVNQiIh6nohYR8TgVtYiIx6moRUQ8TkUtIuJxITkzUUSGjmdXlZ/xY3xuYWEQksQu7VGLiHicilpExONU1CIiHqeiFhHxOBW1iIjHBVTUZpZhZkvNbIeZbTezc0MdTEREfAKdnvcfwOvOuVvNLAlIDWEmERHppd+iNrN04ELgHgDnXDvQHtpYIiLSI5ChjwlALfCEma03s8fMbPjJG5nZEjMrNbPS2traoAcVERmqAinqBGAe8HPnXDHQAnzr5I2cc48650qccyXZ2X1en1FERAYhkKKuACqcc6v8ny/FV9wiIhIG/Ra1c64aOGhm0/xfuhTYFtJUIiLyiUBnfXwNeMY/42Mv8IXQRRIRkd4CKmrn3AagJMRZRESkDzozUUTE41TUIiIep6IWEfE4XeElRHTVCxEJFu1Ri4h4nIpaRMTjVNQiIh6nohYR8TgVtYiIx6moRUQ8TkUtIuJxKmoREY9TUYuIeJyKWkTE41TUIiIep6IWEfE4FbWIiMepqEVEPE5FLSLicSpqERGPU1GLiHicilpExONU1CIiHqeiFhHxuIAubmtm+4EmoAvodM6VhDKUiIj82UCuQr7YOXckZElERKRPGvoQEfG4QIvaAW+a2VozW9LXBma2xMxKzay0trY2eAlFRIa4QIv6fOfcPOBq4AEzu/DkDZxzjzrnSpxzJdnZ2UENKSIylAVU1M65Sv9/a4CXgQWhDCUiIn/Wb1Gb2XAzS+u5DVwBbAl1MBER8Qlk1scY4GUz69n+Wefc6yFNJSIin+i3qJ1ze4E5YcgiIiJ90PQ8ERGPU1GLiHicilpExONU1CIiHqeiFhHxOBW1iIjHqahFRDxORS0i4nEqahERj1NRi4h4nIpaRMTjVNQiIh6nohYR8TgVtYiIx6moRUQ8TkUtIuJxKmoREY9TUYuIeJyKWkTE41TUIiIep6IWEfE4FbWIiMepqEVEPE5FLSLicQEXtZnFm9l6M1seykAiIvKXBrJH/SCwPVRBRESkbwEVtZnlA9cCj4U2joiInCzQPep/B74JdJ9qAzNbYmalZlZaW1sblHAiIhJAUZvZdUCNc27t6bZzzj3qnCtxzpVkZ2cHLaCIyFAXyB71p4AbzGw/8DxwiZn9JqSpRETkE/0WtXPu2865fOdcEXA78Efn3F0hTyYiIoDmUYuIeF7CQDZ2zr0HvBeSJCIi0iftUYuIeJyKWkTE41TUIiIep6IWEfE4FbWIiMepqEVEPE5FLSLicSpqERGPU1GLiHicilpExONU1CIiHqeiFhHxOBW1iIjHqahFRDxORS0i4nEqahERj1NRi4h4nIpaRMTjVNQiIh6nohYR8TgVtYiIx6moRUQ8TkUtIuJxKmoREY/rt6jNLNnMVpvZRjPbamb/JxzBRETEJyGAbdqAS5xzzWaWCHxgZq8551aGOJuIiBBAUTvnHNDs/zTR/+FCGUpERP4soDFqM4s3sw1ADfCWc25VH9ssMbNSMyutra0Ndk4RkSEroKJ2znU55+YC+cACM5vZxzaPOudKnHMl2dnZwc4pIjJkDWjWh3PuGPAucFVo4oiIyMkCmfWRbWYZ/tspwOXAjlAHExERn0BmfYwFfm1m8fiK/bfOueWhjSUiIj0CmfWxCSgOQxYREemDzkwUEfE4FbWIiMepqEVEPE5FLSLicSpqERGPU1GLiHicilpExONU1CISUd3O0d2tBTlPJ5AzE0VEgq61o4uPyo7w4Z6jPPT6DuYUZLB4Wg73nFdEXJxFOp6nqKhFJOz2HmnmmZXlnOjoYnpuGsWFmaw7UM93l29jc2UDD906m8R4veHvoaIWkbA60tzGMyvLGTEsgS+eP4G8jBQ+t7AQ5xyPvFfGj97YSf3xdn5+53xSkuIjHdcT9E+WiITN8fZOnvp4P2Zw93lF5GWkfHKfmfHA4sn84OZZ/GlXLT98bXvkgnqMilpEwubFtRXUH+/groXjyRqe1Oc2dywo5O5zi3hq5QHWHqgPc0JvUlGLSFjsqWlme3UTl501hqLRw0+77d9dOY2xI5P51oubaO/sDlNC71JRi0jIdTvHa1sOkZGayHmTRvW7/YhhCfzfm2ayu6aZn79XFoaE3qaiDqLj7Z2U7q/jiQ/3sWrfUdo6uyIdScQTNpQf41BDK1fOyA14Nscl08dw9cxcHl1RRsPxjhAn9DbN+giSd3fW8NfPraeptfOTr72xtZqFE0ZxyfQcTTWSIaujq5s3t1WTn5nCrPz0AX3vX186hde2VPPUx/v52qVTQhMwCqg9zpBzjl99sI97n1xDQWYqj/1VCav+8VK+ctEkJueksWJXLc+uKqdLZ17JELXx4DEaWzu5YkYucTawE1nOGjuSxdOyeeKj/ZxoH7rvUFXUZ+ix9/fxveXbuHzGGJZ+5VwumzGGMSOTKchK5XMLCrlh7jh2Hm5i6dqDdDuVtQwtzjk+KjtK7shkJmWf/gDiqXx18WTqWtp5fk15kNNFDxX1Gdha1cBDb+zgqrNz+fmd80lN+p8jSQsnjOKKGWPYWNHAW9sORyClSOTsPdJCdWMr500ahQ1wb7rHOUVZnFOUyX+t2DtkZ4CoqAeptaOLrz+/gczUJH5w86zTrk1w0dRs5o/P5P3dtRxqOBHGlCKR9VHZUVKT4plTkHFGj3P/RZOoamjl7e1Dc2dHRT1ID72+k901zfz4M3PIPMXE/R5mxtUzc0lOjOeVDVUaApEhoa6lnR2HGllQlHXGB9MvnpbDuPRknl9zMEjpoouKehD2HWnh1x/v586FhVw4NTug70lNSuDqmWMprzvOOp1tJUPA6n1HMYOFE/ufN92f+DjjMyUFvL+7lor640FIF11U1IPw72/vIjHeePCygU0XmleYQdGoVF7bUk1rx9A9gi2xr6vbsf7gMaaNSSM9JTEoj/mZknwAfltaEZTHiyb9FrWZFZjZu2a2zcy2mtmD4QjmVTurm1i2sYp7zptATlrygL7XzLh21jhOdHSxau/RECUUibyy2maaWjspLswM2mPmZ6ZywZRsfld6cMhNdw1kj7oT+Fvn3AxgEfCAmc0IbSzv+rc3dzIiKYH7L5o4qO/Py0xhSs4IPthzZMgewZbYt668npTEeKbnpgX1cW8/p4BDDa2s2F0b1Mf1un6L2jl3yDm3zn+7CdgO5IU6mBdtrWrgzW2HufeCCWSknv4A4ulcPC2HlvYu1h6oC2I6EW840d7FtqpG5hSkkxDkM3IvO2sMWcOTWDrEhj8G9CqaWRFQDKzq474lZlZqZqW1tbH5r90TH+4nJTGeL5w34Ywep2hUKuOzUnl/95Eh9xZOYt/mygY6ux3zgjjs0SMpIY7rZo/l7e2HaW7r7P8bYkTARW1mI4AXga875xpPvt8596hzrsQ5V5KdHdhMiGhypLmNZRuquGV+HumpZ3ZwxMy4aFo2x050sLHiWJASinjD+vJ6stOG/cVFAYLphjnjaOvs5s2t1SF5fC8KqKjNLBFfST/jnHsptJG86fnV5bR3dXPPeUVBebxpY9LIThvGSh1UlBhy7Hg7B+qOU1yQMegzEfszrzCTvIwUlm2sCsnje1Egsz4M+BWw3Tn3cOgjeU9HVzdPrzzABVNGMzknOAdHzIyFE7KoqD9B5TGdrSixYUtlAwCz8ga2St5AxMUZN8wdx/u7j3C0uS1kz+MlgexRfwr4PHCJmW3wf1wT4lye8vqWag43tvGFTxUF9XGLCzJJjDdW79NetcSGzZUNjMtIZtSIYSF9nk/PHUdXt+MPmw+F9Hm8IpBZHx8458w5N9s5N9f/8YdwhPOKZ1YdoDArlYun5gT1cVOS4pmdn8HGgw06AUaiXn1LOwfrTzAr78zW9QjE9NyRTBuTxisbhsbwh85M7MeBoy2s3FvHbecUnHbhpcFaOCGL9q5u1h/UQUWJbluqQj/s0dsNc8dReqCeqiEwdKii7sdvSw8SZ3DLvPyQPH5+Zip5GSms2VeH02JNEsU2VzaQl5FyyquLB9s1s8YC8NqW2J/9oaI+ja5ux9K1FVw0NZvc9IGdLj4QJUWZVDe2cqihNWTPIRJK9S3tVNSfCNveNMCE0cOZMXYkr26K/eEPFfVprNhVy+HGNm47pyCkzzMrL534OGN9uVbVk+i02T/bY2YYixrg2tljWVd+LOaHP1TUp/Hb0oOMGp7EJdPHhPR5UpMSmJ6bxoaKBp2pKFEp3MMePYbK8IeK+hTqWtp5e/thbizOIykh9C/TvMJMWto62V3TFPLnEgmmupZ2Ko+Fd9ijx1AZ/lBRn8LyTVV0dLmQHUQ82ZQxI0hNimdduWZ/SHQJx0kupzMUhj9U1Kfw0rpKpuemMWPcyLA8X0JcHHMKMthxqJET7ZpTLdFjc2UD+Zkp/V6SLlR6hj9i+eQXFXUfymqb2XDwGDfPC+9qrvMKMunsdp8cmBHxuvKjxyM27NGjZ/hDRT3E/Pf6SuIMPj03vEU9LiOZnLRhmv0hUeNVfzmGe7bHyWJ9+ENFfZLubsfL6yv51OTRjBkZurnTfTEzigszOVB3fMgsNiPRbfmmKt+wxxlcSCMYro3x4Q8V9UnW7K+jov5E2Ic9eswtyMBAp5SL5+070sLWqkZmR3hvGqAoxoc/VNQneXl9JalJ8Vx5dm5Enj89JZFJOSNYX15Pt+ZUi4ct968HHelhjx6xPPyhou6ltaOLVzcd4uqZY0lNSohYjuKCDOqPd1B6QGPV4l3LNx2iZHzmGV0/NJhiefhDRd3LW9sO09TWyS0RGvbocfa4dJLi43hx7dC6gKdEj92Hm9h5uInrZo+NdJRPFI0eztnjRn5ygDOWqKh7eXFdBePSk1k0cVREcyQlxDEzL51XNx/SnGrxpN9vOoTZn+cwe8U1s8ayPgaHP1TUfjVNrazYVcuNxXkhWXd6oOYVZtDc1smb22J7DQOJPs45Xt1UxcIJWeSEeWZUf2J1+ENF7bdsQxXdjojN9jhZ0ejh5GWksFTDH+IxO6qbKKtt4brZ4yId5X+I1eEPFbXfi+sqmZOfHrSL156pODNumZ/PB3uOcKghtt7GSXRbvqmK+Djj6pmRmRnVn57hj1i6aLSKGthW1cj2Q43cHKYFmAJ1y7w8nPNNGRTxAuccyzcd4rxJo0J+AdvB6hn+eC2G9qpV1MDL6ytIiDOun+Ott3LjRw1nQVEWS9dW6DJd4glbKhs5cPS4p2Z7nCwWhz+GfFF3dnXz3xuqWDw9J+yLngfilvl57K1tYYPOVBQPWL6pioQ4i9gJYYG6drZv+KOi/nikowTFkC/qD/YcobapLeJzp0/lmlljSU6M00FFibieYY8Lpoz2zEkup3K9/0DnKxti44ICQ76oX1pXSXpKIoun50Q6Sp/SkhO56uxcfr+xitYOzamWyFl/0HeAzouzPU5WkJXKgqIsXloXG8OG/Ra1mT1uZjVmtiUcgcKpqbWDN7ZWc/2csQxLiI90nFO6ZX4+ja2dvLO9JtJRZAhbtqGKpIQ4Lj87tNcQDZYbi/Moq22JifXdA9mjfhK4KsQ5ImLZxiraOrvDdrmtwTpv0mjGpiezdO3BSEeRIaq9s5tXNlRyxYwxjExOjHScgFw7ayxJ8XG8tC76Z031W9TOuRVAXRiyhN1zq8uZnpvG3IKMSEc5rfg446biPFbsPkJNY2uk48gQ9Mcdh6k/3sGt8729U9Nbemoil56Vw+83VtHR1R3pOGckaGPUZrbEzErNrLS2tjZYDxsymysa2FLZyOcWFmIW+VPG+3PL/Hy6uh0vaU61RMDStRWMGTmMC6ZkRzrKgNxUnMfRlnbe3+39TjqdoBW1c+5R51yJc64kO9v7P8xnV5eTnBgX9sttDdak7BEsmJDFM6sOaJ1qCavapjbe3VnLTcX5xHtgHZyBuHhaDpmpifyuNLpnTQ3JWR/NbZ0s21DJ9bPHkZ4SHeNtAJ9fNJ6DdSf4U5TvHUh0eWVDJV3dLqqGPXokJcRx6/x83tp2mJqm6B02HJJFvWxDFS3tXdyxsDDSUQbkyrNzGT1iGM+sPBDpKDJEOOf4belBigszmJwzItJxBuX2BYV0druo3qsOZHrec8DHwDQzqzCze0MfK3Scczz18X6m56ZR7PGDiCdLSojj9nMKeGdHDQfrYuOMK/G21fvq2HW4mdvPKYh0lEGblD2CRROzeH5NedQOGwYy6+MO59xY51yicy7fOfercAQLlY/KjrKjuokvnj8hKg4inuyOhYUYvhkrIqH21McHSE9J5IY50XEs51TuWFDIwboTfLDnSKSjDMqQG/r41Qf7GD0iiRs8tgBToPIyUrj0rDE8t7pcV3+RkKpuaOWNrdV8tiSflCTvnhAWiKtm5pKZmhi1OzhDqqjLapv5444a7lw4nuTE6P3FW3LhROqPd/A7nQAjIfTs6nK6nOOuReMjHeWMDUuI5zMlBby57XBULtQ0pIr6yQ/3kxQfF/W/eCXjM5lXmMF/vb+XziifyC/e1N7ZzbOryrl4ajbjRw2PdJyguPu8IgCe+HB/RHMMxpAp6qPNbSxdW8ENc8eRnebNBc8DZWZ8+aJJHKw7wWtbdE1FCb7lm6o40tzGX51bFOkoQZOXkcL1s8fy/OpyGk50RDrOgAyZon70/b20dnZx/0WTIh0lKC4/awwTs4fzyxVlMbE6mHhHd7fjZ+/uYXpuGhdN9f7JawPxpQsn0tLexTOromuK65Ao6qPNbTz10QFumDMuaueCniwuzvjyhRPZUtnIe7t0AowEz+tbqymrbeGBxZOJi7IzEftz9rh0zp88mic/3E9bZ/QcjB8SRd2zN/21S6ZEOkpQ3VScT0FWCj9+Y2fUzg8Vb3HO8dM/7mHi6OFcM8u7l9s6E0sunEhNU1tUXYwj5os6FvemeyQlxPGNy6eytaoxpq4PJ5Hz7s4ath9q5CsXT4q6dT0CdcGU0cwfn8lP3tkdNVNcY76of/LObtpicG+6xw1z8piem8a/vbkz6pdylMjq7nY8/NYu8jJSuLE4uk9wOR0z4x+ums7hxjZ+/fH+SMcJSEwX9Y7qRp5eeYC7Fo2Pub3pHvFxxt9fOY39R4/zwhrNq5bBW7qugi2VjXzzqmkkxsd0NbBgQhaLp2XzyLt7aDju/RkgMfvTcM7xnWVbGZmSyDcunxrpOCF1yfQcFkzI4sdv7uRoc1uk40gUam7r5Edv7KS4MCNqz9odqL+/cjpNbZ088qc9kY7Sr5gt6j9srmbl3jr+7oppnr9i8pkyM75/40xa2jr5/qvbIx1HotAj7+6htqmNf75uRlSugTMYM8aN5ObifB7/YB87q5siHee0YrKo61va+e7yrZw1diR3LIiupUwHa8qYNO6/aBIvra/kwyhdeEYiY09NM499sI+bivMoLsyMdJyw+qdrzyItOZF/eHETXR6eORVzRe2c49svbaaupZ0f3To7Zo9c9+WBxZMpGpXKP768mZa2zkjHkSjQ0dXN37ywgeFJ8Xz7mumRjhN2WcOT+OfrZrDh4DGe/nh/pOOcUswV9dK1Fby+tZq/vWIaM/PSIx0nrJIT4/nhLbM5WHecb7+0WWcsSr9++s5uNlc28IObZ5GTlhzpOBHx6bnjuHhaNg+9sZO9tc2RjtOnmCrqPTVNfGfZVhZOyOJLF0yMdJyIWDRxFN+4fCrLNlbxm1XRuaSjhMfaA3X87L0ybp6Xx1UzY/PklkCYGf9y0yySE+P58tNrafbgu9GYKeqaplbufnwNKUkJPHzb3CE15HGyr148mYunZfO9329jXXl9pOOIBx2sO86Xn15LXkYK37nh7EjHibhxGSn85x3FlNU2882lGz33bjQmivp4eyf3PllKXUs7j99TQl5GSqQjRVRcnPH/PjuXMenD+MITa9hR3RjpSOIhDcc7+MKTa+jocjx+zzmMTI6eCzyH0nmTR/Ptq8/iD5urefitXZGO8xeivqgbWzv44pNr2FrVwH9+rpjZ+dF1HcRQyRyexLP3LSI5MY67HlvNviMtkY4kHtDU2sGXnirlwNEWfvn5+TF7Ithg3XfBBG4rKeCnf9zDw2/t8syedVQXdU1jK7f9ciWl++t5+LNzufSsMZGO5CkFWak8c99Cup3js7/8mPUaBhnSapp8fy/ryn1/L4smjop0JM8xM35w8yxuKyngJ+/s5kceWfAsaot65d6j3PTIRxw42sKv7jknptcmOBOTc9J4folvz/q2R1fy8vroWTFMgmdbVSO3/vxj9h1p4bG7S7h+iJx9OBhxcb6yvmNBIY+8V8YXf72G+pb2yGaK6LMPwon2Lr7/6jbu+K+VJMQbLyw5N+YWNw+2qWPSeOWB8ykuyOBvXtjIg8+v54hONR8Surodj7y3h0//7ANOdHTx7JcWcvG0nEjH8ry4OONfbprJ926cyUd7jnLtT97nrW2HIzYUkhCRZx2EE/6rMvziT2UcaW7nrkWF/OM1Z5GaFDX/CxGVNTyJ39y3kJ+9u4dH3i3jvZ21PHjpFG5fUKDXMAY553h3Zw0/fmMX2w41cvXMXL5/0yyyhsf2cgrBZGZ8ftF45uZn8OAL6/nSU6WcO3EUf3vFVOaPzwzrqfYWin8hSkpKXGlp6Rk/TlNrB6UH6lm+8RBvbq2mqa2T8yeP5uuXTaGkKCsISUPn2SDMYf7cwtCc/r6nppl/fmULH5UdJTM1kc8vGs+NxXlMzNaBpWjX3NbJHzYd4pnV5Ww8eIzCrFT+7sppXD97bMiKxcu/68HS0dXNc6vL+fe3d1PX0s6UnBHcOj+fC6ZkMz03LShXwjGztc65kj7vC6Sozewq4D+AeOAx59wPT7f9YIq658oSNU2t1DS2sfdIC2W1zTgHacMSuHJmLredU8A5Hi/oHtHwy1u6v45f/KmMt7fXAHD2uJFcNDWbBROyKC7MJD1F07a8rqOrm92Hm1m97ygf7DnCh3uOcqKji4nZw7nv/Il8piQ/5EuWRsPverC0tHWyfFMVz60+yIaDxwDISE1kak4a+ZkpFI5K5euXDW61zjMqajOLB3YBlwMVwBrgDufctlN9z2D3qGd/5w3i4oyctGHkZ6YytyCDuQUZLJiQRXJi/IAfL5Ki6Zf3UMMJXt10iNe2VLPx4DE6/Ue5c0cmMzlnBLnpyWSnDSN7xDByRg4ja3gSqUkJpCTGk5oUT3JiPEkJccTHGfFmxMVBnPXcHronHvXFOYdz4Hp/DjgH3c7R1tlNa0cXrR1dnOjoorWjmxPtvs9rm9o43NhKdWMrhxtbqTzWSllNM+3+C0aMH5XKhVOyuWleHsUFGWF7ax5Nv+vBVHnsBKv2HmX1vjr2Hmmhsv4E8XHGim8uHtTjna6oAxmcXADscc7t9T/Y88CngVMW9WCt/d+Xx/yC5V40Nj2F+y6YyH0XTOR4eyfrDhxjc2UDuw83UVbbTFltM7VNbZ8U+EDFme8CB3FmBKM7jGC8zTzzHL7C7VW8vT73f/oXRRwsmamJjBmZzNj0ZC6cOpoZY0cyrzCTgqzU4D2J9CsvI4Wb5+Vz87z8T74Wqql8gRR1HtD70iEVwMKTNzKzJcAS/6fNZrbzzOOd0mjA62t5nnHGO4MU5DSGxOsYYmHPd2Dg3+L115A7oyAjoc84/lR3BO1wv3PuUeDRYD3e6ZhZ6aneIniFMgaH1zN6PR8oY7BEMmMg4wyVQEGvz/P9XxMRkTAIpKjXAFPMbIKZJQG3A8tCG0tERHr0O/ThnOs0s/8FvIFvet7jzrmtIU92emEZYjlDyhgcXs/o9XygjMESsYwhOeFFRESCR3PhREQ8TkUtIuJxUVHUZpZlZm+Z2W7/f//HNe3NbK6ZfWxmW81sk5ndFoZcV5nZTjPbY2bf6uP+YWb2gv/+VWZWFOpMg8j4DTPb5n/N3jGzU87ljFTGXtvdYmbOzMI+RSqQjGb2Wf9rudXMnvVaRjMrNLN3zWy9/+d9TZjzPW5mNWa25RT3m5n9xJ9/k5nNC2e+ADPe6c+22cw+MrM5YQnmO6XV2x/AQ8C3/Le/BfxrH9tMBab4b48DDgEZIcwUD5QBE4EkYCMw46Rtvgr8wn/7duCFML9ugWRcDKT6b3/Fixn926UBK4CVQInXMgJTgPVApv/zHA9mfBT4iv/2DGB/mDNeCMwDtpzi/muA1wADFgGrwpkvwIzn9foZXx2ujFGxR43vlPVf+2//Grjx5A2cc7ucc7v9t6uAGiCUC1V/cmq9c64d6Dm1vrfeuZcCl1o410YMIKNz7l3n3HH/pyvxzZMPp0BeR4DvAf8KtIYznF8gGb8E/Mw5Vw/gnKvxYEYHjPTfTgeqwpgP59wKoO40m3waeMr5rAQyzCysl0fvL6Nz7qOenzFh/HuJlqIe45w75L9dDZz2mltmtgDfXkVZCDP1dWr9yZeZ+WQb51wn0ACE8/pHgWTs7V58ezTh1G9G/1vgAufcq+EM1ksgr+NUYKqZfWhmK/0rToZTIBm/A9xlZhXAH4CvhSdawAb6+xppYft78cyK8Wb2NpDbx13/1PsT55wzs1POKfT/C/w0cLdzrju4KWOXmd0FlAAXRTpLb2YWBzwM3BPhKP1JwDf8cTG+vawVZjbLOXcsoqn+0h3Ak865fzOzc4GnzWym/k4GzswW4yvq88PxfJ4paufcZae6z8wOm9lY57qXkBIAAANBSURBVNwhfxH3+bbSzEYCrwL/5H/rFEqBnFrfs02FmSXge7t5NMS5+nr+Hn2e/m9ml+H7B/Ei51y4r9HVX8Y0YCbwnn/UKBdYZmY3OOfO/OoUwckIvr2/Vc65DmCfme3CV9xrwhMxoIz3AlcBOOc+NrNkfAsNhXuY5lSiYrkKM5sNPAZc7ZwLy99ztAx9LAPu9t++G3jl5A38p7e/jG+Ma2kYMgVyan3v3LcCf3T+oxBh0m9GMysGfgncEIFx1X4zOucanHOjnXNFzrkifOOC4SzpfjP6/Te+vWnMbDS+oZC9HstYDlzqz3gWkAzUhjFjf5YBf+Wf/bEIaOg15OkJZlYIvAR83jm3K2xPHO6jqoP5wDeu+w6wG3gbyPJ/vQTfFWcA7gI6gA29PuaGONc1+C6qUIZvLx7gu/iKBHx/CL8D9gCrgYkReO36y/g2cLjXa7bMaxlP2vY9wjzrI8DX0fAN0WwDNgO3ezDjDOBDfDNCNgBXhDnfc/hmY3XgewdyL3A/cH+v1/Bn/vybI/Rz7i/jY0B9r7+X0nDk0inkIiIeFy1DHyIiQ5aKWkTE41TUIiIep6IWEfE4FbWIiMepqCUqmdlfm9l2M6vvZ8W9DDP7aq/Px5lZOObZiwSNpudJVDKzHcBlzrmKfrYrApY752aGI5dIKGiPWqKOmf0C33Ker5nZ35jZf/q/PsbMXjazjf6P84AfApPMbIOZ/cjMinrWGjazZDN7wr+28Hr/+g2Y2T1m9pKZvW6+NdAfitT/qwh4aK0PkUA55+73r063GLiu110/Af7knLvJzOKBEfjWL5/pnJsLn+xh93jA93BulplNB940s6n+++YCxUAbsNPMfuqc672ym0jYaI9aYsklwM8BnHNdzrmGfrY/H/iNf/sdwAF8a3QAvON864y04jstPOxXvhHpoaIW6VvvVQS70LtPiSAVtcSSd/BdTgwzizezdKAJ31KpfXkfuNO//VSgENgZhpwiA6KilljyILDYzDYDa/FdM/Ao8KGZbTGzH520/SNAnH/7F4B7XPjX4xbpl6bniYh4nPaoRUQ8TkUtIuJxKmoREY9TUYuIeJyKWkTE41TUIiIep6IWEfG4/w896lCJYq26oAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Target distribution === #\n",
    "print(y_train.value_counts())\n",
    "sns.distplot(y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Y1zfXpFIT5-"
   },
   "source": [
    "#### Majority class baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8-fMHHmbIT6A",
    "outputId": "4cf166ef-706e-43f1-ff68-f4045d554a11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5234241908006815"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Use mode as predictions === #\n",
    "maj = y_train.mode()[0]  # Mode is 1 (fiction)\n",
    "\n",
    "# Simply predict 1 for every training example\n",
    "y_pred_maj = [maj] * len(y_train)\n",
    "\n",
    "# Baseline accuracy\n",
    "accuracy_score(y_train, y_pred_maj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WJyObFatIT6F"
   },
   "source": [
    "#### Limited logistic baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-Jd35T12IT6H",
    "outputId": "f1eafe48-9822-4143-dd6f-4b01a6e11710"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11740, 3), (2935, 3), (3669, 3))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Use only a few features for this baseline === #\n",
    "base_features = [\n",
    "    \"num_reviews\",\n",
    "    \"avg_rating\",\n",
    "    \"num_pages\",\n",
    "]\n",
    "\n",
    "# Arrange X matrices\n",
    "X1_train = train[base_features]\n",
    "X1_val = val[base_features]\n",
    "X1_test = test[base_features]\n",
    "\n",
    "X1_train.shape, X1_val.shape, X1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "colab_type": "code",
    "id": "_MUpLWo5IT6L",
    "outputId": "98e2de7b-7acb-41de-c6da-d9888d0a38ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('imputer', SimpleImputer(strategy='median')),\n",
       "                ('logreg', LogisticRegression(random_state=92))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Baseline model === #\n",
    "pipe1 = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"logreg\", LogisticRegression(random_state=92)),\n",
    "])\n",
    "\n",
    "# Train base pipeline\n",
    "pipe1.fit(X1_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "JvLfVqdMIT6R",
    "outputId": "c7451b47-8043-449d-fba5-15fe998c187b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.6275979557069846\n"
     ]
    }
   ],
   "source": [
    "# === Made predictions to get validation accuracy === #\n",
    "y_pred1 = pipe1.predict(X1_val)\n",
    "\n",
    "# Compute accuracy\n",
    "print(\"Baseline accuracy:\", accuracy_score(y_val, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "oLxd7U0-IT6W",
    "outputId": "fdb1973a-a8b6-4e7b-c0d8-9304cd795baf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 821,  578],\n",
       "       [ 515, 1021]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Baseline confusion matrix === #\n",
    "confusion_matrix(y_val, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TP4_Zqm9IT6a"
   },
   "source": [
    "#### Default Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "QcqQAr_HIT6c",
    "outputId": "03aef88a-260e-43e4-cfb2-408deeb24294"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default random forest eval metrics:\n",
      "  Accuracy: 0.7342419080068143\n",
      "  F1 score: 0.7477360931435963\n"
     ]
    }
   ],
   "source": [
    "# === Default random forest model === #\n",
    "def_drop_columns = [\n",
    "    \"title\",\n",
    "    \"author\",\n",
    "    \"language\",\n",
    "]\n",
    "\n",
    "X2_train = X_train.drop(columns=def_drop_columns)\n",
    "X2_val = X_val.drop(columns=def_drop_columns)\n",
    "X2_test = X_test.drop(columns=def_drop_columns)\n",
    "\n",
    "rf1_pipe = Pipeline([\n",
    "    (\"encoder\", ce.OrdinalEncoder()),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"rfc\", RandomForestClassifier(random_state=92)),\n",
    "])\n",
    "\n",
    "# Train default random forest\n",
    "rf1_pipe.fit(X2_train, y_train)\n",
    "\n",
    "# Made predictions to get validation accuracy\n",
    "y_pred_rf1 = rf1_pipe.predict(X2_val)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(\"Default random forest eval metrics:\")\n",
    "print(\"  Accuracy:\", accuracy_score(y_val, y_pred_rf1))\n",
    "print(\"  F1 score:\", f1_score(y_val, y_pred_rf1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "zC0QPwcNIT6g",
    "outputId": "3380ef13-14bd-421e-ec56-8d4ec5456c05"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Evaluate default rf with confusion matrix === #\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "unique_labels(y_val)  # Create unique labels\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    labels = unique_labels(y_true)\n",
    "    columns = [f'Predicted {label}' for label in labels]\n",
    "    index = [f'Actual {label}' for label in labels]\n",
    "    table = pd.DataFrame(confusion_matrix(y_true, y_pred), \n",
    "                         columns=columns, index=index)\n",
    "    return sns.heatmap(table, annot=True, fmt='d', cmap='viridis')\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(y_val, y_pred_rf1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7uQ4SRFvIT6k"
   },
   "source": [
    "Alrighty then! With the (almost) full set of features and default hyperparameters the target can be predicted with ~73% accuracy. Although the target is not skewed very much, it is still skewed. Therefore, accuracy may not be the best way to evaluate the model. A better metric could be the F1 score. This is a little higher than the accuracy, clocking in at almost 75%.\n",
    "\n",
    "The F1 score is made up of the precision and recall. Actually, it can be interpreted of as the weighted average of precision and recall.\n",
    "\n",
    "This provides a better method of evaluating performance, because it takes into account false positives and false negatives. Accuracy only accounts for the model's correct predictions and mistakes, irrespective of _how_ the model made those mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "BQ-_O3VRIT6l",
    "outputId": "539d49f5-e6f2-45c4-f4c1-dfcd32656437"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7429305912596401\n"
     ]
    }
   ],
   "source": [
    "# === Calculate precision === #\n",
    "true_pos = 1156\n",
    "false_pos = 400\n",
    "precision = true_pos / (true_pos + false_pos)\n",
    "print(f\"Precision: {precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "xxBgEJ04IT6p",
    "outputId": "f284bdb4-2fd3-4cbe-99ba-dac7d0d4e0e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.7526041666666666\n"
     ]
    }
   ],
   "source": [
    "# === Calculate recall === #\n",
    "true_pos = 1156\n",
    "false_neg = 380\n",
    "recall = true_pos / (true_pos + false_neg)\n",
    "print(f\"recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "colab_type": "code",
    "id": "mRMKAvgsIT6t",
    "outputId": "258969da-b797-472d-c0f7-c75e73400397"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.71      0.72      1399\n",
      "           1       0.74      0.75      0.75      1536\n",
      "\n",
      "    accuracy                           0.73      2935\n",
      "   macro avg       0.73      0.73      0.73      2935\n",
      "weighted avg       0.73      0.73      0.73      2935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === Classification report === #\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_val, y_pred_rf1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EAKy3O32IT6w"
   },
   "source": [
    "Let's see what we can do to increase that score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qdxnY7AUIT6x"
   },
   "source": [
    "---\n",
    "\n",
    "## Iterate\n",
    "\n",
    "* [x] Engineer new features\n",
    "* [x] Feature pruning with permutation importance\n",
    "* [x] Use cross-validation (RandomizedSearchCV) to tune hyperparameters\n",
    "* [x] Try out different algorithms\n",
    "  * [x] KNearestClassifier\n",
    "  * [x] XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QHAQC5nIIT6z"
   },
   "source": [
    "### Feature Engineering\n",
    "\n",
    "When I initially started this project, I went through the process of validating and training a model or two that tried to predict the average rating of books. This was by far the most common target chosen by those who started Kaggle kernels using other GoodReads datasets. Although this may have the most obvious business value if I was a data scientist working for a book publisher, to me this wasn't a particularly interesting target to try to predict.\n",
    "\n",
    "I realized this when I hit a wall with my progress in improving the rating-predictor model. One reason was that I did not see any obvious useful features that could be engineered. However, once I found my way to the idea of predicting the fictionality of the books, the target drove the direction I took with my feature engineering. It was a great learning experience for me in engineering features toward the specific target that the model is trying to predict.\n",
    "\n",
    "Here are the feature ideas I came up with and engineered (all in short succession once the new target was chosen):\n",
    "\n",
    "- [x] Title begins with \"The\"\n",
    "- [x] Has subtitle: contains \":\"\n",
    "- [x] Title character count\n",
    "- [x] Title word count\n",
    "- [x] Title longest word\n",
    "- [x] Author number of names\n",
    "- [x] Author middle initial\n",
    "- [x] Ratings (stars) ratio (1 + 2 / 4 + 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7H71nRy8IT6z"
   },
   "outputs": [],
   "source": [
    "def engineer_features(data):\n",
    "    \"\"\"Engineer a handful of new features.\"\"\"\n",
    "    # Create new feature that is if the title begins with \"The\"\n",
    "    data[\"the_title\"] = data[\"title\"].str.startswith(\"The\")\n",
    "    # New feature - has_subtitle\n",
    "    data[\"has_subtitle\"] = data[\"title\"].str.contains(\":\")\n",
    "    # New feature - title character length\n",
    "    data[\"title_char_count\"] = data[\"title\"].apply(lambda x: len(x))\n",
    "    # New feature - title word count\n",
    "    data[\"title_word_count\"] = data[\"title\"].apply(lambda x: len(x.split()))\n",
    "    # New feature - title longest word\n",
    "    data[\"title_longest_word\"] = data[\"title\"].apply(lambda x: len(max(x.split(), key=len)))\n",
    "    # New feature - author number of names\n",
    "    data[\"author_name_count\"] = data[\"author\"].apply(lambda x: len(x.split()))\n",
    "    # New feature - author middle initial\n",
    "    pat = r\"\\w* (\\w. )+ \\w*\"\n",
    "    data[\"author_middle_initial\"] = data[\"author\"].str.contains(pat, regex=True)\n",
    "    # New feature - low/high rating ratio\n",
    "    data[\"rating_ratio\"] = (data[\"1_rating_count\"] + data[\"2_rating_count\"]) / (data[\"4_rating_count\"] + data[\"5_rating_count\"])\n",
    "    # Replace Boolean with binary\n",
    "    data = data.replace(to_replace={True: 1, False:0})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FMbgz_ncIT63"
   },
   "source": [
    "#### Same random forest with additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "7NetaoBmIT63",
    "outputId": "7eedd518-089b-4204-8928-bc5c498d0994"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tobias/.vega/vela-_qIiF1eP/lib/python3.7/site-packages/pandas/core/strings.py:1954: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default random forest eval metrics:\n",
      "  Accuracy: 0.7761499148211244\n",
      "  F1 score: 0.7884057971014492\n"
     ]
    }
   ],
   "source": [
    "# === Random forest model, new features === #\n",
    "X3_train = engineer_features(X_train)\n",
    "X3_val = engineer_features(X_val)\n",
    "X3_test = engineer_features(X_test)\n",
    "\n",
    "rf2_pipe = Pipeline([\n",
    "    (\"encoder\", ce.OrdinalEncoder()),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"rfc\", RandomForestClassifier(random_state=92)),\n",
    "])\n",
    "\n",
    "# Train default random forest\n",
    "rf2_pipe.fit(X3_train, y_train)\n",
    "\n",
    "# Made predictions to get validation accuracy\n",
    "y_pred_rf2 = rf2_pipe.predict(X3_val)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(\"Default random forest eval metrics:\")\n",
    "print(\"  Accuracy:\", accuracy_score(y_val, y_pred_rf2))\n",
    "print(\"  F1 score:\", f1_score(y_val, y_pred_rf2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ugp45Y9fIT67"
   },
   "source": [
    "Got an extra ~3-4% out of those new features!\n",
    "\n",
    "And that is with the default RandomForestClassifier hyperparameters and the SimpleImputer. For the next iteration, I will try using the IterativeImputer, then utilize RandomizedSearchCV to tune the hyperparameters and conduct cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UuMEKWgQ08rS"
   },
   "source": [
    "### Permutation Importances\n",
    "\n",
    "It is likely that some of the features do not help the model make correct predictions. Indeed, some may even be worse than that: they could add noise that makes the model perform worse.\n",
    "\n",
    "To address this potential problem, I'm going to find the feature importances using a method called permutation importance. Basically, this method will go through each of the features, replacing their data with random noise generated from the distribution of the original data. The performance of the model will be evaluated and compared with the score using all of the original data to find the effect of each feature on the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-3jQF7VZ08rX"
   },
   "outputs": [],
   "source": [
    "# === Transformer pipeline === #\n",
    "# Use the same (fitted) steps from main pipeline\n",
    "transformers = Pipeline([\n",
    "    (\"encoder\", rf2_pipe.named_steps[\"encoder\"]),\n",
    "    (\"imputer\", rf2_pipe.named_steps[\"imputer\"]),\n",
    "])\n",
    "\n",
    "# Encode and impute\n",
    "X3_train_transformed = transformers.transform(X3_train)\n",
    "X3_val_transformed = transformers.transform(X3_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "colab_type": "code",
    "id": "ajoeqOPJ1U4L",
    "outputId": "28c524ee-ef0b-4e37-9045-cf64ab48d8b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PermutationImportance(estimator=RandomForestClassifier(random_state=92),\n",
       "                      random_state=42, scoring='f1')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Instantiate and fit the permuter === #\n",
    "permuter = PermutationImportance(\n",
    "    rf2_pipe.named_steps[\"rfc\"], \n",
    "    scoring='f1', \n",
    "    n_iter=5, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "permuter.fit(X3_val_transformed, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "colab_type": "code",
    "id": "sTccpQkRYaLW",
    "outputId": "d0f5587c-bb3c-4ae0-8b83-2f16242f3b29"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0307\n",
       "                \n",
       "                    &plusmn; 0.0021\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                has_subtitle\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 82.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0264\n",
       "                \n",
       "                    &plusmn; 0.0116\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                avg_rating\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.30%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0197\n",
       "                \n",
       "                    &plusmn; 0.0066\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                4_rating_count\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.52%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0193\n",
       "                \n",
       "                    &plusmn; 0.0031\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                publish_year\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 87.70%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0153\n",
       "                \n",
       "                    &plusmn; 0.0059\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                num_ratings\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.39%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0124\n",
       "                \n",
       "                    &plusmn; 0.0039\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                series\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.89%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0116\n",
       "                \n",
       "                    &plusmn; 0.0071\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                1_rating_count\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.10%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0096\n",
       "                \n",
       "                    &plusmn; 0.0048\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                num_pages\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.31%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0078\n",
       "                \n",
       "                    &plusmn; 0.0099\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                num_reviews\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.70%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0073\n",
       "                \n",
       "                    &plusmn; 0.0091\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                3_rating_count\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.43%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0062\n",
       "                \n",
       "                    &plusmn; 0.0075\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                title_char_count\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.60%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0060\n",
       "                \n",
       "                    &plusmn; 0.0043\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                5_rating_count\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0031\n",
       "                \n",
       "                    &plusmn; 0.0048\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                rating_ratio\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.44%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0016\n",
       "                \n",
       "                    &plusmn; 0.0024\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                language\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.48%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0008\n",
       "                \n",
       "                    &plusmn; 0.0059\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                the_title\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.59%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0007\n",
       "                \n",
       "                    &plusmn; 0.0056\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                2_rating_count\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.82%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0005\n",
       "                \n",
       "                    &plusmn; 0.0024\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                title_longest_word\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.03%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0004\n",
       "                \n",
       "                    &plusmn; 0.0025\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                republish\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.14%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0003\n",
       "                \n",
       "                    &plusmn; 0.0020\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                author_name_count\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.77%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0001\n",
       "                \n",
       "                    &plusmn; 0.0002\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                author_middle_initial\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 99.45%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0002\n",
       "                \n",
       "                    &plusmn; 0.0040\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                publish_month\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 98.76%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0006\n",
       "                \n",
       "                    &plusmn; 0.0041\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                author\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 98.52%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0007\n",
       "                \n",
       "                    &plusmn; 0.0030\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                title_word_count\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 98.47%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0008\n",
       "                \n",
       "                    &plusmn; 0.0009\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                title\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 96.31%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0027\n",
       "                \n",
       "                    &plusmn; 0.0030\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                publish_day\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Get permutation importances === #\n",
    "feature_names = X3_val.columns.tolist()\n",
    "pd.Series(permuter.feature_importances_, feature_names).sort_values(ascending=False)\n",
    "\n",
    "eli5.show_weights(\n",
    "    permuter, \n",
    "    top=None, # Show permutation importances for all features\n",
    "    feature_names=feature_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above table, I should see either no change or a small increase in the model's performance by removing `publish_month`, `author`, `title_word_count`, `title`, and `publish_day`. I'm going to try removing those and training the model again.\n",
    "\n",
    "As for the rest of the features, I find it interesting to see what features have the largest positive effect on the model's predictive power. From this table, I can see that the majority of the benefit I got from engineering the new features came from the `has_subtitle` feature. This feature, according to the permutation importance table, is the most important predictor by quite a long shot and accounted for 0.04 simply indicates whether the title of the book has a colon in it. My intuition was that having a subtitle is very common for nonfiction books, not so much for fiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Prune the features === #\n",
    "more_drop_cols = [\n",
    "    \"publish_month\",\n",
    "    \"author\",\n",
    "    \"title_word_count\",\n",
    "    \"title\",\n",
    "    \"publish_day\",\n",
    "]\n",
    "\n",
    "# New features are already engineered\n",
    "X4_train = X3_train.drop(columns=more_drop_cols)\n",
    "X4_val   = X3_val.drop(columns=more_drop_cols)\n",
    "X4_test  = X3_test.drop(columns=more_drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default random forest:\n",
      "  Accuracy: 0.7867120954003407\n",
      "  F1 score: 0.7991014120667522\n"
     ]
    }
   ],
   "source": [
    "# === Random forest model with pruned features === #\n",
    "rf3_pipe = Pipeline([\n",
    "    (\"encoder\", ce.OrdinalEncoder()),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"rfc\", RandomForestClassifier(random_state=92)),\n",
    "])\n",
    "\n",
    "# Train default random forest\n",
    "rf3_pipe.fit(X4_train, y_train)\n",
    "\n",
    "# Made predictions to get validation accuracy\n",
    "y_pred_rf3 = rf3_pipe.predict(X4_val)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(\"Default random forest:\")\n",
    "print(\"  Accuracy:\", accuracy_score(y_val, y_pred_rf3))\n",
    "print(\"  F1 score:\", f1_score(y_val, y_pred_rf3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that removing the features indicated did have a positive effect of about 0.01 on the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default logistic model:\n",
      "  Accuracy: 0.7315161839863714\n",
      "  F1 score: 0.7612121212121213\n"
     ]
    }
   ],
   "source": [
    "# === Logistic regression, pruned features === #\n",
    "lg_pipe = Pipeline([\n",
    "    (\"encoder\", ce.OrdinalEncoder()),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"lg\", LogisticRegression(random_state=92)),\n",
    "])\n",
    "\n",
    "# Train default logistic model\n",
    "lg_pipe.fit(X4_train, y_train)\n",
    "\n",
    "# Made predictions to get validation accuracy\n",
    "y_pred_lg = lg_pipe.predict(X4_val)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(\"Default logistic model:\")\n",
    "print(\"  Accuracy:\", accuracy_score(y_val, y_pred_lg))\n",
    "print(\"  F1 score:\", f1_score(y_val, y_pred_lg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the performance of the logistic model, it does seem that random forest is a good model for the problem at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jDCfJc9CIT68"
   },
   "source": [
    "### Cross-validation + Hyperparameter tuning\n",
    "\n",
    "Though I don't have a record of every single iteration of the hyperparameter searches, the method I used to tune is to basically look at the values of each parameter, and moved the search range to more closely fit around those values.\n",
    "\n",
    "The resulting performances from the models that I ran through the hyperparameter tuning and cross-validation process were actually on par with the default random forest model that did not use cross-validation.\n",
    "\n",
    "It could be that the best estimator from the search would outperform the previous one when predicting the test data. Or, it could be that the parameters and their ranges I'm searching are not optimal. Or, I simply did not provide enough of a search window to find the best combination of parameters. That is, I could try increasing the number of iterations in the randomized search to hopefully increase the chances of finding the optimal combination.\n",
    "\n",
    "Ultimately, I decided to try out some other algorithms to see if they might be a better fit for this problem and dataset: logistic regression (with full featureset), k-nearest neighbors, and gradient-boosted decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression\n",
    "\n",
    "With the full featureset (after pruning), a basic logistic model was able to get an F1 score of about .76."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QXBIGtq8IT7Y"
   },
   "source": [
    "#### Nearest Neighbors\n",
    "\n",
    "The third type of model I trained was a nearest neighbors model using Scikit-Learn's KNeighborsClassifier algorithm.\n",
    "\n",
    "The trained KNeighborsClassifier model was the worst-performing of the lot, clocking in with an F1 score of just under .70.\n",
    "\n",
    "It seems that Random Forest is quite a bit better of an algorithm for this problem than k-nearest neighbors, or even logistic regression. Therefore, I didn't move forward with nearest neighbors. I mostly wanted to just try it out anyways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5_kdsJbZKSND"
   },
   "source": [
    "#### Gradient Boosting\n",
    "\n",
    "The fourth and final type of model I trained was a gradient-boosted decision tree using [XGBoost](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn).\n",
    "\n",
    "I was surprised to find that my attempts at training the `XGBClassifier` had about the same performance as the default random forest with the newly-engineered features.\n",
    "\n",
    "As I mentioned above, one hypothesis of what was causing the discrepancy (or lack thereof: I assumed gradient-boosting would increase the performance, which maybe wasn't a sound assumption), could be the simple fact that the randomized search doesn't cover every possibility. To test this, I increased the number of iterations and let 'er rip!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FecTx0zMVKGG"
   },
   "source": [
    "#### More Random Forests\n",
    "\n",
    "Even with 40 total fits (4 cross-validation folds, 10 iterations) the gradient-boosted classifier did not really outperform the random forest by any significant margin. Given the additional complexity and computation required for an XGBoost model, I'm going to use the random forest classifier instead.\n",
    "\n",
    "To continue testing the hypothesis that my initial number of iterations was too low for the search to converge on a good combination of hyperparameters, I'm going to train more random forests. This time, I'm going to try running the random search with a higher number of iterations. If that seems promising, I'm going to further tune the hyperparameters and look into any additional hyperparameters that might be good to include in the tuning process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to val\n",
    "\n",
    "Somewhat to my surprise, the best performance of the models achieved through hyperparameter tuning and cross-validation was on par with the default random forest model that did not use cross-validation. That held true even when using a gradient-boosted algorithm.\n",
    "\n",
    "Therefore, to simplify things, the final model I used was the default random forest with a manual validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest 4 eval metrics:\n",
      "  Accuracy: 0.7664213682202234\n",
      "  F1 score: 0.7791806235506312\n"
     ]
    }
   ],
   "source": [
    "# === But how does it perform on the test data? === #\n",
    "y_pred_test_rf3 = rf3_pipe.predict(X4_test)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(\"Random forest 4 eval metrics:\")\n",
    "print(\"  Accuracy:\", accuracy_score(y_test, y_pred_test_rf3))\n",
    "print(\"  F1 score:\", f1_score(y_test, y_pred_test_rf3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Get feature importances === #\n",
    "rf3 = rf3_pipe.named_steps[\"rfc\"]\n",
    "importances = pd.Series(rf3.feature_importances_, X4_train.columns)\n",
    "\n",
    "# Plot feature importances\n",
    "n = 20\n",
    "plt.figure(figsize=(10,n/2))\n",
    "plt.title(f'Top {n} features')\n",
    "importances.sort_values()[-n:].plot.barh(color='grey');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RwBBzF7x1In2"
   },
   "source": [
    "---\n",
    "\n",
    "## Results and Interpretation\n",
    "\n",
    "I tried many different combinations of different hyperparameters and the best F1 score I was able to achieve was just north of .79. Even with all of my tuning, I never beat the F1 score that was achieved with the random forest classifier using default hyperparameters.\n",
    "\n",
    "One final step to be taken before deployment is to inspect the predictions that the model made on the test set, looking at the predicted probabilities that resulted in each of the predictions. By looking at the predicted probabilities, I can look at instances when the model was sure or unsure of its predictions, and if those predictions were correct or not.\n",
    "\n",
    "This can provide some insight into the reasons for the model being incorrect, which could be valuable information to have, particularly when attempting to interpret (the results of) the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indexes as an id field to match up on later\n",
    "train_id = X4_train.reset_index()[\"index\"]\n",
    "test_id = X4_test.reset_index()[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1042\n",
       "1    10779\n",
       "2    10072\n",
       "3    15540\n",
       "4    13007\n",
       "Name: index, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC for class 1:\n",
      "0.8508187240388956\n"
     ]
    }
   ],
   "source": [
    "# === ROC AUC + predicted probabilities === #\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Process the test data\n",
    "transformers_2 = Pipeline([\n",
    "    (\"encoder\", rf3_pipe.named_steps[\"encoder\"]),\n",
    "    (\"imputer\", rf3_pipe.named_steps[\"imputer\"]),\n",
    "])\n",
    "\n",
    "# Encode and impute\n",
    "X4_test_transform = transformers_2.transform(X4_test)\n",
    "class_index = 1\n",
    "\n",
    "# Make predictions with the trained random forest\n",
    "y_pred_proba_rf3 = rf3.predict_proba(X4_test_transform)[:, class_index]\n",
    "\n",
    "# ROC AUC score ranges from 0-1; higher is better\n",
    "print(f'Test ROC AUC for class {class_index}:')\n",
    "print(roc_auc_score(y_test, y_pred_proba_rf3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>language</th>\n",
       "      <th>series</th>\n",
       "      <th>1_rating_count</th>\n",
       "      <th>2_rating_count</th>\n",
       "      <th>3_rating_count</th>\n",
       "      <th>4_rating_count</th>\n",
       "      <th>5_rating_count</th>\n",
       "      <th>publish_year</th>\n",
       "      <th>republish</th>\n",
       "      <th>the_title</th>\n",
       "      <th>has_subtitle</th>\n",
       "      <th>title_char_count</th>\n",
       "      <th>title_longest_word</th>\n",
       "      <th>author_name_count</th>\n",
       "      <th>author_middle_initial</th>\n",
       "      <th>rating_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1042</td>\n",
       "      <td>112871.0</td>\n",
       "      <td>4674.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>317.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>1593.0</td>\n",
       "      <td>5439.0</td>\n",
       "      <td>24255.0</td>\n",
       "      <td>41993.0</td>\n",
       "      <td>39591.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10779</td>\n",
       "      <td>364.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3.97</td>\n",
       "      <td>431.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.106061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10072</td>\n",
       "      <td>49.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.18</td>\n",
       "      <td>294.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15540</td>\n",
       "      <td>150.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.87</td>\n",
       "      <td>200.0</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13007</td>\n",
       "      <td>19322.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>4.09</td>\n",
       "      <td>268.0</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "      <td>285.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>3758.0</td>\n",
       "      <td>5984.0</td>\n",
       "      <td>8309.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.088925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  num_ratings  num_reviews  avg_rating  num_pages language  series  \\\n",
       "0   1042     112871.0       4674.0        4.00      317.0  English       0   \n",
       "1  10779        364.0         47.0        3.97      431.0  English       0   \n",
       "2  10072         49.0         12.0        4.18      294.0  English       0   \n",
       "3  15540        150.0         14.0        3.87      200.0  English       1   \n",
       "4  13007      19322.0        213.0        4.09      268.0  English       1   \n",
       "\n",
       "   1_rating_count  2_rating_count  3_rating_count  4_rating_count  \\\n",
       "0          1593.0          5439.0         24255.0         41993.0   \n",
       "1            12.0            16.0            72.0           134.0   \n",
       "2             0.0             3.0            10.0            11.0   \n",
       "3             0.0             2.0            46.0            71.0   \n",
       "4           285.0           986.0          3758.0          5984.0   \n",
       "\n",
       "   5_rating_count  publish_year  republish  the_title  has_subtitle  \\\n",
       "0         39591.0        1997.0          1          0             0   \n",
       "1           130.0        2016.0          1          0             0   \n",
       "2            25.0        1994.0          0          0             0   \n",
       "3            31.0        1994.0          0          0             0   \n",
       "4          8309.0        1993.0          1          0             1   \n",
       "\n",
       "   title_char_count  title_longest_word  author_name_count  \\\n",
       "0                29                   7                  2   \n",
       "1                18                   8                  2   \n",
       "2                16                   8                  2   \n",
       "3                16                   6                  2   \n",
       "4                40                  11                  2   \n",
       "\n",
       "   author_middle_initial  rating_ratio  \n",
       "0                      0      0.086193  \n",
       "1                      0      0.106061  \n",
       "2                      0      0.083333  \n",
       "3                      0      0.019608  \n",
       "4                      0      0.088925  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Reset index of test set to get column to match on === #\n",
    "X4_test = X4_test.reset_index()\n",
    "X4_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3669, 21), (3669,), (3669,), (3669,))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X4_test.shape, test_id.shape, y_pred_proba_rf3.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>fiction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1042</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10779</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10072</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15540</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  fiction\n",
       "0   1042        1\n",
       "1  10779        0\n",
       "2  10072        0\n",
       "3  15540        1\n",
       "4  13007        1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.reset_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3669, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1042</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10779</td>\n",
       "      <td>1</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10072</td>\n",
       "      <td>0</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15540</td>\n",
       "      <td>1</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13007</td>\n",
       "      <td>1</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  pred  pred_proba\n",
       "0   1042     1        0.92\n",
       "1  10779     1        0.57\n",
       "2  10072     0        0.14\n",
       "3  15540     1        0.63\n",
       "4  13007     1        0.58"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Compare true / pred === #\n",
    "# Create new dataframe to compare the predictions to the actual\n",
    "df = pd.DataFrame({\n",
    "    \"index\": test_id,\n",
    "    \"pred\": y_pred_test_rf3,\n",
    "    \"pred_proba\": y_pred_proba_rf3,\n",
    "})\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3669, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_proba</th>\n",
       "      <th>fiction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1042</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10779</td>\n",
       "      <td>1</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10072</td>\n",
       "      <td>0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15540</td>\n",
       "      <td>1</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13007</td>\n",
       "      <td>1</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  pred  pred_proba  fiction\n",
       "0   1042     1        0.92        1\n",
       "1  10779     1        0.57        0\n",
       "2  10072     0        0.14        0\n",
       "3  15540     1        0.63        1\n",
       "4  13007     1        0.58        1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Merge in actuals === #\n",
    "df = df.merge(y_test.reset_index())\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3669, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_proba</th>\n",
       "      <th>fiction</th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>language</th>\n",
       "      <th>series</th>\n",
       "      <th>1_rating_count</th>\n",
       "      <th>2_rating_count</th>\n",
       "      <th>3_rating_count</th>\n",
       "      <th>4_rating_count</th>\n",
       "      <th>5_rating_count</th>\n",
       "      <th>publish_year</th>\n",
       "      <th>republish</th>\n",
       "      <th>the_title</th>\n",
       "      <th>has_subtitle</th>\n",
       "      <th>title_char_count</th>\n",
       "      <th>title_longest_word</th>\n",
       "      <th>author_name_count</th>\n",
       "      <th>author_middle_initial</th>\n",
       "      <th>rating_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1042</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>112871.0</td>\n",
       "      <td>4674.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>317.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>1593.0</td>\n",
       "      <td>5439.0</td>\n",
       "      <td>24255.0</td>\n",
       "      <td>41993.0</td>\n",
       "      <td>39591.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10779</td>\n",
       "      <td>1</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3.97</td>\n",
       "      <td>431.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.106061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10072</td>\n",
       "      <td>0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.18</td>\n",
       "      <td>294.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15540</td>\n",
       "      <td>1</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1</td>\n",
       "      <td>150.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.87</td>\n",
       "      <td>200.0</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13007</td>\n",
       "      <td>1</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1</td>\n",
       "      <td>19322.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>4.09</td>\n",
       "      <td>268.0</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "      <td>285.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>3758.0</td>\n",
       "      <td>5984.0</td>\n",
       "      <td>8309.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.088925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  pred  pred_proba  fiction  num_ratings  num_reviews  avg_rating  \\\n",
       "0   1042     1        0.92        1     112871.0       4674.0        4.00   \n",
       "1  10779     1        0.57        0        364.0         47.0        3.97   \n",
       "2  10072     0        0.14        0         49.0         12.0        4.18   \n",
       "3  15540     1        0.63        1        150.0         14.0        3.87   \n",
       "4  13007     1        0.58        1      19322.0        213.0        4.09   \n",
       "\n",
       "   num_pages language  series  1_rating_count  2_rating_count  3_rating_count  \\\n",
       "0      317.0  English       0          1593.0          5439.0         24255.0   \n",
       "1      431.0  English       0            12.0            16.0            72.0   \n",
       "2      294.0  English       0             0.0             3.0            10.0   \n",
       "3      200.0  English       1             0.0             2.0            46.0   \n",
       "4      268.0  English       1           285.0           986.0          3758.0   \n",
       "\n",
       "   4_rating_count  5_rating_count  publish_year  republish  the_title  \\\n",
       "0         41993.0         39591.0        1997.0          1          0   \n",
       "1           134.0           130.0        2016.0          1          0   \n",
       "2            11.0            25.0        1994.0          0          0   \n",
       "3            71.0            31.0        1994.0          0          0   \n",
       "4          5984.0          8309.0        1993.0          1          0   \n",
       "\n",
       "   has_subtitle  title_char_count  title_longest_word  author_name_count  \\\n",
       "0             0                29                   7                  2   \n",
       "1             0                18                   8                  2   \n",
       "2             0                16                   8                  2   \n",
       "3             0                16                   6                  2   \n",
       "4             1                40                  11                  2   \n",
       "\n",
       "   author_middle_initial  rating_ratio  \n",
       "0                      0      0.086193  \n",
       "1                      0      0.106061  \n",
       "2                      0      0.083333  \n",
       "3                      0      0.019608  \n",
       "4                      0      0.088925  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Merge the rest of the features back in === #\n",
    "df = df.merge(\n",
    "     X4_test,\n",
    "     how='left'\n",
    ")\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p8MrKRFRIT7o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(857, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_proba</th>\n",
       "      <th>fiction</th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>language</th>\n",
       "      <th>series</th>\n",
       "      <th>1_rating_count</th>\n",
       "      <th>2_rating_count</th>\n",
       "      <th>3_rating_count</th>\n",
       "      <th>4_rating_count</th>\n",
       "      <th>5_rating_count</th>\n",
       "      <th>publish_year</th>\n",
       "      <th>republish</th>\n",
       "      <th>the_title</th>\n",
       "      <th>has_subtitle</th>\n",
       "      <th>title_char_count</th>\n",
       "      <th>title_longest_word</th>\n",
       "      <th>author_name_count</th>\n",
       "      <th>author_middle_initial</th>\n",
       "      <th>rating_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10779</td>\n",
       "      <td>1</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3.97</td>\n",
       "      <td>431.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.106061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5437</td>\n",
       "      <td>1</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0</td>\n",
       "      <td>2650.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>304.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>927.0</td>\n",
       "      <td>930.0</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.109316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9875</td>\n",
       "      <td>1</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0</td>\n",
       "      <td>3073.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>4.25</td>\n",
       "      <td>659.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>469.0</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>1426.0</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2513</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1471.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>308.0</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "      <td>96.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.254545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3274</td>\n",
       "      <td>0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1</td>\n",
       "      <td>60322.0</td>\n",
       "      <td>2623.0</td>\n",
       "      <td>4.04</td>\n",
       "      <td>365.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>2063.0</td>\n",
       "      <td>12538.0</td>\n",
       "      <td>25237.0</td>\n",
       "      <td>20107.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.053811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  pred  pred_proba  fiction  num_ratings  num_reviews  avg_rating  \\\n",
       "1   10779     1        0.57        0        364.0         47.0        3.97   \n",
       "7    5437     1        0.70        0       2650.0         92.0        3.96   \n",
       "9    9875     1        0.66        0       3073.0         82.0        4.25   \n",
       "10   2513     0        0.25        1       1471.0        345.0        3.80   \n",
       "13   3274     0        0.13        1      60322.0       2623.0        4.04   \n",
       "\n",
       "    num_pages language  series  1_rating_count  2_rating_count  \\\n",
       "1       431.0  English       0            12.0            16.0   \n",
       "7       304.0  English       0            49.0           154.0   \n",
       "9       659.0  English       0            22.0            65.0   \n",
       "10      308.0  English       1            96.0           142.0   \n",
       "13      365.0  English       0           377.0          2063.0   \n",
       "\n",
       "    3_rating_count  4_rating_count  5_rating_count  publish_year  republish  \\\n",
       "1             72.0           134.0           130.0        2016.0          1   \n",
       "7            590.0           927.0           930.0        1987.0          1   \n",
       "9            469.0          1091.0          1426.0        1976.0          1   \n",
       "10           298.0           358.0           577.0        2011.0          0   \n",
       "13         12538.0         25237.0         20107.0        2005.0          1   \n",
       "\n",
       "    the_title  has_subtitle  title_char_count  title_longest_word  \\\n",
       "1           0             0                18                   8   \n",
       "7           1             0                45                   9   \n",
       "9           1             0                17                   8   \n",
       "10          0             0                 8                   8   \n",
       "13          0             1                46                   9   \n",
       "\n",
       "    author_name_count  author_middle_initial  rating_ratio  \n",
       "1                   2                      0      0.106061  \n",
       "7                   2                      0      0.109316  \n",
       "9                   2                      0      0.034565  \n",
       "10                  2                      0      0.254545  \n",
       "13                  2                      0      0.053811  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Filter for incorrect predictions === #\n",
    "df_wrong = df[df[\"pred\"] != df[\"fiction\"]]\n",
    "print(df_wrong.shape)\n",
    "df_wrong.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GujxCzg8IT7r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(857, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_proba</th>\n",
       "      <th>fiction</th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>language</th>\n",
       "      <th>series</th>\n",
       "      <th>1_rating_count</th>\n",
       "      <th>2_rating_count</th>\n",
       "      <th>3_rating_count</th>\n",
       "      <th>4_rating_count</th>\n",
       "      <th>5_rating_count</th>\n",
       "      <th>publish_year</th>\n",
       "      <th>republish</th>\n",
       "      <th>the_title</th>\n",
       "      <th>has_subtitle</th>\n",
       "      <th>title_char_count</th>\n",
       "      <th>title_longest_word</th>\n",
       "      <th>author_name_count</th>\n",
       "      <th>author_middle_initial</th>\n",
       "      <th>rating_ratio</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10779</td>\n",
       "      <td>1</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3.97</td>\n",
       "      <td>431.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.106061</td>\n",
       "      <td>Whispers of Heaven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5437</td>\n",
       "      <td>1</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0</td>\n",
       "      <td>2650.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>304.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>927.0</td>\n",
       "      <td>930.0</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.109316</td>\n",
       "      <td>The Condition of the Working Class in England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9875</td>\n",
       "      <td>1</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0</td>\n",
       "      <td>3073.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>4.25</td>\n",
       "      <td>659.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>469.0</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>1426.0</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034565</td>\n",
       "      <td>The Portable Jung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2513</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1471.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>308.0</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "      <td>96.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>Creatura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3274</td>\n",
       "      <td>0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1</td>\n",
       "      <td>60322.0</td>\n",
       "      <td>2623.0</td>\n",
       "      <td>4.04</td>\n",
       "      <td>365.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>2063.0</td>\n",
       "      <td>12538.0</td>\n",
       "      <td>25237.0</td>\n",
       "      <td>20107.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.053811</td>\n",
       "      <td>Smoke and Mirrors: Short Fiction and Illusions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1</td>\n",
       "      <td>227.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>236.0</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.068571</td>\n",
       "      <td>Tempus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>30195.0</td>\n",
       "      <td>5083.0</td>\n",
       "      <td>4.19</td>\n",
       "      <td>360.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>804.0</td>\n",
       "      <td>1225.0</td>\n",
       "      <td>3935.0</td>\n",
       "      <td>9587.0</td>\n",
       "      <td>14644.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083736</td>\n",
       "      <td>Okay for Now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14775</td>\n",
       "      <td>1</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>3.98</td>\n",
       "      <td>394.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>Five Suns Saga I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1</td>\n",
       "      <td>283.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.95</td>\n",
       "      <td>96.0</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125683</td>\n",
       "      <td>The Fox and the Hound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5396</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>12296.0</td>\n",
       "      <td>1649.0</td>\n",
       "      <td>4.32</td>\n",
       "      <td>302.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>3777.0</td>\n",
       "      <td>6549.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.046969</td>\n",
       "      <td>Copper Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10286</td>\n",
       "      <td>0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>The Guardian Angel (The Guardians of Nine Heav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7692</td>\n",
       "      <td>0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.43</td>\n",
       "      <td>306.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>The Tattooed Wolf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16937</td>\n",
       "      <td>0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1</td>\n",
       "      <td>3390.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>3.92</td>\n",
       "      <td>288.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>727.0</td>\n",
       "      <td>1184.0</td>\n",
       "      <td>1168.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.132228</td>\n",
       "      <td>To Reign in Hell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15951</td>\n",
       "      <td>1</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.02</td>\n",
       "      <td>260.0</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.084806</td>\n",
       "      <td>Secrets and Lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4451</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "      <td>24764.0</td>\n",
       "      <td>901.0</td>\n",
       "      <td>4.26</td>\n",
       "      <td>939.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>3612.0</td>\n",
       "      <td>8502.0</td>\n",
       "      <td>11844.0</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.039615</td>\n",
       "      <td>The Autobiography of Henry VIII: With Notes by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8767</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>714.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>3.91</td>\n",
       "      <td>448.0</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.139489</td>\n",
       "      <td>Dead Of Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12042</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "      <td>590.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>4.27</td>\n",
       "      <td>346.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.091476</td>\n",
       "      <td>Reclaimed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1432</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0</td>\n",
       "      <td>259458.0</td>\n",
       "      <td>11004.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>544.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>4756.0</td>\n",
       "      <td>8841.0</td>\n",
       "      <td>36070.0</td>\n",
       "      <td>88756.0</td>\n",
       "      <td>121035.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064812</td>\n",
       "      <td>A Short History of Nearly Everything</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0</td>\n",
       "      <td>1196.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.09</td>\n",
       "      <td>1376.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>Collected Poems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13762</td>\n",
       "      <td>0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1</td>\n",
       "      <td>18001.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>4.32</td>\n",
       "      <td>44.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>5078.0</td>\n",
       "      <td>9858.0</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.054566</td>\n",
       "      <td>The Love Song of J. Alfred Prufrock and Other ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>769</td>\n",
       "      <td>0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.37</td>\n",
       "      <td>605.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>698.0</td>\n",
       "      <td>715.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032555</td>\n",
       "      <td>Brownout - 666: or the Real Meaning of the Swa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6084</td>\n",
       "      <td>1</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.90</td>\n",
       "      <td>594.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.178478</td>\n",
       "      <td>Apple Cider Vinegar Miracle Health System</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9482</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1</td>\n",
       "      <td>25789.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>4.09</td>\n",
       "      <td>216.0</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "      <td>625.0</td>\n",
       "      <td>1154.0</td>\n",
       "      <td>4738.0</td>\n",
       "      <td>8036.0</td>\n",
       "      <td>11236.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.092310</td>\n",
       "      <td>Oz: The Wonderful Wizard of Oz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11433</td>\n",
       "      <td>0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1</td>\n",
       "      <td>499.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.99</td>\n",
       "      <td>152.0</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.053619</td>\n",
       "      <td>Queen and Country, Vol. 3: Crystal Ball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3103</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>43840.0</td>\n",
       "      <td>4184.0</td>\n",
       "      <td>4.32</td>\n",
       "      <td>132.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>903.0</td>\n",
       "      <td>1474.0</td>\n",
       "      <td>4890.0</td>\n",
       "      <td>11873.0</td>\n",
       "      <td>24700.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064993</td>\n",
       "      <td>The Arrival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10215</td>\n",
       "      <td>0</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1</td>\n",
       "      <td>229.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>4.10</td>\n",
       "      <td>315.0</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>Speaking in Tungs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5987</td>\n",
       "      <td>0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1</td>\n",
       "      <td>325.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3.91</td>\n",
       "      <td>226.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.174312</td>\n",
       "      <td>Master of the Jinn: A Sufi Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1</td>\n",
       "      <td>12371.0</td>\n",
       "      <td>604.0</td>\n",
       "      <td>4.39</td>\n",
       "      <td>1204.0</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "      <td>276.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>2758.0</td>\n",
       "      <td>7684.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066175</td>\n",
       "      <td>The Black Jewels Trilogy: Daughter of the Bloo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>11175</td>\n",
       "      <td>0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1</td>\n",
       "      <td>6887.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>4.27</td>\n",
       "      <td>326.0</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "      <td>127.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>2218.0</td>\n",
       "      <td>3510.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>Dungeon Born</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9417</td>\n",
       "      <td>0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1</td>\n",
       "      <td>851.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>4.14</td>\n",
       "      <td>176.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066770</td>\n",
       "      <td>The Secret Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3290</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1</td>\n",
       "      <td>169722.0</td>\n",
       "      <td>11894.0</td>\n",
       "      <td>3.84</td>\n",
       "      <td>280.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>6266.0</td>\n",
       "      <td>13286.0</td>\n",
       "      <td>39355.0</td>\n",
       "      <td>54058.0</td>\n",
       "      <td>56757.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.176438</td>\n",
       "      <td>The DUFF: Designated Ugly Fat Friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8249</td>\n",
       "      <td>0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1</td>\n",
       "      <td>103.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.22</td>\n",
       "      <td>293.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>How Fast Can You Run</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  pred  pred_proba  fiction  num_ratings  num_reviews  avg_rating  \\\n",
       "0   10779     1        0.57        0        364.0         47.0        3.97   \n",
       "1    5437     1        0.70        0       2650.0         92.0        3.96   \n",
       "2    9875     1        0.66        0       3073.0         82.0        4.25   \n",
       "3    2513     0        0.25        1       1471.0        345.0        3.80   \n",
       "4    3274     0        0.13        1      60322.0       2623.0        4.04   \n",
       "5   18101     0        0.34        1        227.0         15.0        4.15   \n",
       "6    2960     0        0.50        1      30195.0       5083.0        4.19   \n",
       "7   14775     1        0.64        0        111.0         49.0        3.98   \n",
       "8   16221     0        0.44        1        283.0         18.0        3.95   \n",
       "9    5396     0        0.50        1      12296.0       1649.0        4.32   \n",
       "10  10286     0        0.26        1          5.0          0.0        5.00   \n",
       "11   7692     0        0.11        1         23.0          6.0        4.43   \n",
       "12  16937     0        0.47        1       3390.0        206.0        3.92   \n",
       "13  15951     1        0.53        0        376.0         80.0        4.02   \n",
       "14   4451     0        0.24        1      24764.0        901.0        4.26   \n",
       "15   8767     0        0.50        1        714.0         81.0        3.91   \n",
       "16  12042     0        0.24        1        590.0         66.0        4.27   \n",
       "17   1432     1        0.76        0     259458.0      11004.0        4.20   \n",
       "18   2009     1        0.67        0       1196.0         35.0        4.09   \n",
       "19  13762     0        0.35        1      18001.0        263.0        4.32   \n",
       "20    769     0        0.13        1       1503.0         21.0        4.37   \n",
       "21   6084     1        0.53        0        595.0         56.0        3.90   \n",
       "22   9482     0        0.48        1      25789.0        608.0        4.09   \n",
       "23  11433     0        0.37        1        499.0         23.0        3.99   \n",
       "24   3103     0        0.50        1      43840.0       4184.0        4.32   \n",
       "25  10215     0        0.41        1        229.0         85.0        4.10   \n",
       "26   5987     0        0.39        1        325.0         53.0        3.91   \n",
       "27     77     0        0.28        1      12371.0        604.0        4.39   \n",
       "28  11175     0        0.33        1       6887.0        470.0        4.27   \n",
       "29   9417     0        0.49        1        851.0         90.0        4.14   \n",
       "30   3290     0        0.48        1     169722.0      11894.0        3.84   \n",
       "31   8249     0        0.33        1        103.0         34.0        4.22   \n",
       "\n",
       "    num_pages language  series  1_rating_count  2_rating_count  \\\n",
       "0       431.0  English       0            12.0            16.0   \n",
       "1       304.0  English       0            49.0           154.0   \n",
       "2       659.0  English       0            22.0            65.0   \n",
       "3       308.0  English       1            96.0           142.0   \n",
       "4       365.0  English       0           377.0          2063.0   \n",
       "5       236.0  English       1             3.0             9.0   \n",
       "6       360.0  English       0           804.0          1225.0   \n",
       "7       394.0  English       0             0.0            10.0   \n",
       "8        96.0  English       1             5.0            18.0   \n",
       "9       302.0  English       0           125.0           360.0   \n",
       "10        NaN      NaN       0             0.0             0.0   \n",
       "11      306.0  English       0             0.0             0.0   \n",
       "12      288.0  English       0            85.0           226.0   \n",
       "13      260.0  English       1             9.0            15.0   \n",
       "14      939.0  English       0           241.0           565.0   \n",
       "15      448.0  English       1            23.0            48.0   \n",
       "16      346.0      NaN       1            17.0            27.0   \n",
       "17      544.0  English       0          4756.0          8841.0   \n",
       "18     1376.0      NaN       0            26.0            54.0   \n",
       "19       44.0  English       0           226.0           589.0   \n",
       "20      605.0      NaN       0            26.0            20.0   \n",
       "21      594.0      NaN       0            22.0            46.0   \n",
       "22      216.0  English       1           625.0          1154.0   \n",
       "23      152.0  English       1             7.0            13.0   \n",
       "24      132.0  English       0           903.0          1474.0   \n",
       "25      315.0  English       1             5.0             6.0   \n",
       "26      226.0  English       0             6.0            32.0   \n",
       "27     1204.0  English       1           276.0           415.0   \n",
       "28      326.0  English       1           127.0           231.0   \n",
       "29      176.0  English       0             8.0            35.0   \n",
       "30      280.0  English       0          6266.0         13286.0   \n",
       "31      293.0  English       0             3.0             5.0   \n",
       "\n",
       "    3_rating_count  4_rating_count  5_rating_count  publish_year  republish  \\\n",
       "0             72.0           134.0           130.0        2016.0          1   \n",
       "1            590.0           927.0           930.0        1987.0          1   \n",
       "2            469.0          1091.0          1426.0        1976.0          1   \n",
       "3            298.0           358.0           577.0        2011.0          0   \n",
       "4          12538.0         25237.0         20107.0        2005.0          1   \n",
       "5             40.0            75.0           100.0        2011.0          1   \n",
       "6           3935.0          9587.0         14644.0        2011.0          0   \n",
       "7             21.0            41.0            39.0        2015.0          1   \n",
       "8             77.0            69.0           114.0        1994.0          1   \n",
       "9           1485.0          3777.0          6549.0        2006.0          0   \n",
       "10             0.0             0.0             5.0        2018.0          0   \n",
       "11             2.0             9.0            12.0        2014.0          1   \n",
       "12           727.0          1184.0          1168.0           NaN          1   \n",
       "13            69.0           150.0           133.0        2013.0          1   \n",
       "14          3612.0          8502.0         11844.0        1998.0          1   \n",
       "15           134.0           277.0           232.0        2012.0          1   \n",
       "16            65.0           153.0           328.0        2015.0          0   \n",
       "17         36070.0         88756.0        121035.0        2004.0          1   \n",
       "18           216.0           394.0           506.0        2003.0          1   \n",
       "19          2250.0          5078.0          9858.0        1976.0          1   \n",
       "20            44.0           698.0           715.0        2018.0          1   \n",
       "21           146.0           138.0           243.0        1995.0          0   \n",
       "22          4738.0          8036.0         11236.0        2009.0          1   \n",
       "23           106.0           226.0           147.0        2003.0          1   \n",
       "24          4890.0         11873.0         24700.0        2007.0          0   \n",
       "25            42.0            84.0            92.0        2018.0          1   \n",
       "26            69.0            95.0           123.0        2004.0          1   \n",
       "27          1238.0          2758.0          7684.0        2003.0          0   \n",
       "28           801.0          2218.0          3510.0        2016.0          0   \n",
       "29           164.0           265.0           379.0        1998.0          1   \n",
       "30         39355.0         54058.0         56757.0        2010.0          0   \n",
       "31            10.0            33.0            52.0        2016.0          0   \n",
       "\n",
       "    the_title  has_subtitle  title_char_count  title_longest_word  \\\n",
       "0           0             0                18                   8   \n",
       "1           1             0                45                   9   \n",
       "2           1             0                17                   8   \n",
       "3           0             0                 8                   8   \n",
       "4           0             1                46                   9   \n",
       "5           0             0                 6                   6   \n",
       "6           0             0                12                   4   \n",
       "7           0             0                16                   4   \n",
       "8           1             0                21                   5   \n",
       "9           0             0                10                   6   \n",
       "10          1             0                52                   9   \n",
       "11          1             0                17                   8   \n",
       "12          0             0                16                   5   \n",
       "13          0             0                16                   7   \n",
       "14          1             1                68                  13   \n",
       "15          0             0                14                   6   \n",
       "16          0             0                 9                   9   \n",
       "17          0             0                36                  10   \n",
       "18          0             0                15                   9   \n",
       "19          1             0                51                   8   \n",
       "20          0             1                51                   8   \n",
       "21          0             0                41                   7   \n",
       "22          0             1                30                   9   \n",
       "23          0             1                39                   8   \n",
       "24          1             0                11                   7   \n",
       "25          0             0                17                   8   \n",
       "26          0             1                32                   6   \n",
       "27          1             1                91                   8   \n",
       "28          0             0                12                   7   \n",
       "29          1             0                19                   8   \n",
       "30          1             1                36                  10   \n",
       "31          0             0                20                   4   \n",
       "\n",
       "    author_name_count  author_middle_initial  rating_ratio  \\\n",
       "0                   2                      0      0.106061   \n",
       "1                   2                      0      0.109316   \n",
       "2                   2                      0      0.034565   \n",
       "3                   2                      0      0.254545   \n",
       "4                   2                      0      0.053811   \n",
       "5                   3                      0      0.068571   \n",
       "6                   3                      0      0.083736   \n",
       "7                   2                      0      0.125000   \n",
       "8                   3                      0      0.125683   \n",
       "9                   3                      0      0.046969   \n",
       "10                  2                      0      0.000000   \n",
       "11                  2                      0      0.000000   \n",
       "12                  2                      0      0.132228   \n",
       "13                  2                      0      0.084806   \n",
       "14                  2                      0      0.039615   \n",
       "15                  2                      0      0.139489   \n",
       "16                  2                      0      0.091476   \n",
       "17                  2                      0      0.064812   \n",
       "18                  2                      0      0.088889   \n",
       "19                  2                      0      0.054566   \n",
       "20                  3                      0      0.032555   \n",
       "21                  2                      0      0.178478   \n",
       "22                  2                      0      0.092310   \n",
       "23                  2                      0      0.053619   \n",
       "24                  2                      0      0.064993   \n",
       "25                  3                      0      0.062500   \n",
       "26                  2                      0      0.174312   \n",
       "27                  2                      0      0.066175   \n",
       "28                  2                      0      0.062500   \n",
       "29                  2                      0      0.066770   \n",
       "30                  2                      0      0.176438   \n",
       "31                  3                      0      0.094118   \n",
       "\n",
       "                                                title  \n",
       "0                                  Whispers of Heaven  \n",
       "1       The Condition of the Working Class in England  \n",
       "2                                   The Portable Jung  \n",
       "3                                            Creatura  \n",
       "4      Smoke and Mirrors: Short Fiction and Illusions  \n",
       "5                                              Tempus  \n",
       "6                                        Okay for Now  \n",
       "7                                    Five Suns Saga I  \n",
       "8                               The Fox and the Hound  \n",
       "9                                          Copper Sun  \n",
       "10  The Guardian Angel (The Guardians of Nine Heav...  \n",
       "11                                  The Tattooed Wolf  \n",
       "12                                   To Reign in Hell  \n",
       "13                                   Secrets and Lies  \n",
       "14  The Autobiography of Henry VIII: With Notes by...  \n",
       "15                                     Dead Of Winter  \n",
       "16                                          Reclaimed  \n",
       "17               A Short History of Nearly Everything  \n",
       "18                                    Collected Poems  \n",
       "19  The Love Song of J. Alfred Prufrock and Other ...  \n",
       "20  Brownout - 666: or the Real Meaning of the Swa...  \n",
       "21          Apple Cider Vinegar Miracle Health System  \n",
       "22                     Oz: The Wonderful Wizard of Oz  \n",
       "23            Queen and Country, Vol. 3: Crystal Ball  \n",
       "24                                        The Arrival  \n",
       "25                                  Speaking in Tungs  \n",
       "26                   Master of the Jinn: A Sufi Novel  \n",
       "27  The Black Jewels Trilogy: Daughter of the Bloo...  \n",
       "28                                       Dungeon Born  \n",
       "29                                The Secret Language  \n",
       "30               The DUFF: Designated Ugly Fat Friend  \n",
       "31                               How Fast Can You Run  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Get titles, because I'm curious === #\n",
    "df_wrong = df_wrong.merge(books.iloc[df_wrong[\"index\"]][\"title\"].reset_index())\n",
    "print(df_wrong.shape)\n",
    "df_wrong.head(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qCUPn-XuIT7w"
   },
   "source": [
    "From a brief read through the above table of some incorrect predictions, one of the common mistakes the model makes is to trust the `has_subtitle` feature too much. There does seem to be some fiction books that have subtitles, seemingly many of which cause the model to predict as nonfiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QGXwE6_OIT7z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cmVOAg53IT71"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "print_fiction_2-03_modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
