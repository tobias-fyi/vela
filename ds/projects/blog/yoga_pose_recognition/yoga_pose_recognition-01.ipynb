{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good Quality Data (Images)\n",
    "\n",
    "The goal is to recognize real-life yoga positions. That means the training data should look like real-life yoga positions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## The Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the past few months, a few friends and I have been brainstorming ideas for a human optimization app. One of the ways we see the app helping people optimize themselves is by giving them a suite of tools to keep themselves accountable.\n",
    "\n",
    "An idea I had to get started with this was to train a series of models to recognize certain exercises. Ideally, a user would be able to set their phone down, pointing the camera at themselves, and have it guide them through exercises, noting down how many of each is done or how long one stays in a position.\n",
    "\n",
    "Eventually it would be great to get to the point of training an action recognition model that could recognize dynamic exercises. But it's best to start simple, stupid. And the simplest way version of this I could think of to start with is to recognize yoga poses, as these poses are visually distinct and the one practicing will typically stay in each positions for at least a few breathes.\n",
    "\n",
    "Another thing to eventually get to would be for the model to know what good and bad forms of each exercise or pose look like. Then, the system would be able to advise on how to correct bad form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used a tool called fastclass to gather images from Google and Bing.\n",
    "\n",
    "Notes:\n",
    "\n",
    "* Cartoon images\n",
    "* Dataset bias - the vast majority of images were of white people\n",
    "  * Could image augmentation help reduce the model's bias from the image dataset?\n",
    "* Image watermarks - many from shutterstock, etc.\n",
    "  * At what point do watermarks get recognized as features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Digressions\n",
    "\n",
    "* Visual satiation - like semantic satiation but with imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('vela': pipenv)",
   "language": "python",
   "name": "python37664bitvelapipenvde09592071074af6a70ce3b1ce38af95"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
