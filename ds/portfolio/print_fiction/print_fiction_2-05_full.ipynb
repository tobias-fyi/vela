{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6K-Ijmo7VceT"
   },
   "source": [
    "# üëΩüëæ `print(fiction)` üìöüõ∏\n",
    "\n",
    "> #### A data science project by _Tobias Reaper_\n",
    "\n",
    "#### üìì Notebook 3: Modeling üß†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_K7zk62hIT4-"
   },
   "source": [
    "---\n",
    "\n",
    "### Notebook Outline\n",
    "\n",
    "[explanation of this notebook in context of project]\n",
    "\n",
    "* Intro\n",
    "* Imports and Configuration\n",
    "* Load Data\n",
    "* Model Validation\n",
    "  * Majority class baseline\n",
    "  * Limited logistic baseline\n",
    "  * Default random forest\n",
    "* Iterate\n",
    "  * Feature engineering\n",
    "  * Feature importances\n",
    "  * Cross-validation and hyperparameter tuning\n",
    "* Results and Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kM63g2O2IT5B"
   },
   "source": [
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "`print(fiction)` is a solo project I worked on to explore the data on and around stories‚Äîspecifically, the stories contained in print books.\n",
    "\n",
    "I used Scrapy to scrape metadata for over 20,000 books from GoodReads and used it to train a gradient-boosted random forest classifier. The final version of the model classified books as either fiction or nonfiction with 88% accuracy.\n",
    "\n",
    "The dataset is freely available for download from GitHub or Kaggle (link to come).\n",
    "I built an interactive dashboard using Plotly Dash that can be used to tinker with the model parameters and view the resulting prediction in real time.\n",
    "\n",
    "You can find the current live version of the app here: [print(fiction)](http://print-fiction.herokuapp.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is part of an on-going series of exploratory articles and projects called Sci-Fi IRL, through which I am exploring the relationship between science-fiction and the real world. It is my belief that the stories we read, write, and believe in, particularly about our future, have an effect on how that future ultimately turns out.\n",
    "\n",
    "Our human minds are geared toward thinking about what could go wrong. It follows that the majority of stories in popular and niche culture are written about how things could go wrong, usually catastrophically so‚Äîit \"tells a good story\".\n",
    "\n",
    "In the case of science-fiction, stories tend to be dystopian in nature, showing what could go wrong if our technology advances along certain trajectories.\n",
    "\n",
    "But does this affect our outlook on what these technologies can do for us?\n",
    "\n",
    "While it is always good to consider the possible ramifications of technological advances, I believe that too many dystopian stories are causing humans, as a civilization, to fall short of our potential. If instead of describing dystopia, the majority of science-fiction was utopian‚Äîexploring the possible ways that things could go _right_ for us‚ÄîI believe it would, in a very real sense, point us a little bit more in that direction.\n",
    "\n",
    "If that's a bit too lofty for you, another way to think about this is to imagine what your life could be like 100 years from now (i.e. if you'd been born 60 years from now). Depending on how things go, you could be scraping by with a group of other radiation-poisoned humans as the world recovers from nuclear holocaust. Or, you could be out exploring the galaxy in a luxury space yacht, with a potential lifespan in the centuries or millennia.\n",
    "\n",
    "Which is more interesting to you? Which future would you rather live in?\n",
    "\n",
    "This is the area I'm exploring with this series. I want to find the data and conduct the analyses that begins to show how our collective narrative (aliased by popular science-fiction) can bring about changes in our technological progress.\n",
    "\n",
    "Of course this area is too large to explore in a single project, which is why I am doing it as a series. The first article in the series explored, at a very basic level, how technical terminology disperses through popular culture. You can find that article here: Tech Term Velocity.\n",
    "\n",
    "In this project, print(fiction) the broad question I wanted to explore was this:\n",
    "\n",
    "> What separates fact from fiction?\n",
    "\n",
    "...which is really just a clich√© way of saying I wanted to explore the differences between nonfiction and fiction stories. My favorite method of consuming science-fiction is through books. Therefore, I chose to look at the differences between fiction and nonfiction books.\n",
    "\n",
    "Without diving into the actual content of books (that's a project for a later time when I have more experience with natural language processing), my goal was to look for patterns in the book metadata that could distinguish the two genres.\n",
    "\n",
    "One last quick note before getting into it.\n",
    "\n",
    "I'm not going to walk through every single step (though I'll do my best to paint the whole picture) or show the actual code in this article. If you're curious about the nitty-gritty details and code I wrote for any of the steps, the Jupyter notebooks found at the link below walk through all of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebooks detailing the entire process of data gathering, wrangling, modeling, and deployment, can be found here: [print(fiction) notebooks](https://github.com/tobias-fyi/print-fiction/tree/master/notebooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NCMU9Y5DVvT5"
   },
   "source": [
    "---\n",
    "\n",
    "### Imports and Configuration\n",
    "\n",
    "‚öôÔ∏èüì• "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "cOS1Wyo0VZQM",
    "outputId": "c8cf3f18-b0e1-4cf3-e6eb-8fda07f48def"
   },
   "outputs": [],
   "source": [
    "# === General Imports === #\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import randint, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sgtmOkO6IT5Q"
   },
   "outputs": [],
   "source": [
    "# === Configure === #\n",
    "%matplotlib inline\n",
    "pd.options.display.max_rows = 200\n",
    "pd.options.display.max_columns = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gGwq5WRwI6ty"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install category-encoders\n",
    "!pip install eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "f01v7xNdIT5W",
    "outputId": "c8c09332-0f42-488e-ca0f-0f601510be12"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tobias/.vega/vela-_qIiF1eP/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Tobias/.vega/vela-_qIiF1eP/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# === ML Imports === #\n",
    "\n",
    "# Preprocessing\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "\n",
    "# Model validation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Interpretations\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yInEDKOEIT5c"
   },
   "source": [
    "---\n",
    "\n",
    "## Load Data\n",
    "\n",
    "üööüìà"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "colab_type": "code",
    "id": "ndvQA9x5WtnB",
    "outputId": "c3f6ca83-af13-4502-dcb7-cf71cdcfffa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18344, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>language</th>\n",
       "      <th>series</th>\n",
       "      <th>1_rating_count</th>\n",
       "      <th>2_rating_count</th>\n",
       "      <th>3_rating_count</th>\n",
       "      <th>4_rating_count</th>\n",
       "      <th>5_rating_count</th>\n",
       "      <th>publish_year</th>\n",
       "      <th>publish_month</th>\n",
       "      <th>publish_day</th>\n",
       "      <th>fiction</th>\n",
       "      <th>republish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Book of Mormon: Another Testament of Jesus...</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>71355.0</td>\n",
       "      <td>5704.0</td>\n",
       "      <td>4.37</td>\n",
       "      <td>531.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>7520.0</td>\n",
       "      <td>2697.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>56654.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Prince</td>\n",
       "      <td>Niccol√≤ Machiavelli</td>\n",
       "      <td>229715.0</td>\n",
       "      <td>7261.0</td>\n",
       "      <td>3.81</td>\n",
       "      <td>140.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>5254.0</td>\n",
       "      <td>16827.0</td>\n",
       "      <td>61182.0</td>\n",
       "      <td>80221.0</td>\n",
       "      <td>66231.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Foundation Trilogy</td>\n",
       "      <td>Isaac Asimov</td>\n",
       "      <td>83933.0</td>\n",
       "      <td>1331.0</td>\n",
       "      <td>4.40</td>\n",
       "      <td>679.0</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "      <td>477.0</td>\n",
       "      <td>1521.0</td>\n",
       "      <td>9016.0</td>\n",
       "      <td>25447.0</td>\n",
       "      <td>47472.0</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title               author  \\\n",
       "0  The Book of Mormon: Another Testament of Jesus...            Anonymous   \n",
       "1                                         The Prince  Niccol√≤ Machiavelli   \n",
       "2                             The Foundation Trilogy         Isaac Asimov   \n",
       "\n",
       "   num_ratings  num_reviews  avg_rating  num_pages language  series  \\\n",
       "0      71355.0       5704.0        4.37      531.0  English       0   \n",
       "1     229715.0       7261.0        3.81      140.0  English       0   \n",
       "2      83933.0       1331.0        4.40      679.0  English       1   \n",
       "\n",
       "   1_rating_count  2_rating_count  3_rating_count  4_rating_count  \\\n",
       "0          7520.0          2697.0          2521.0          1963.0   \n",
       "1          5254.0         16827.0         61182.0         80221.0   \n",
       "2           477.0          1521.0          9016.0         25447.0   \n",
       "\n",
       "   5_rating_count  publish_year  publish_month  publish_day  fiction  \\\n",
       "0         56654.0        2013.0           10.0         22.0        0   \n",
       "1         66231.0        2003.0            6.0          1.0        0   \n",
       "2         47472.0        1974.0            1.0          1.0        1   \n",
       "\n",
       "   republish  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Load the dataset === #\n",
    "# This version was exported from the previous notebook\n",
    "# after doing some initial wrangling\n",
    "data_path = \"https://raw.githubusercontent.com/tobias-fyi/vela/master/ds/interview_prep/practice/print-fiction/assets/must_read_books-02.csv\"\n",
    "\n",
    "books = pd.read_csv(data_path, na_values=\"?\")\n",
    "print(books.shape)\n",
    "books.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "colab_type": "code",
    "id": "ynTpCxezIT5l",
    "outputId": "ed5090be-ec2a-438e-9d3f-d9b524086f12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                0\n",
       "author               0\n",
       "num_ratings          0\n",
       "num_reviews          0\n",
       "avg_rating           0\n",
       "num_pages          666\n",
       "language          1332\n",
       "series               0\n",
       "1_rating_count      83\n",
       "2_rating_count      83\n",
       "3_rating_count      83\n",
       "4_rating_count      83\n",
       "5_rating_count      83\n",
       "publish_year       282\n",
       "publish_month      282\n",
       "publish_day        282\n",
       "fiction              0\n",
       "republish            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Confirm null values were read in correctly === #\n",
    "books.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6YxTVzcUIT5s"
   },
   "source": [
    "---\n",
    "\n",
    "## Model validation\n",
    "\n",
    "* Split data into train, validation, and test sets\n",
    "* Choose an appropriate evaluation metric\n",
    "* Get a baseline accuracy (or precision/recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "KLQb9YurIT5u",
    "outputId": "bb38642f-6279-4971-ac5a-91a71502e44c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11740, 18), (2935, 18), (3669, 18))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Split data into train / val / test === #\n",
    "train, test = train_test_split(books, stratify=books[\"fiction\"], test_size=0.2, random_state=92)\n",
    "train, val = train_test_split(train, stratify=train[\"fiction\"], test_size=0.2, random_state=92)\n",
    "\n",
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "d80Z_YY-IT5y",
    "outputId": "f85f4b48-0679-49d9-8328-6ba49afe867f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11740,) (2935,) (3669,)\n",
      "(11740, 17) (2935, 17) (3669, 17)\n"
     ]
    }
   ],
   "source": [
    "# === Set up target and features === #\n",
    "target = \"fiction\"\n",
    "\n",
    "# Arrange y vector\n",
    "y_train = train[target]\n",
    "y_val = val[target]\n",
    "y_test = test[target]\n",
    "\n",
    "print(y_train.shape, y_val.shape, y_test.shape)\n",
    "\n",
    "# Arrange X matrices\n",
    "X_train = train.drop(columns=[target])\n",
    "X_val = val.drop(columns=[target])\n",
    "X_test = test.drop(columns=[target])\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "id": "ax4SYWEYIT52",
    "outputId": "d9e44b93-dc36-416e-c5b2-b63cd769c1e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    6145\n",
      "0    5595\n",
      "Name: fiction, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Target distribution === #\n",
    "print(y_train.value_counts())\n",
    "sns.distplot(y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Y1zfXpFIT5-"
   },
   "source": [
    "#### Majority class baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8-fMHHmbIT6A",
    "outputId": "4cf166ef-706e-43f1-ff68-f4045d554a11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5234241908006815"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Use mode as predictions === #\n",
    "maj = y_train.mode()[0]  # Mode is 1 (fiction)\n",
    "\n",
    "# Simply predict 1 for every training example\n",
    "y_pred_maj = [maj] * len(y_train)\n",
    "\n",
    "# Baseline accuracy\n",
    "accuracy_score(y_train, y_pred_maj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WJyObFatIT6F"
   },
   "source": [
    "#### Limited logistic baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-Jd35T12IT6H",
    "outputId": "f1eafe48-9822-4143-dd6f-4b01a6e11710"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11740, 3), (2935, 3), (3669, 3))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Use only a few features for this baseline === #\n",
    "base_features = [\n",
    "    \"num_reviews\",\n",
    "    \"avg_rating\",\n",
    "    \"num_pages\",\n",
    "]\n",
    "\n",
    "# Arrange X matrices\n",
    "X1_train = train[base_features]\n",
    "X1_val = val[base_features]\n",
    "X1_test = test[base_features]\n",
    "\n",
    "X1_train.shape, X1_val.shape, X1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "colab_type": "code",
    "id": "_MUpLWo5IT6L",
    "outputId": "98e2de7b-7acb-41de-c6da-d9888d0a38ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('imputer', SimpleImputer(strategy='median')),\n",
       "                ('logreg', LogisticRegression(random_state=92))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Baseline model === #\n",
    "pipe1 = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"logreg\", LogisticRegression(random_state=92)),\n",
    "])\n",
    "\n",
    "# Train base pipeline\n",
    "pipe1.fit(X1_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "JvLfVqdMIT6R",
    "outputId": "c7451b47-8043-449d-fba5-15fe998c187b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.6275979557069846\n"
     ]
    }
   ],
   "source": [
    "# === Made predictions to get validation accuracy === #\n",
    "y_pred1 = pipe1.predict(X1_val)\n",
    "\n",
    "# Compute accuracy\n",
    "print(\"Baseline accuracy:\", accuracy_score(y_val, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "oLxd7U0-IT6W",
    "outputId": "fdb1973a-a8b6-4e7b-c0d8-9304cd795baf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 821,  578],\n",
       "       [ 515, 1021]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Baseline confusion matrix === #\n",
    "confusion_matrix(y_val, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TP4_Zqm9IT6a"
   },
   "source": [
    "#### Default Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "QcqQAr_HIT6c",
    "outputId": "03aef88a-260e-43e4-cfb2-408deeb24294"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default random forest eval metrics:\n",
      "  Accuracy: 0.7342419080068143\n",
      "  F1 score: 0.7477360931435963\n"
     ]
    }
   ],
   "source": [
    "# === Default random forest model === #\n",
    "def_drop_columns = [\n",
    "    \"title\",\n",
    "    \"author\",\n",
    "    \"language\",\n",
    "]\n",
    "\n",
    "X2_train = X_train.drop(columns=def_drop_columns)\n",
    "X2_val = X_val.drop(columns=def_drop_columns)\n",
    "X2_test = X_test.drop(columns=def_drop_columns)\n",
    "\n",
    "rf1_pipe = Pipeline([\n",
    "    (\"encoder\", ce.OrdinalEncoder()),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"rfc\", RandomForestClassifier(random_state=92)),\n",
    "])\n",
    "\n",
    "# Train default random forest\n",
    "rf1_pipe.fit(X2_train, y_train)\n",
    "\n",
    "# Made predictions to get validation accuracy\n",
    "y_pred_rf1 = rf1_pipe.predict(X2_val)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(\"Default random forest eval metrics:\")\n",
    "print(\"  Accuracy:\", accuracy_score(y_val, y_pred_rf1))\n",
    "print(\"  F1 score:\", f1_score(y_val, y_pred_rf1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "zC0QPwcNIT6g",
    "outputId": "3380ef13-14bd-421e-ec56-8d4ec5456c05"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Evaluate default rf with confusion matrix === #\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "unique_labels(y_val)  # Create unique labels\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    labels = unique_labels(y_true)\n",
    "    columns = [f'Predicted {label}' for label in labels]\n",
    "    index = [f'Actual {label}' for label in labels]\n",
    "    table = pd.DataFrame(confusion_matrix(y_true, y_pred), \n",
    "                         columns=columns, index=index)\n",
    "    return sns.heatmap(table, annot=True, fmt='d', cmap='viridis')\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(y_val, y_pred_rf1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7uQ4SRFvIT6k"
   },
   "source": [
    "Alrighty then! With the (almost) full set of features and default hyperparameters the target can be predicted with ~73% accuracy. Although the target is not skewed very much, it is still skewed. Therefore, accuracy may not be the best way to evaluate the model. A better metric could be the F1 score. This is a little higher than the accuracy, clocking in at almost 75%.\n",
    "\n",
    "The F1 score is made up of the precision and recall. Actually, it can be interpreted of as the weighted average of precision and recall.\n",
    "\n",
    "This provides a better method of evaluating performance, because it takes into account false positives and false negatives. Accuracy only accounts for the model's correct predictions and mistakes, irrespective of _how_ the model made those mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "BQ-_O3VRIT6l",
    "outputId": "539d49f5-e6f2-45c4-f4c1-dfcd32656437"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7429305912596401\n"
     ]
    }
   ],
   "source": [
    "# === Calculate precision === #\n",
    "true_pos = 1156\n",
    "false_pos = 400\n",
    "precision = true_pos / (true_pos + false_pos)\n",
    "print(f\"Precision: {precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "xxBgEJ04IT6p",
    "outputId": "f284bdb4-2fd3-4cbe-99ba-dac7d0d4e0e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7526041666666666\n"
     ]
    }
   ],
   "source": [
    "# === Calculate recall === #\n",
    "true_pos = 1156\n",
    "false_neg = 380\n",
    "precision = true_pos / (true_pos + false_neg)\n",
    "print(f\"Precision: {precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "colab_type": "code",
    "id": "mRMKAvgsIT6t",
    "outputId": "258969da-b797-472d-c0f7-c75e73400397"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.71      0.72      1399\n",
      "           1       0.74      0.75      0.75      1536\n",
      "\n",
      "    accuracy                           0.73      2935\n",
      "   macro avg       0.73      0.73      0.73      2935\n",
      "weighted avg       0.73      0.73      0.73      2935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === Classification report === #\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_val, y_pred_rf1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EAKy3O32IT6w"
   },
   "source": [
    "Let's see what we can do to increase that score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qdxnY7AUIT6x"
   },
   "source": [
    "---\n",
    "\n",
    "## Iterate\n",
    "\n",
    "* [x] Engineer new features\n",
    "* [x] Feature pruning with permutation importance\n",
    "* [x] Use cross-validation (RandomizedSearchCV) to tune hyperparameters\n",
    "* [x] Try out different algorithms\n",
    "  * [x] KNearestClassifier\n",
    "  * [x] XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QHAQC5nIIT6z"
   },
   "source": [
    "### Feature Engineering\n",
    "\n",
    "When I initially started this project, I went through the process of validating and training a model or two that tried to predict the average rating of books. This was by far the most common target chosen by those who started Kaggle kernels using other GoodReads datasets. Although this may have the most obvious business value if I was a data scientist working for a book publisher, to me this wasn't a particularly interesting target to try to predict.\n",
    "\n",
    "I realized this when I hit a wall with my progress in improving the rating-predictor model. One reason was that I did not see any obvious useful features that could be engineered. However, once I found my way to the idea of predicting the fictionality of the books, the target drove the direction I took with my feature engineering. It was a great learning experience for me in engineering features toward the specific target that the model is trying to predict.\n",
    "\n",
    "Here are the feature ideas I came up with and engineered (all in short succession once the new target was chosen):\n",
    "\n",
    "- [x] Title begins with \"The\"\n",
    "- [x] Has subtitle: contains \":\"\n",
    "- [x] Title character count\n",
    "- [x] Title word count\n",
    "- [x] Title longest word\n",
    "- [x] Author number of names\n",
    "- [x] Author middle initial\n",
    "- [x] Ratings (stars) ratio (1 + 2 / 4 + 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7H71nRy8IT6z"
   },
   "outputs": [],
   "source": [
    "def engineer_features(data):\n",
    "    \"\"\"Engineer a handful of new features.\"\"\"\n",
    "    # Create new feature that is if the title begins with \"The\"\n",
    "    data[\"the_title\"] = data[\"title\"].str.startswith(\"The\")\n",
    "    # New feature - has_subtitle\n",
    "    data[\"has_subtitle\"] = data[\"title\"].str.contains(\":\")\n",
    "    # New feature - title character length\n",
    "    data[\"title_char_count\"] = data[\"title\"].apply(lambda x: len(x))\n",
    "    # New feature - title word count\n",
    "    data[\"title_word_count\"] = data[\"title\"].apply(lambda x: len(x.split()))\n",
    "    # New feature - title longest word\n",
    "    data[\"title_longest_word\"] = data[\"title\"].apply(lambda x: len(max(x.split(), key=len)))\n",
    "    # New feature - author number of names\n",
    "    data[\"author_name_count\"] = data[\"author\"].apply(lambda x: len(x.split()))\n",
    "    # New feature - author middle initial\n",
    "    pat = r\"\\w* (\\w. )+ \\w*\"\n",
    "    data[\"author_middle_initial\"] = data[\"author\"].str.contains(pat, regex=True)\n",
    "    # New feature - low/high rating ratio\n",
    "    data[\"rating_ratio\"] = (data[\"1_rating_count\"] + data[\"2_rating_count\"]) / (data[\"4_rating_count\"] + data[\"5_rating_count\"])\n",
    "    # Replace Boolean with binary\n",
    "    data = data.replace(to_replace={True: 1, False:0})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FMbgz_ncIT63"
   },
   "source": [
    "#### Same random forest with additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "7NetaoBmIT63",
    "outputId": "7eedd518-089b-4204-8928-bc5c498d0994"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tobias/.vega/vela-_qIiF1eP/lib/python3.7/site-packages/pandas/core/strings.py:1954: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default random forest eval metrics:\n",
      "  Accuracy: 0.7819420783645656\n",
      "  F1 score: 0.7939471989697361\n"
     ]
    }
   ],
   "source": [
    "# === Random forest model, new features === #\n",
    "X3_train = engineer_features(X_train)\n",
    "X3_val = engineer_features(X_val)\n",
    "X3_test = engineer_features(X_test)\n",
    "\n",
    "rf2_pipe = Pipeline([\n",
    "    (\"encoder\", ce.OrdinalEncoder()),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"rfc\", RandomForestClassifier(random_state=92)),\n",
    "])\n",
    "\n",
    "# Train default random forest\n",
    "rf2_pipe.fit(X3_train, y_train)\n",
    "\n",
    "# Made predictions to get validation accuracy\n",
    "y_pred_rf2 = rf2_pipe.predict(X3_val)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(\"Default random forest eval metrics:\")\n",
    "print(\"  Accuracy:\", accuracy_score(y_val, y_pred_rf2))\n",
    "print(\"  F1 score:\", f1_score(y_val, y_pred_rf2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ugp45Y9fIT67"
   },
   "source": [
    "Got an extra ~5% out of those new features!\n",
    "\n",
    "And that is with the default RandomForestClassifier hyperparameters and the SimpleImputer. For the next iteration, I will try using the IterativeImputer, then utilize RandomizedSearchCV to tune the hyperparameters and conduct cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UuMEKWgQ08rS"
   },
   "source": [
    "### Feature Importances\n",
    "\n",
    "It is likely that some of the features do not help the model make correct predictions. Indeed, some may even be worse than that: they could add noise that makes the model perform worse.\n",
    "\n",
    "To address this potential problem, I'm going to find the feature importances using a method called permutation importance. Basically, this method will go through each of the features, replacing their data with random noise generated from the distribution of the original data. The performance of the model will be evaluated and compared with the score using all of the original data to find the effect of each feature on the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-3jQF7VZ08rX"
   },
   "outputs": [],
   "source": [
    "# === Transformer pipeline === #\n",
    "# Use the same (fitted) steps from main pipeline\n",
    "transformers = Pipeline([\n",
    "    (\"encoder\", rf2_pipe.named_steps[\"encoder\"]),\n",
    "    (\"imputer\", rf2_pipe.named_steps[\"imputer\"]),\n",
    "])\n",
    "\n",
    "# Encode and impute\n",
    "X3_train_transformed = transformers.transform(X3_train)\n",
    "X3_val_transformed = transformers.transform(X3_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "colab_type": "code",
    "id": "ajoeqOPJ1U4L",
    "outputId": "28c524ee-ef0b-4e37-9045-cf64ab48d8b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PermutationImportance(estimator=RandomForestClassifier(random_state=92),\n",
       "                      random_state=42, scoring='f1')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Instantiate and fit the permuter === #\n",
    "permuter = PermutationImportance(\n",
    "    rf2_pipe.named_steps[\"rfc\"], \n",
    "    scoring='f1', \n",
    "    n_iter=5, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "permuter.fit(X3_val_transformed, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "colab_type": "code",
    "id": "sTccpQkRYaLW",
    "outputId": "d0f5587c-bb3c-4ae0-8b83-2f16242f3b29"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0474\n",
       "                \n",
       "                    &plusmn; 0.0070\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                has_subtitle\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.72%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0264\n",
       "                \n",
       "                    &plusmn; 0.0104\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                publish_year\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 87.80%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0234\n",
       "                \n",
       "                    &plusmn; 0.0021\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                avg_rating\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.42%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0166\n",
       "                \n",
       "                    &plusmn; 0.0020\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                3_rating_count\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.63%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0160\n",
       "                \n",
       "                    &plusmn; 0.0023\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                series\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.27%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0145\n",
       "                \n",
       "                    &plusmn; 0.0054\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                4_rating_count\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.60%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0137\n",
       "                \n",
       "                    &plusmn; 0.0066\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                title_char_count\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.69%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0135\n",
       "                \n",
       "                    &plusmn; 0.0047\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                num_ratings\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.98%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0129\n",
       "                \n",
       "                    &plusmn; 0.0058\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                1_rating_count\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.60%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0115\n",
       "                \n",
       "                    &plusmn; 0.0033\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                num_pages\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.90%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0087\n",
       "                \n",
       "                    &plusmn; 0.0059\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                num_reviews\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.92%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0086\n",
       "                \n",
       "                    &plusmn; 0.0037\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                5_rating_count\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.12%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0083\n",
       "                \n",
       "                    &plusmn; 0.0048\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                author\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0081\n",
       "                \n",
       "                    &plusmn; 0.0035\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                2_rating_count\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.16%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0063\n",
       "                \n",
       "                    &plusmn; 0.0039\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                rating_ratio\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.97%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0032\n",
       "                \n",
       "                    &plusmn; 0.0028\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                title_word_count\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.26%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0028\n",
       "                \n",
       "                    &plusmn; 0.0026\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                republish\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.11%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0016\n",
       "                \n",
       "                    &plusmn; 0.0050\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                the_title\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.83%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0008\n",
       "                \n",
       "                    &plusmn; 0.0013\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                language\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.85%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0008\n",
       "                \n",
       "                    &plusmn; 0.0045\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                publish_day\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.56%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0002\n",
       "                \n",
       "                    &plusmn; 0.0017\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                author_name_count\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.74%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0001\n",
       "                \n",
       "                    &plusmn; 0.0005\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                title\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                author_middle_initial\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 99.51%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0002\n",
       "                \n",
       "                    &plusmn; 0.0043\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                publish_month\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Get permutation importances === #\n",
    "feature_names = X3_val.columns.tolist()\n",
    "pd.Series(permuter.feature_importances_, feature_names).sort_values(ascending=False)\n",
    "\n",
    "eli5.show_weights(\n",
    "    permuter, \n",
    "    top=None, # Show permutation importances for all features\n",
    "    feature_names=feature_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above table, I should see either no change or a small increase in the model's performance by removing `publish_month` and `author_middle_initial`. I'm going to try removing those and training the model again.\n",
    "\n",
    "As for the rest of the features, I find it interesting to see what features have the largest positive effect on the model's predictive power. From this table, I can see that the majority of the benefit I got from engineering the new features came from the `has_subtitle` feature. This feature, according to the permutation importance table, is the most important predictor by quite a long shot and accounted for 0.04 simply indicates whether the title of the book has a colon in it. My intuition was that having a subtitle is very common for nonfiction books, not so much for fiction.\n",
    "\n",
    "One other engineered feature that seems to be a good predictor is `title_char_count`, or title character count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default random forest eval metrics:\n",
      "  Accuracy: 0.7805792163543441\n",
      "  F1 score: 0.7933247753530167\n"
     ]
    }
   ],
   "source": [
    "# === Random forest model, new features === #\n",
    "more_drop_cols = [\n",
    "    \"author_middle_initial\",\n",
    "    \"publish_month\",\n",
    "]\n",
    "\n",
    "# New features are already engineered\n",
    "X4_train = X3_train.drop(columns=more_drop_cols)\n",
    "X4_val   = X3_val.drop(columns=more_drop_cols)\n",
    "X4_test  = X3_test.drop(columns=more_drop_cols)\n",
    "\n",
    "rf3_pipe = Pipeline([\n",
    "    (\"encoder\", ce.OrdinalEncoder()),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"rfc\", RandomForestClassifier(random_state=92)),\n",
    "])\n",
    "\n",
    "# Train default random forest\n",
    "rf3_pipe.fit(X4_train, y_train)\n",
    "\n",
    "# Made predictions to get validation accuracy\n",
    "y_pred_rf3 = rf3_pipe.predict(X4_val)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(\"Default random forest eval metrics:\")\n",
    "print(\"  Accuracy:\", accuracy_score(y_val, y_pred_rf3))\n",
    "print(\"  F1 score:\", f1_score(y_val, y_pred_rf3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that removing the features indicated to have negative or no feature importance actually had a small negative effect on the model's performance. That result in hand, I'm going to leave those features in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default random forest eval metrics:\n",
      "  Accuracy: 0.7653311529026983\n",
      "  F1 score: 0.7773467804499612\n"
     ]
    }
   ],
   "source": [
    "# === How does it perform on the test data? === #\n",
    "y_pred_test_rf2 = rf2_pipe.predict(X3_test)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(\"Default random forest eval metrics:\")\n",
    "print(\"  Accuracy:\", accuracy_score(y_test, y_pred_test_rf2))\n",
    "print(\"  F1 score:\", f1_score(y_test, y_pred_test_rf2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jDCfJc9CIT68"
   },
   "source": [
    "### Cross-validation and hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "z-kOYJMtIT68",
    "outputId": "40e6ca0b-0954-48b3-d28f-87b288762442"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tobias/.vega/vela-_qIiF1eP/lib/python3.7/site-packages/pandas/core/strings.py:1954: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# === Engineer the new features === #\n",
    "# Start from original dataset, because data\n",
    "# will only be split into train and test\n",
    "books2 = engineer_features(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "ZBSTSbgCIT7B",
    "outputId": "67743040-d120-4515-ef48-cef5915a9a62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18344, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>language</th>\n",
       "      <th>series</th>\n",
       "      <th>1_rating_count</th>\n",
       "      <th>2_rating_count</th>\n",
       "      <th>3_rating_count</th>\n",
       "      <th>4_rating_count</th>\n",
       "      <th>5_rating_count</th>\n",
       "      <th>publish_year</th>\n",
       "      <th>publish_month</th>\n",
       "      <th>publish_day</th>\n",
       "      <th>fiction</th>\n",
       "      <th>republish</th>\n",
       "      <th>the_title</th>\n",
       "      <th>has_subtitle</th>\n",
       "      <th>title_char_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>author_name_count</th>\n",
       "      <th>author_middle_initial</th>\n",
       "      <th>rating_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Book of Mormon: Another Testament of Jesus...</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>71355.0</td>\n",
       "      <td>5704.0</td>\n",
       "      <td>4.37</td>\n",
       "      <td>531.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>7520.0</td>\n",
       "      <td>2697.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>56654.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.174301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Prince</td>\n",
       "      <td>Niccol√≤ Machiavelli</td>\n",
       "      <td>229715.0</td>\n",
       "      <td>7261.0</td>\n",
       "      <td>3.81</td>\n",
       "      <td>140.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>5254.0</td>\n",
       "      <td>16827.0</td>\n",
       "      <td>61182.0</td>\n",
       "      <td>80221.0</td>\n",
       "      <td>66231.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title               author  \\\n",
       "0  The Book of Mormon: Another Testament of Jesus...            Anonymous   \n",
       "1                                         The Prince  Niccol√≤ Machiavelli   \n",
       "\n",
       "   num_ratings  num_reviews  avg_rating  num_pages language  series  \\\n",
       "0      71355.0       5704.0        4.37      531.0  English       0   \n",
       "1     229715.0       7261.0        3.81      140.0  English       0   \n",
       "\n",
       "   1_rating_count  2_rating_count  3_rating_count  4_rating_count  \\\n",
       "0          7520.0          2697.0          2521.0          1963.0   \n",
       "1          5254.0         16827.0         61182.0         80221.0   \n",
       "\n",
       "   5_rating_count  publish_year  publish_month  publish_day  fiction  \\\n",
       "0         56654.0        2013.0           10.0         22.0        0   \n",
       "1         66231.0        2003.0            6.0          1.0        0   \n",
       "\n",
       "   republish  the_title  has_subtitle  title_char_count  title_word_count  \\\n",
       "0          1          1             1                53                 9   \n",
       "1          1          1             0                10                 2   \n",
       "\n",
       "   author_name_count  author_middle_initial  rating_ratio  \n",
       "0                  1                      0      0.174301  \n",
       "1                  2                      0      0.150773  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Take a look === #\n",
    "print(books2.shape)\n",
    "books2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "sBErEAJ-IT7F",
    "outputId": "300deed8-2951-4c7a-a8b2-87519f083375"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14675, 25), (3669, 25))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Split data into train / test === #\n",
    "train, test = train_test_split(books2, stratify=books2[\"fiction\"], test_size=0.2, random_state=92)\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Id90Q2BwIT7M",
    "outputId": "c5112a16-4bc8-406e-cd06-1783d6b2f547"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14675,) (3669,)\n",
      "(14675, 19) (3669, 19)\n"
     ]
    }
   ],
   "source": [
    "# === Set up target and features === #\n",
    "# No val this time bc using cross-validation\n",
    "target = \"fiction\"\n",
    "\n",
    "drop_cols = [  # Columns not useful to model\n",
    "    \"title\",\n",
    "    \"author\",\n",
    "    \"language\",\n",
    "    \"publish_month\",\n",
    "    \"publish_day\",\n",
    "]\n",
    "\n",
    "# Arrange y vector\n",
    "y_train = train[target]\n",
    "y_test = test[target]\n",
    "\n",
    "print(y_train.shape, y_test.shape)\n",
    "\n",
    "# Arrange X matrices\n",
    "X_train = train.drop(columns=[target] + drop_cols)\n",
    "X_test = test.drop(columns=[target] + drop_cols)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "cKyaHruHIT7P",
    "outputId": "99b35f01-6d49-4883-c5c5-338da999a464"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  25 | elapsed:   16.7s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:   17.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters {'imputer__imputation_order': 'random', 'imputer__initial_strategy': 'median', 'imputer__max_iter': 19, 'imputer__n_nearest_features': 4, 'imputer__tol': 0.02223640657375538, 'rfc__max_depth': 21, 'rfc__min_samples_split': 0.00799211859966853, 'rfc__n_estimators': 205}\n",
      "F1 score 0.7874357962768823\n"
     ]
    }
   ],
   "source": [
    "# === Random forest, Part 3 === #\n",
    "# Tune hyperparameters using cross-validation\n",
    "\n",
    "rf3_pipe = Pipeline([\n",
    "    (\"encoder\", ce.OrdinalEncoder()),\n",
    "    (\"imputer\", IterativeImputer(random_state=92)),\n",
    "    (\"rfc\", RandomForestClassifier(random_state=92)),\n",
    "])\n",
    "\n",
    "rf3_params = {\n",
    "    \"imputer__initial_strategy\": [\"median\", \"most_frequent\"], \n",
    "    \"imputer__max_iter\": randint(16, 40),\n",
    "    \"imputer__tol\": uniform(0.001, 0.05),\n",
    "    \"imputer__n_nearest_features\": randint(2, 10),\n",
    "    \"imputer__imputation_order\": [\"ascending\", \"roman\", \"random\"],\n",
    "    \"rfc__n_estimators\": randint(80, 300), \n",
    "    \"rfc__max_depth\": randint(6, 32),\n",
    "    \"rfc__min_samples_split\": uniform(0, 1), \n",
    "}\n",
    "\n",
    "# Define the search using parameter distros above\n",
    "rf3_search = RandomizedSearchCV(\n",
    "    rf3_pipe, \n",
    "    param_distributions=rf3_params, \n",
    "    n_iter=5,\n",
    "    cv=5, \n",
    "    scoring='f1',\n",
    "    verbose=10, \n",
    "    return_train_score=True, \n",
    "    n_jobs=-1,\n",
    "    random_state=92,\n",
    ")\n",
    "\n",
    "# Train default random forest\n",
    "rf3_search.fit(X_train, y_train)\n",
    "\n",
    "# Best combination of hyperparameters and their resulting f1 score\n",
    "print(\"Best hyperparameters\", rf3_search.best_params_)\n",
    "print(\"F1 score\", rf3_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1mdZBVeRIT7U"
   },
   "source": [
    "That score is actually not as good as the default random forest was, without cross-validation. It could also be that the best estimator from this search would outperform the previous one when predicting the test data. Or, it could be that the parameters and their ranges I'm searching are not optimal.\n",
    "\n",
    "Another reason could be that I simply did not provide enough of a search window. That is, I could try increasing the number of iterations that the search goes through while testing out parameter combinations.\n",
    "\n",
    "That score is still pretty close though. I'm going to try out some other algorithms now, starting with nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QRvblD9KIT7V"
   },
   "source": [
    "#### Nearest Neighbors\n",
    "\n",
    "Nearest neighbors model with KNeighborsClassifier algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "cJ-rTHI9IT7V",
    "outputId": "5d8555f3-a0a8-4142-cc97-5ef763fc70f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  25 | elapsed:   15.1s remaining:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:   16.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters {'imputer__imputation_order': 'ascending', 'imputer__initial_strategy': 'most_frequent', 'imputer__max_iter': 17, 'imputer__n_nearest_features': 8, 'imputer__tol': 0.040172486631023935, 'nn__algorithm': 'ball_tree', 'nn__leaf_size': 29, 'nn__n_neighbors': 15, 'nn__weights': 'uniform'}\n",
      "F1 score 0.6971155846391321\n"
     ]
    }
   ],
   "source": [
    "# === Nearest Neighbors === #\n",
    "\n",
    "nn_pipe = Pipeline([\n",
    "    (\"encoder\", ce.OrdinalEncoder()),\n",
    "    (\"imputer\", IterativeImputer(random_state=92)),\n",
    "    (\"nn\", KNeighborsClassifier()),\n",
    "])\n",
    "\n",
    "nn_params = {\n",
    "    \"imputer__initial_strategy\": [\"median\", \"most_frequent\"], \n",
    "    \"imputer__max_iter\": randint(16, 40),\n",
    "    \"imputer__tol\": uniform(0.001, 0.05),\n",
    "    \"imputer__n_nearest_features\": randint(2, 10),\n",
    "    \"imputer__imputation_order\": [\"ascending\", \"roman\", \"random\"],\n",
    "    \"nn__n_neighbors\": randint(2, 20), \n",
    "    \"nn__weights\": [\"uniform\", \"distance\"],\n",
    "    \"nn__algorithm\": [\"ball_tree\", \"kd_tree\"],\n",
    "    \"nn__leaf_size\": randint(20, 50),\n",
    "}\n",
    "\n",
    "# Define the search using parameter distros above\n",
    "nn_search = RandomizedSearchCV(\n",
    "    nn_pipe, \n",
    "    param_distributions=nn_params, \n",
    "    n_iter=5,\n",
    "    cv=5, \n",
    "    scoring=\"f1\",\n",
    "    verbose=10, \n",
    "    return_train_score=True, \n",
    "    n_jobs=-1,\n",
    "    random_state=92,\n",
    ")\n",
    "\n",
    "# Train default random forest\n",
    "nn_search.fit(X_train, y_train)\n",
    "\n",
    "# Best combination of hyperparameters and their resulting f1 score\n",
    "print(\"Best hyperparameters\", nn_search.best_params_)\n",
    "print(\"F1 score\", nn_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QXBIGtq8IT7Y"
   },
   "source": [
    "It seems that Random Forest is quite a bit better of an algorithm for this problem than k-nearest neighbors. Therefore, I won't be moving forward with nearest neighbors.\n",
    "\n",
    "The last algorithm I'll try is a gradient-boosted decision tree classifier from XGBoost: `XGBClassifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5_kdsJbZKSND"
   },
   "source": [
    "#### Gradient Boosting\n",
    "\n",
    "Training a gradient-boosted decision tree using [XGBoost](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn).\n",
    "\n",
    "Though I don't have a record of every single iteration of the below classifier search, the method I used to tune is to basically look at the values of each parameter, and moved the search range to more closely fit around those values.\n",
    "\n",
    "I was surprised to find that my initial attempts at training the `XGBClassifier` had about the same performance as the default random forest with the newly-engineered features.\n",
    "\n",
    "As I mentioned above, one hypothesis of what was causing the discrepancy (or lack thereof: I assumed gradient-boosting would increase the performance, which maybe wasn't a sound assumption), could be the simple fact that the randomized search doesn't cover every possibility. To test this, I increased the number of iterations and let 'er rip!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "colab_type": "code",
    "id": "K7HKTPfwIT7Z",
    "outputId": "df0c183f-6322-4db0-dac3-02479ed67588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   20.2s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   39.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  5.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score 0.7942245127829319\n",
      "Best hyperparameters:\n",
      "imputer__imputation_order: ascending\n",
      "imputer__initial_strategy: median\n",
      "imputer__max_iter: 31\n",
      "imputer__n_nearest_features: 3\n",
      "imputer__tol: 0.03492326452711587\n",
      "xgb__learning_rate: 0.10726406674881385\n",
      "xgb__max_depth: 27\n",
      "xgb__n_estimators: 100\n"
     ]
    }
   ],
   "source": [
    "# === XGBoost Classifier === #\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb1_pipe = Pipeline([\n",
    "    (\"encoder\", ce.OrdinalEncoder()),\n",
    "    (\"imputer\", IterativeImputer(random_state=92)),\n",
    "    (\"xgb\", XGBClassifier(random_state=92)),\n",
    "])\n",
    "\n",
    "xgb1_params = {\n",
    "    \"imputer__initial_strategy\": [\"median\", \"most_frequent\"], \n",
    "    \"imputer__max_iter\": randint(16, 45),\n",
    "    \"imputer__tol\": uniform(0.02, 0.04),\n",
    "    \"imputer__n_nearest_features\": randint(2, 10),\n",
    "    \"imputer__imputation_order\": [\"ascending\", \"roman\", \"random\"],\n",
    "    \"xgb__n_estimators\": randint(80, 160), \n",
    "    \"xgb__max_depth\": randint(18, 48),\n",
    "    \"xgb__learning_rate\": uniform(0.05, .5),\n",
    "}\n",
    "\n",
    "# Define the search using parameter distros above\n",
    "xgb1_search = RandomizedSearchCV(\n",
    "    xgb1_pipe, \n",
    "    param_distributions=xgb1_params, \n",
    "    n_iter=10,\n",
    "    cv=4,\n",
    "    scoring=\"f1\",\n",
    "    verbose=10, \n",
    "    return_train_score=True, \n",
    "    n_jobs=-1,\n",
    "    random_state=92,\n",
    ")\n",
    "\n",
    "# Train default random forest\n",
    "xgb1_search.fit(X_train, y_train)\n",
    "\n",
    "# Best combination of hyperparameters and their resulting f1 score\n",
    "print(\"F1 score\", xgb1_search.best_score_)\n",
    "print(\"Best hyperparameters:\")\n",
    "for param, val in xgb1_search.best_params_.items():\n",
    "    print(  f\"{param}: {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FecTx0zMVKGG"
   },
   "source": [
    "#### More Random Forests\n",
    "\n",
    "Even with 40 total fits (4 cross-validation folds, 10 iterations) the gradient-boosted classifier did not really outperform the random forest by any significant margin.\n",
    "\n",
    "To continue testing the hypothesis that my initial number of iterations was too low for the search to converge on a good combination of hyperparameters, I'm going to train more random forests. This time, I'm going to try running the random search with a higher number of iterations. If that seems promising, I'm going to further tune the hyperparameters and look into any additional hyperparameters that might be good to include in the tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "4IMFloUxIT7g",
    "outputId": "c1dd6928-fdf6-4c24-8baa-86455ecc27f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   39.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   46.6s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:   59.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score 0.7908519538332393\n",
      "Best hyperparameters:\n",
      "imputer__imputation_order: ascending\n",
      "imputer__initial_strategy: median\n",
      "imputer__max_iter: 12\n",
      "imputer__tol: 0.029121541514263292\n",
      "rfc__max_depth: 12\n",
      "rfc__min_impurity_decrease: 0.00010629484293753989\n",
      "rfc__min_samples_split: 11\n",
      "rfc__n_estimators: 195\n"
     ]
    }
   ],
   "source": [
    "# === Random forest, Part 4 === #\n",
    "rf4_pipe = Pipeline([\n",
    "    (\"encoder\", ce.OrdinalEncoder()),\n",
    "    (\"imputer\", IterativeImputer(random_state=92, n_nearest_features=3)),\n",
    "    (\"rfc\", RandomForestClassifier(random_state=92)),\n",
    "])\n",
    "\n",
    "rf4_params = {\n",
    "    \"imputer__initial_strategy\": [\"median\", \"most_frequent\"], \n",
    "    \"imputer__max_iter\": randint(8, 20),\n",
    "    \"imputer__tol\": uniform(0.01, 0.04),\n",
    "    \"imputer__imputation_order\": [\"ascending\", \"roman\", \"random\"],\n",
    "    \"rfc__n_estimators\": randint(140, 200), \n",
    "    \"rfc__max_depth\": randint(6, 18),\n",
    "    \"rfc__min_samples_split\": randint(6, 14), \n",
    "    \"rfc__min_impurity_decrease\": uniform(0, .01), \n",
    "}\n",
    "\n",
    "# Define the search using parameter distros above\n",
    "rf4_search = RandomizedSearchCV(\n",
    "    rf4_pipe, \n",
    "    param_distributions=rf4_params, \n",
    "    n_iter=15,\n",
    "    cv=5, \n",
    "    scoring='f1',\n",
    "    verbose=10,\n",
    "    return_train_score=True, \n",
    "    n_jobs=-1,\n",
    "    random_state=92,\n",
    ")\n",
    "\n",
    "# Train default random forest\n",
    "rf4_search.fit(X_train, y_train)\n",
    "\n",
    "# Best combination of hyperparameters and their resulting f1 score\n",
    "print('F1 score', rf4_search.best_score_)\n",
    "print('Best hyperparameters:')\n",
    "for param, val in rf4_search.best_params_.items():\n",
    "    print(  f\"{param}: {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest 4 eval metrics:\n",
      "  Accuracy: 0.7623330607795039\n",
      "  F1 score: 0.7795753286147623\n"
     ]
    }
   ],
   "source": [
    "# === How does it perform on the test data? === #\n",
    "rf4 = rf4_search.best_estimator_\n",
    "\n",
    "y_pred_test_rf4 = rf4.predict(X_test)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(\"Random forest 4 eval metrics:\")\n",
    "print(\"  Accuracy:\", accuracy_score(y_test, y_pred_test_rf4))\n",
    "print(\"  F1 score:\", f1_score(y_test, y_pred_test_rf4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RwBBzF7x1In2"
   },
   "source": [
    "---\n",
    "\n",
    "## Results and Interpretation\n",
    "\n",
    "I tried many different combinations of different hyperparameters and the best F1 score I was able to achieve was just north of .79. Even with all of my tuning, I never beat the F1 score that was achieved with the random forest classifier using default hyperparameters.\n",
    "\n",
    "One final step to be taken before deployment is to inspect the predictions that the model made on the test set, looking at the predicted probabilities that resulted in each of the predictions. By looking at the predicted probabilities, I can look at instances when the model was sure or unsure of its predictions, and if those predictions were correct or not.\n",
    "\n",
    "This can provide some insight into the reasons for the model being incorrect, which could be valuable information to have, particularly when attempting to interpret (the results of) the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p8MrKRFRIT7o"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GujxCzg8IT7r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qCUPn-XuIT7w"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QGXwE6_OIT7z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cmVOAg53IT71"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "print_fiction_2-03_modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
