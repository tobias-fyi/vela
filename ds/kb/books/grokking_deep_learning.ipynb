{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grokking Deep Learning\n",
    "\n",
    "> Andrew Trask\n",
    "\n",
    "Notes by Tobias Reaper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Chapter 2: Fundamental Concepts\n",
    "\n",
    "* What are deep learning, machine learning, and artificial intelligence?\n",
    "* What are parametric models and nonparametric models?\n",
    "* What are supervised learning and unsupervised learning?\n",
    "* How can machines learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### What is deep learning?\n",
    "\n",
    "* Deep learning is a subset of machine learning\n",
    "  * Subset of methods in the ML toolbox primarily using ANNs\n",
    "\n",
    "#### What is machine learning?\n",
    "\n",
    "* Subfield of computer science\n",
    "* Deals with teaching machines to perform tasks for which they were not explicitly programmed\n",
    "* Machines observe a pattern and attempt to imitate it, either directly or indirectly\n",
    "  * i.e. supervised or unsupervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Supervised vs unsupervised\n",
    "\n",
    "### Supervised\n",
    "\n",
    "* Transform one dataset into another\n",
    "  * Input is what is known\n",
    "  * Output is what one wants to know\n",
    "  \n",
    "### Unsupervised\n",
    "\n",
    "* Also transforms one dataset into another\n",
    "* However, the output dataset is not previously known\n",
    "* No \"right answer\"\n",
    "  * Finding patterns in the data\n",
    "* Ex: clustering datapoints into cluster labels\n",
    "\n",
    "> In general, all forms of unsupervised learning are ~forms of clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Parametric vs nonparametric learning\n",
    "\n",
    "* Supervision ~ the type of pattern being learned\n",
    "* Parametricism ~ the way the learning is stored and the method for learning\n",
    "* Characterization by number of parameters\n",
    "  * Parametric model has a fixed number of parameters\n",
    "    * Tend to use trial and error\n",
    "  * Nonparametric model has potentially infinite number of parameters\n",
    "    * Tend to use counting\n",
    "    \n",
    "#### Supervised parametric learning\n",
    "\n",
    "* \"Trial and error learning using knobs\"\n",
    "  * Trial-and-error is a common property of parametric models (with exceptions)\n",
    "* Machines with a fixed number of knobs (parameters)\n",
    "  * Learning means turning the knobs\n",
    "* Input data is processed based on the settings of the knobs, transformed into a prediction\n",
    "* Steps\n",
    "  * 1. Predict\n",
    "  * 2. Compare to truth pattern\n",
    "  * 3. Learn the pattern\n",
    "  \n",
    "#### Unsupervised parametric learning\n",
    "\n",
    "* Uses knobs to group data\n",
    "  * Knobs in each group map the input's \"affinity\" to a particular group\n",
    "* Each group's machine transforms the input data to number 0-1\n",
    "  * Probability that the input is a member of that group\n",
    "\n",
    "#### Nonparametric learning\n",
    "\n",
    "* \"Counting-based methods\"\n",
    "* Number of parameters/knobs is based on the data, rather than predefined\n",
    "* There is some overlap / a blurry boundary between (non)parametric\n",
    "  * Because the number of parameters in parametric models will be influenced by the number of classes in the data\n",
    "* \"Parameters\" is a generic term\n",
    "  * Set of numbers used to model a pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Review and solifidy\n",
    "\n",
    "> Record myself explaining (ELI5) the following topics\n",
    "\n",
    "* [ ] Machine learning and deep learning\n",
    "* [ ] Supervised vs unsupervised learning\n",
    "* [ ] Parametric vs nonparametric learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Chapter 3: Forward Propogation\n",
    "\n",
    "* A simple network making a prediction\n",
    "* What is a neural network and what does it do?\n",
    "* Making a prediction with...\n",
    "  * Multiple inputs\n",
    "  * Multiple outputs\n",
    "  * Multiple inputs and outputs\n",
    "* Predicting on predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Step 1: Predict\n",
    "\n",
    "* Number of datapoints processed at a time does a lot to determine the structure of the NN\n",
    "* How many to process at a time?\n",
    "  * Can the neural network be accurate with the (batch of) data it's given?\n",
    "  * E.g. predicting on an image requires the entire image data, not just a single pixel\n",
    "  * Rule of thumb: always present \"enough\" (how much a human might need to make the same prediction)\n",
    "* Network defined by the shape of the input and output\n",
    "  * Start with a single datapoint making a single prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making a prediction with a single input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === First neural network === #\n",
    "weight = 0.1\n",
    "\n",
    "def neural_network(input, weight):\n",
    "    pred = input * weight\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9500000000000001"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_fingers = [9.5, 10, 15.5, 11]\n",
    "input = number_of_fingers[0]\n",
    "\n",
    "pred = neural_network(input, weight)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What does this NN do?\n",
    "\n",
    "* Multiplies the input by a weight\n",
    "  * Scales the input by a certain amount\n",
    "* Input variable = information\n",
    "* Weight variable = knowledge\n",
    "* Prediction = output\n",
    "\n",
    "> Though they might get more complex, this same underlying concept always applies.\n",
    "\n",
    "* Another way to look at it:\n",
    "  * Weight value is a measure of sensitivity b/w input and the net's prediction\n",
    "    * Large weights amplify the range of predictions\n",
    "    * Small weights \"understate\" or reduce range of preds\n",
    "  * \"Volume knob\"\n",
    "* Inputs, predictions can be negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making a prediction with multiple inputs\n",
    "\n",
    "* Combining intelligence from multiple datapoints\n",
    "  * Multiply each input by its own weight\n",
    "  * Sum the predictions (weighted sum)\n",
    "    * Dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_sum(a, b):\n",
    "    assert(len(a) == len(b))\n",
    "    output = 0\n",
    "    for i in range(len(a)):\n",
    "        output += (a[i] * b[i])\n",
    "    return output\n",
    "\n",
    "def neural_network(input, weights):\n",
    "    pred = w_sum(input, weights)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9800000000000001"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = [0.1, 0.2, 0]\n",
    "\n",
    "toes = [8.5, 9.5, 9.9, 9.0]\n",
    "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "\n",
    "input = [toes[0], wlrec[0], nfans[0]]\n",
    "\n",
    "pred = neural_network(input, weights)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vector math\n",
    "\n",
    "* Elementwise operation\n",
    "  * Mathematical operation between two vectors of equal length\n",
    "  * Pair up values according to their positions in their vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elementwise_multiplication(vec_a, vec_b):\n",
    "    assert len(vec_a) == len(vec_b)\n",
    "    vec_out = [0 for i in range(len(vec_a))]\n",
    "    for i in range(len(vec_a)):\n",
    "        vec_out[i] = vec_a[i] * vec_b[i]\n",
    "    return vec_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elementwise_addition(vec_a, vec_b):\n",
    "    assert len(vec_a) == len(vec_b)\n",
    "    vec_out = [0 for i in range(len(vec_a))]\n",
    "    for i in range(len(vec_a)):\n",
    "        vec_out[i] = vec_a[i] + vec_b[i]\n",
    "    return vec_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_sum(vec_a):\n",
    "    output = 0\n",
    "    for v in vec_a:\n",
    "        output += v\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_average(vec_a):\n",
    "    output = 0\n",
    "    for v in vec_a:\n",
    "        output += v\n",
    "    return output / len(vec_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(vec_a, vec_b):\n",
    "    vec_c = elementwise_multiplication(vec_a, vec_b)\n",
    "    return vector_sum(vec_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dot product intuition\n",
    "\n",
    "The intuition behind how and why a dot product (weighted sum) works is one of the most important parts of understanding how NNs make predictions.\n",
    "\n",
    "> A dot product gives you a notion of similarity between two vectors\n",
    "\n",
    "The highest dot product is between two identical vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does it mean when a neural network makes a prediction?\n",
    "\n",
    "> The network gives a high score of the inputs based on how similar they are to the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "# === Multiple inputs using numpy === #\n",
    "import numpy as np\n",
    "\n",
    "weights = np.array([0.1, 0.2, 0])\n",
    "def neural_network(input, weights):\n",
    "    pred = input.dot(weights)\n",
    "    return pred\n",
    "\n",
    "toes = np.array([8.5, 9.5, 9.9, 9.0])\n",
    "wlrec = np.array([0.65, 0.8, 0.8, 0.9])\n",
    "nfans = np.array([1.2, 1.3, 0.5, 1.0])\n",
    "\n",
    "input = np.array([toes[0], wlrec[0], nfans[0]])\n",
    "pred = neural_network(input, weights)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making a prediction with multiple outputs\n",
    "\n",
    "I.e. 3 disconnected single-weight networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.195, 0.13, 0.5850000000000001]\n"
     ]
    }
   ],
   "source": [
    "def ele_mul(number,vector):\n",
    "    output = [0] * len(vector)\n",
    "    assert(len(output) == len(vector))\n",
    "    for i in range(len(vector)):\n",
    "        output[i] = number * vector[i]\n",
    "    return output\n",
    "\n",
    "def neural_network(input, weights):\n",
    "    pred = ele_mul(input, weights)\n",
    "    return pred\n",
    "\n",
    "weights = [0.3, 0.2, 0.9]\n",
    "\n",
    "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
    "input = wlrec[0]\n",
    "pred = neural_network(input, weights)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple inputs and multiple outputs\n",
    "\n",
    "Three independent weighted sums of the input -> three predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.555, 0.9800000000000001, 0.9650000000000001]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def w_sum(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    output = 0\n",
    "    for i in range(len(a)):\n",
    "        output += (a[i] * b[i])\n",
    "    return output\n",
    "\n",
    "def vect_mat_mul(vect, matrix):\n",
    "    assert len(vect) == len(matrix)\n",
    "    output = [0] * len(vect)\n",
    "    for i in range(len(vect)):\n",
    "        output[i] = w_sum(vect, matrix[i])\n",
    "    return output\n",
    "\n",
    "def neural_network(input, weights):\n",
    "    pred = vect_mat_mul(input, weights)\n",
    "    return pred\n",
    "\n",
    "weights = [\n",
    "    [0.1, 0.1, -0.3], # hurt?\n",
    "    [0.1, 0.2, 0.0],  # win?\n",
    "    [0.0, 1.3, 0.1],  # sad?\n",
    "]\n",
    "\n",
    "toes = [8.5, 9.5, 9.9, 9.0]\n",
    "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "\n",
    "input = [toes[0], wlrec[0], nfans[0]]\n",
    "pred = neural_network(input, weights)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions on predictions\n",
    "\n",
    "Take the output of one network and use it as input to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.21350000000000002, 0.14500000000000002, 0.5065]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ih_wgt = [\n",
    "    [0.1, 0.2, -0.1], # hid[0]\n",
    "    [-0.1,0.1, 0.9],  # hid[1]\n",
    "    [0.1, 0.4, 0.1],  # hid[2]\n",
    "]\n",
    "\n",
    "hp_wgt = [\n",
    "    [0.3, 1.1, -0.3], # hurt?\n",
    "    [0.1, 0.2, 0.0],  # win?\n",
    "    [0.0, 1.3, 0.1],  # sad?\n",
    "]\n",
    "\n",
    "weights = [ih_wgt, hp_wgt]\n",
    "\n",
    "def neural_network(input, weights):\n",
    "    hid = vect_mat_mul(input, weights[0])\n",
    "    pred = vect_mat_mul(hid, weights[1])\n",
    "    return pred\n",
    "\n",
    "neural_network(input, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.496,  1.256, -0.286])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === numpy version === #\n",
    "import numpy as np\n",
    "\n",
    "ih_wgt = np.array([\n",
    "    [0.1, 0.2, -0.1], # hid[0]\n",
    "    [-0.1,0.1, 0.9],  # hid[1]\n",
    "    [0.1, 0.4, 0.1],  # hid[2]\n",
    "])\n",
    "\n",
    "hp_wgt = np.array([\n",
    "    [0.3, 1.1, -0.3], # hurt?\n",
    "    [0.1, 0.2, 0.0],  # win?\n",
    "    [0.0, 1.3, 0.1],  # sad?\n",
    "])\n",
    "\n",
    "weights = [ih_wgt, hp_wgt]\n",
    "\n",
    "input = np.array([toes[0], wlrec[0], nfans[0]])\n",
    "\n",
    "def neural_network(input, weights):\n",
    "    hid = input.dot(weights[0])\n",
    "    pred = hid.dot(weights[1])\n",
    "    return pred\n",
    "\n",
    "neural_network(input, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For dot product: put the (rows, columns) shapes next to each other - the inner ones should match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Chapter 3: Review and solifidy\n",
    "\n",
    "> Record myself explaining (ELI5) the following topics\n",
    "\n",
    "* [ ] What is a neural network and what does it do?\n",
    "* [ ] What is the intuition behind the dot product of two vectors?\n",
    "* [ ] What dimensions have to match when taking the dot product?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Chapter 4: Gradient Descent\n",
    "\n",
    "* Do neural networks make accurate predictions?\n",
    "* Why measure error?\n",
    "* Hot and cold learning\n",
    "* Calculating both direction and amount from error\n",
    "* Gradient descent\n",
    "* Learning is just reducing error\n",
    "* Derivatives and how to use them to learn\n",
    "* Divergence and alpha\n",
    "\n",
    "> Or, the \"compare\" and \"learn\" part of the \"predict, compare, and learn\" process.\n",
    "\n",
    "Compare provides a measurement of how far off a prediction was, while learning tells each weight how it can change to reduce the error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare\n",
    "\n",
    "Does your network make good predictions?\n",
    "\n",
    "* Measuring error simplifies the problem\n",
    "* Different ways of measuring error prioritize error differently\n",
    "  * Mean squared error amplifies large error and minimizes small error\n",
    "* Also ensures that the error is always positive (there can't be negative error!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30250000000000005\n"
     ]
    }
   ],
   "source": [
    "knob_weight = 0.5\n",
    "input = 0.5\n",
    "goal_pred = 0.8\n",
    "\n",
    "pred = input * knob_weight\n",
    "error = (pred - goal_pred) ** 2\n",
    "\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating both direction and amount from error\n",
    "\n",
    "AKA gradient descent!\n",
    "\n",
    "* Stopping: if `input` is 0 then `direction_and_amount` is also 0 - there's nothing to learn\n",
    "* Negative reversal: multiplying pure error by `input` will reverse the sign of `direction_and_amount` if `input` is negative\n",
    "  * Ensures `weight` moves in the right direction even if `input` is negative\n",
    "* Scaling: if `input` is large, so should be `weight`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.30250000000000005; Prediction: 0.25\n",
      "Error: 0.17015625000000004; Prediction: 0.3875\n",
      "Error: 0.095712890625; Prediction: 0.49062500000000003\n",
      "Error: 0.05383850097656251; Prediction: 0.56796875\n",
      "Error: 0.03028415679931642; Prediction: 0.6259765625\n",
      "Error: 0.0170348381996155; Prediction: 0.669482421875\n",
      "Error: 0.00958209648728372; Prediction: 0.70211181640625\n",
      "Error: 0.005389929274097089; Prediction: 0.7265838623046875\n",
      "Error: 0.0030318352166796153; Prediction: 0.7449378967285156\n",
      "Error: 0.0017054073093822882; Prediction: 0.7587034225463867\n",
      "Error: 0.0009592916115275371; Prediction: 0.76902756690979\n",
      "Error: 0.0005396015314842384; Prediction: 0.7767706751823426\n",
      "Error: 0.000303525861459885; Prediction: 0.7825780063867569\n",
      "Error: 0.00017073329707118678; Prediction: 0.7869335047900676\n",
      "Error: 9.603747960254256e-05; Prediction: 0.7902001285925507\n",
      "Error: 5.402108227642978e-05; Prediction: 0.7926500964444131\n",
      "Error: 3.038685878049206e-05; Prediction: 0.7944875723333098\n",
      "Error: 1.7092608064027242e-05; Prediction: 0.7958656792499823\n",
      "Error: 9.614592036015323e-06; Prediction: 0.7968992594374867\n",
      "Error: 5.408208020258491e-06; Prediction: 0.7976744445781151\n"
     ]
    }
   ],
   "source": [
    "weight = 0.5\n",
    "goal_pred = 0.8\n",
    "input = 0.5\n",
    "\n",
    "for iteration in range(20):\n",
    "    pred = input * weight\n",
    "    # `(pred - goal_pred)` is the pure error\n",
    "    error = (pred - goal_pred) ** 2\n",
    "    # input: scaling, negative reversal, and stopping\n",
    "    direction_and_amount = (pred - goal_pred) * input\n",
    "    # Recalculate weight\n",
    "    weight = weight - direction_and_amount\n",
    "    \n",
    "    print(f\"Error: {error}; Prediction: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.6400000000000001; Prediction: 0.0\n",
      "Error: 0.3600000000000001; Prediction: 0.2\n",
      "Error: 0.2025; Prediction: 0.35000000000000003\n",
      "Error: 0.11390625000000001; Prediction: 0.4625\n"
     ]
    }
   ],
   "source": [
    "# Perform weight update / gradient descent on single training example\n",
    "\n",
    "weight = 0.1\n",
    "alpha = 0.01\n",
    "\n",
    "def neural_network(input, weight):\n",
    "    prediction = input * weight\n",
    "    return prediction\n",
    "\n",
    "weight, goal_pred, input = (0.0, 0.8, 0.5)\n",
    "\n",
    "for iteration in range(4):\n",
    "    # Make prediction, calculate error and delta\n",
    "    pred = neural_network(input, weight)\n",
    "    error = (pred - goal_pred) ** 2\n",
    "    delta = pred - goal_pred\n",
    "    weight_delta = input * delta\n",
    "    weight = weight - weight_delta\n",
    "    print(f\"Error: {error}; Prediction: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is `weight_delta`, really?\n",
    "\n",
    "What is a function, and how can one be understood?\n",
    "\n",
    "* A function defines some sort of relationship between the input and output\n",
    "* Every function has moving parts that can be tweaked to change the output\n",
    "\n",
    "    error = ((input * weight) - goal_pred) ** 2\n",
    "\n",
    "`weight` is the only part of the function above that can be changed while still conforming to the patterns in the data\n",
    "\n",
    "> Key point: learning is adjusting `weight` to reduce `error` to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derivatives\n",
    "\n",
    "The derivative describes how one variable moves when another is changed. Or, it's the slope describing the relationship.\n",
    "\n",
    "This slope can be used to figure out how to force one to change in a specific direction by modifying the other.\n",
    "\n",
    "The important thing is to understand what the derivative represents.\n",
    "\n",
    "Again again again! — the relationship between two variables in a function, describing how much one changes in response to the other changing. It's the sensitivity between two variables.\n",
    "\n",
    "#### Using a derivative to learn\n",
    "\n",
    "> `weight_delta` is the derivative!\n",
    "\n",
    "To use the derivative in finding the minimum `error`, move (change `weight`) in the opposite direction of the slope (derivative).\n",
    "\n",
    "#### Divergence and alpha\n",
    "\n",
    "With big `input`, the prediction is very sensitive to changes in `weight`. Small changes in `weight` will lead to massive swings in the prediction.\n",
    "\n",
    "This can be combatted using alpha, or the learning rate. I.e. multiply the `weight_delta` by a fraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:0.03999999999999998 Prediction:1.0\n",
      "Error:0.0144 Prediction:0.92\n",
      "Error:0.005183999999999993 Prediction:0.872\n",
      "Error:0.0018662400000000014 Prediction:0.8432000000000001\n",
      "Error:0.0006718464000000028 Prediction:0.8259200000000001\n",
      "Error:0.00024186470400000033 Prediction:0.815552\n",
      "Error:8.70712934399997e-05 Prediction:0.8093312\n",
      "Error:3.134566563839939e-05 Prediction:0.80559872\n",
      "Error:1.1284439629823931e-05 Prediction:0.803359232\n",
      "Error:4.062398266736526e-06 Prediction:0.8020155392\n",
      "Error:1.4624633760252567e-06 Prediction:0.8012093235200001\n",
      "Error:5.264868153690924e-07 Prediction:0.8007255941120001\n",
      "Error:1.8953525353291194e-07 Prediction:0.8004353564672001\n",
      "Error:6.82326912718715e-08 Prediction:0.8002612138803201\n",
      "Error:2.456376885786678e-08 Prediction:0.8001567283281921\n",
      "Error:8.842956788836216e-09 Prediction:0.8000940369969153\n",
      "Error:3.1834644439835434e-09 Prediction:0.8000564221981492\n",
      "Error:1.1460471998340758e-09 Prediction:0.8000338533188895\n",
      "Error:4.125769919393652e-10 Prediction:0.8000203119913337\n",
      "Error:1.485277170987127e-10 Prediction:0.8000121871948003\n"
     ]
    }
   ],
   "source": [
    "weight = 0.5\n",
    "goal_pred = 0.8\n",
    "# Earlier implementation would break with this input\n",
    "# but this one doesn't, thanks to our friend alpha!\n",
    "input = 2\n",
    "alpha = 0.1\n",
    "\n",
    "for iteration in range(20):\n",
    "    pred = input * weight\n",
    "    error = (pred - goal_pred) ** 2\n",
    "    derivative = input * (pred - goal_pred)\n",
    "    weight = weight - (alpha * derivative)\n",
    "    print(\"Error:\" + str(error) + \" Prediction:\" + str(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Chapter 4: Review and solifidy\n",
    "\n",
    "\n",
    "* [ ] Build the code for the above neural network implementation from scratch, without looking at notes\n",
    "  * Leave comments ELI5 every single line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Chapter 5: Generalizing Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('vela': pipenv)",
   "language": "python",
   "name": "python37664bitvelapipenvde09592071074af6a70ce3b1ce38af95"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
