{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Savor Data\n",
    "\n",
    "> Taking advantage of my own big data.\n",
    "\n",
    "A data-driven project by [Tobias Reaper](https://github.com/tobias-fyi/)\n",
    "\n",
    "## Part 3: EDA and Visualization\n",
    "\n",
    "* Connect to the Savor data in local Postgres instance\n",
    "    * Until db is set up, load from CSV\n",
    "* Initial exploration and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Intro\n",
    "\n",
    "> Take advantage of your own big data.\n",
    "\n",
    "Savor is a project based on an idea that I first had in 2016. At the time I was working as a consultant for an enterprise resource planning (ERP) software company. I worked intimately with manufacturers to integrate our system into their business, with the goal of optimizing their manufacturing processes. I became fascinated by the idea of tracking things to such a degree, and began to imagine what it would be like to have a similar type of system that would optimize my life.\n",
    "\n",
    "That's the core idea: building a system to organize my life as if it were a series of manufacturing processes.\n",
    "\n",
    "That way of saying it may initially make it seem impersonal. I believe it's the opposite, in fact. The goal is to use software to understand myself better. That's where the tagline comes from — I'd like to take advantage of my own big data to make my life better in whatever ways I see fit at any given time.\n",
    "\n",
    "Companies like Google and Facebook have been taking advantage of my big data for years, with the primary goal of making money. In the process of segmenting and profiling me, they likely know a lot about me. I'd like to have a similar data-driven profile of my life, for my own purposes. Namely, to learn more about myself and my life, to be able to optimize it.\n",
    "\n",
    "I guess it's at this point that I can see people rolling their eyes and thinking this is just another productivity app. Words like \"optimize\" don't help things. However, I want to get across the fact that because I have total control over this system, that I get to choose exactly how it gets used and precisely what is optimized. While sometimes this optimization would come in the form of making myself more productive, it's equally likely that I'll want to optimize the length of time and quality of connection I have with family and friends.\n",
    "\n",
    "Imagine that: a system that can help you find time to spend with family and friends, and find mindsets and/or conversation topics that will most likely increase the quality of those connections.\n",
    "\n",
    "I think that sounds like the opposite of impersonal — getting intimate with oneself on levels and to a degree potentially not possible before.\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Model\n",
    "\n",
    "The latest data model I came up with for my journal is one that has 3 distinct layers (with more to come in proceeding iterations).\n",
    "\n",
    "1. Project Log\n",
    "2. Engagement Log\n",
    "3. Moment Log\n",
    "\n",
    "The naming was not completely arbitrary, though could definitely be improved — the names aren't perfectly self-explanatory.\n",
    "\n",
    "Basically, the reason I broke it up has to do with something I noticed about how my time is spent. At the top level, I try to work on a single \"project\" for a certain period of time. This helps me stay focused on what I wanted to do/work on during that time. Another way to think about it is that this level defines overarching parts of the day, usually somewhere between 5 and 10, depending on what I'm doing.\n",
    "\n",
    "Within each block of time (maybe that's a better name right there — \"block\") I can switch between specific activities, such as between coding, writing, and reading/research. That is the second level, with each individual activity assigned to that higher level block. This second level is where the vast majority of the action is; the level where I spend most of my time.\n",
    "\n",
    "The third level is for very short activities I do that aren't necessarily related to the main activity. For example, I could be working on the notebook to explore this data but take short little breaks to get water, use the restroom, or clear my head. In the previous iteration of the data model I didn't account for these little activities — every activity was \"created equal\", so to speak, and in order to account for that time, I'd have to split up and duplicate the main activity record, interspersing the short breaks into them that way. Simply put, that caused too much overhead sometimes.\n",
    "\n",
    "The goal with this project is to reduce the time and effort required to keep a real-time journal to the point where it doesn't interrupt what I'm actually doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook in context\n",
    "\n",
    "I wanted to explain about the project and how the data is set up to give some context. The last bit of context for now is how this notebook fits into the project.\n",
    "\n",
    "> This notebook will focus primarily on exploring the `engage_log` table. The primary features I'll be exploring in this notebook are:\n",
    "\n",
    "* `time_in`\n",
    "* `time_out`\n",
    "* `duration`\n",
    "* `mental`\n",
    "* `physical`\n",
    "* `mental_note`\n",
    "* `physical_note`\n",
    "* `subloc`\n",
    "* `project_location`\n",
    "\n",
    "There are many others that I could and will use, but I'll save those for another notebook.\n",
    "\n",
    "I am starting with this table because it is the experiential layer in which most of my experience is documented. The other layers are mostly there to support the `engage_log`, whether to provide a sort of group index (`project_log`) or to append additional information (`moment_log`).\n",
    "\n",
    "Let's get into it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "# === Some initial imports and config === #\n",
    "from os import environ\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pandas config\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "# Environment variables\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "env_path = Path.cwd().parents[0] / \".env\"\n",
    "load_dotenv(dotenv_path=env_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the data\n",
    "\n",
    "#### TODO: Load from Savor database\n",
    "\n",
    "Once the [previous notebook](02-savor_data_pipelines.ipynb) is done, the pipeline between Airtable and my local Postgres instance will make it easy to keep my local Postgres up to date. Once that is the case, I'll load the data directly from there.\n",
    "\n",
    "#### Load data from CSV\n",
    "\n",
    "Until then, however, I'm going to use CSVs which I downloaded from Airtable via their browser GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from csv\n",
    "data_path = \"../assets/data_/20-09-07-engage_log.csv\"\n",
    "engage_1 = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Initial Wrangling\n",
    "\n",
    "* Pruning the dataset right away to only the columns I'm using in this analysis\n",
    "* Removing the single null value at the very end of the dataset (the record that hasn't ended yet)\n",
    "    * The rest are filled with empty strings\n",
    "* Fixing data types\n",
    "    * Datetimes\n",
    "    * `duration`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Initial shape: (12297, 23)\nAfter column pruning: (12297, 9)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            time_in          time_out duration   mental  physical  \\\n0  2019-12-03 06:00  2019-12-03 06:19    19:00  Podcast  Exercise   \n1  2019-12-03 06:19  2019-12-03 06:37    18:00  Podcast  Exercise   \n2  2019-12-03 06:37  2019-12-03 07:02    25:00  Podcast  Exercise   \n\n                                         mental_note  \\\n0  Full Stack Radio - Evan Yue \\\\ Vue 3.0 + new e...   \n1  Full Stack Radio with Evan Yue \\\\ Vue 3.0 - fi...   \n2  Django Chat \\\\ Caching - something to read up ...   \n\n                                       physical_note       subloc  \\\n0                               Cardio - elliptical    Elliptical   \n1                                   Cardio - stairs   Stairmaster   \n2  Weights - hip abduction in / out (machine) - k...     Machines   \n\n  project_location  \n0        24hr-Bel   \n1        24hr-Bel   \n2        24hr-Bel   ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time_in</th>\n      <th>time_out</th>\n      <th>duration</th>\n      <th>mental</th>\n      <th>physical</th>\n      <th>mental_note</th>\n      <th>physical_note</th>\n      <th>subloc</th>\n      <th>project_location</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2019-12-03 06:00</td>\n      <td>2019-12-03 06:19</td>\n      <td>19:00</td>\n      <td>Podcast</td>\n      <td>Exercise</td>\n      <td>Full Stack Radio - Evan Yue \\\\ Vue 3.0 + new e...</td>\n      <td>Cardio - elliptical</td>\n      <td>Elliptical</td>\n      <td>24hr-Bel</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2019-12-03 06:19</td>\n      <td>2019-12-03 06:37</td>\n      <td>18:00</td>\n      <td>Podcast</td>\n      <td>Exercise</td>\n      <td>Full Stack Radio with Evan Yue \\\\ Vue 3.0 - fi...</td>\n      <td>Cardio - stairs</td>\n      <td>Stairmaster</td>\n      <td>24hr-Bel</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2019-12-03 06:37</td>\n      <td>2019-12-03 07:02</td>\n      <td>25:00</td>\n      <td>Podcast</td>\n      <td>Exercise</td>\n      <td>Django Chat \\\\ Caching - something to read up ...</td>\n      <td>Weights - hip abduction in / out (machine) - k...</td>\n      <td>Machines</td>\n      <td>24hr-Bel</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# Clean up columns to only what's needed right now\n",
    "print(\"Initial shape:\", engage_1.shape)\n",
    "\n",
    "engage_keep_cols = [\n",
    "    \"time_in\",\n",
    "    \"time_out\",\n",
    "    \"duration\",\n",
    "    \"mental\",\n",
    "    \"physical\",\n",
    "    \"mental_note\",\n",
    "    \"physical_note\",\n",
    "    \"subloc\",\n",
    "    \"project_location\",\n",
    "]\n",
    "\n",
    "# Copy columns new dataframe\n",
    "engage_2 = engage_1[engage_keep_cols].copy()\n",
    "print(\"After column pruning:\", engage_2.shape)\n",
    "engage_2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "time_in             0\ntime_out            0\nduration            0\nmental              0\nphysical            0\nmental_note         0\nphysical_note       0\nsubloc              0\nproject_location    0\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# The null in time_out and duration is the current record - can be removed\n",
    "engage_3 = engage_2.dropna(axis=0, subset=[\"time_out\"])\n",
    "# Fill remaining nulls with empty string\n",
    "engage_3 = engage_3.fillna(value=\"\")\n",
    "# Confirm it worked\n",
    "engage_3.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "time_in             datetime64[ns]\ntime_out            datetime64[ns]\nduration                    object\nmental                      object\nphysical                    object\nmental_note                 object\nphysical_note               object\nsubloc                      object\nproject_location            object\ndtype: object"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# Fix datetime columns\n",
    "date_cols = [\n",
    "    \"time_in\",\n",
    "    \"time_out\",\n",
    "]\n",
    "\n",
    "for col in date_cols:\n",
    "    engage_3[col] = pd.to_datetime(engage_2[col])\n",
    "    \n",
    "engage_3.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert duration to minutes\n",
    "\n",
    "The `duration` feature was imported as a string, which makes sense given the format: `[hh:]mm:ss`. To convert this into minutes, I'll split on the colon and extract the hours and minutes, multiplying the hours by 60 and adding them to the minutes. I can leave out the seconds, as I did not capture the timestamps at that level of detail.\n",
    "\n",
    "Unfortunately, if the hour is not present in the record, it simply doesn't include that segment. Therefore, I had to write a custom function to both split and calculate the minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_calculate_mins(cell):\n",
    "    \"\"\"Splits up `duration` based on colon, accounting for missing hours.\n",
    "    Expects format: [hh:]mm:ss.\"\"\"\n",
    "    # Split up cell into component parts\n",
    "    segments = [int(s) for s in cell.split(\":\")]\n",
    "    # Check length - if more than 2, means hour is present\n",
    "    if len(segments) > 2:\n",
    "        # Calculate mins from hours and sum\n",
    "        return (segments[0] * 60) + segments[1]\n",
    "    elif len(segments) == 2:  # Case with mins:secs\n",
    "        # Simply return the minutes\n",
    "        return segments[0]\n",
    "    else:  # Catch edge case when no duration\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "              time_in            time_out  duration   mental  physical  \\\n0 2019-12-03 06:00:00 2019-12-03 06:19:00        19  Podcast  Exercise   \n1 2019-12-03 06:19:00 2019-12-03 06:37:00        18  Podcast  Exercise   \n2 2019-12-03 06:37:00 2019-12-03 07:02:00        25  Podcast  Exercise   \n3 2019-12-03 07:02:00 2019-12-03 07:08:00         6  Podcast      Walk   \n4 2019-12-03 07:08:00 2019-12-03 07:20:00        12  Podcast     Drive   \n\n                                         mental_note  \\\n0  Full Stack Radio - Evan Yue \\\\ Vue 3.0 + new e...   \n1  Full Stack Radio with Evan Yue \\\\ Vue 3.0 - fi...   \n2  Django Chat \\\\ Caching - something to read up ...   \n3  Not so standard deviations \\\\ misc discussions...   \n4                                  SE Daily \\\\ TIBCO   \n\n                                       physical_note       subloc  \\\n0                               Cardio - elliptical    Elliptical   \n1                                   Cardio - stairs   Stairmaster   \n2  Weights - hip abduction in / out (machine) - k...     Machines   \n3                  Walked to locker room then to car      Outside   \n4                                                         Trinity   \n\n  project_location  \n0        24hr-Bel   \n1        24hr-Bel   \n2        24hr-Bel   \n3        24hr-Bel   \n4        24hr-Bel   ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time_in</th>\n      <th>time_out</th>\n      <th>duration</th>\n      <th>mental</th>\n      <th>physical</th>\n      <th>mental_note</th>\n      <th>physical_note</th>\n      <th>subloc</th>\n      <th>project_location</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2019-12-03 06:00:00</td>\n      <td>2019-12-03 06:19:00</td>\n      <td>19</td>\n      <td>Podcast</td>\n      <td>Exercise</td>\n      <td>Full Stack Radio - Evan Yue \\\\ Vue 3.0 + new e...</td>\n      <td>Cardio - elliptical</td>\n      <td>Elliptical</td>\n      <td>24hr-Bel</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2019-12-03 06:19:00</td>\n      <td>2019-12-03 06:37:00</td>\n      <td>18</td>\n      <td>Podcast</td>\n      <td>Exercise</td>\n      <td>Full Stack Radio with Evan Yue \\\\ Vue 3.0 - fi...</td>\n      <td>Cardio - stairs</td>\n      <td>Stairmaster</td>\n      <td>24hr-Bel</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2019-12-03 06:37:00</td>\n      <td>2019-12-03 07:02:00</td>\n      <td>25</td>\n      <td>Podcast</td>\n      <td>Exercise</td>\n      <td>Django Chat \\\\ Caching - something to read up ...</td>\n      <td>Weights - hip abduction in / out (machine) - k...</td>\n      <td>Machines</td>\n      <td>24hr-Bel</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2019-12-03 07:02:00</td>\n      <td>2019-12-03 07:08:00</td>\n      <td>6</td>\n      <td>Podcast</td>\n      <td>Walk</td>\n      <td>Not so standard deviations \\\\ misc discussions...</td>\n      <td>Walked to locker room then to car</td>\n      <td>Outside</td>\n      <td>24hr-Bel</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2019-12-03 07:08:00</td>\n      <td>2019-12-03 07:20:00</td>\n      <td>12</td>\n      <td>Podcast</td>\n      <td>Drive</td>\n      <td>SE Daily \\\\ TIBCO</td>\n      <td></td>\n      <td>Trinity</td>\n      <td>24hr-Bel</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# Use apply to calculate new duration\n",
    "engage_3[\"duration\"] = engage_3[\"duration\"].apply(split_and_calculate_mins)\n",
    "engage_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "time_in             datetime64[ns]\ntime_out            datetime64[ns]\nduration                     int64\nmental                      object\nphysical                    object\nmental_note                 object\nphysical_note               object\nsubloc                      object\nproject_location            object\ndtype: object"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "engage_3.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save modified dataset back to CSV, for posterity\n",
    "engage_3.to_csv(\"../assets/data_/20-09-07-engage_log_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Exploration and Visualization\n",
    "\n",
    "There are so, so many interesting questions to ask and avenues to explore with this data, it was almost overwhelming at first. I'd been brainstorming casually over the years on the topic of how to tackle the exploratory analysis and visualization.\n",
    "\n",
    "Here are a few ideas to get me started:\n",
    "\n",
    "* How do I spend my time?\n",
    "    * What patterns does this follow on a daily, weekly, monthly, yearly time horizon?\n",
    "* Sentiment analysis over time\n",
    "  * Does my mood oscillate according to any discernable pattern?\n",
    "  * Does my mood correlate with spending time on particular activities?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activities\n",
    "\n",
    "An obvious first question to explore is how I spend my time. I think it would be an interesting first step to calculate a monthly sum of the time I spent on each activity\n",
    "\n",
    "To do this, I'll of course need to group by month, then sum up the time spent on each activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "              time_in            time_out  duration   mental  physical\n0 2019-12-03 06:00:00 2019-12-03 06:19:00        19  Podcast  Exercise\n1 2019-12-03 06:19:00 2019-12-03 06:37:00        18  Podcast  Exercise\n2 2019-12-03 06:37:00 2019-12-03 07:02:00        25  Podcast  Exercise\n3 2019-12-03 07:02:00 2019-12-03 07:08:00         6  Podcast      Walk\n4 2019-12-03 07:08:00 2019-12-03 07:20:00        12  Podcast     Drive",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time_in</th>\n      <th>time_out</th>\n      <th>duration</th>\n      <th>mental</th>\n      <th>physical</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2019-12-03 06:00:00</td>\n      <td>2019-12-03 06:19:00</td>\n      <td>19</td>\n      <td>Podcast</td>\n      <td>Exercise</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2019-12-03 06:19:00</td>\n      <td>2019-12-03 06:37:00</td>\n      <td>18</td>\n      <td>Podcast</td>\n      <td>Exercise</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2019-12-03 06:37:00</td>\n      <td>2019-12-03 07:02:00</td>\n      <td>25</td>\n      <td>Podcast</td>\n      <td>Exercise</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2019-12-03 07:02:00</td>\n      <td>2019-12-03 07:08:00</td>\n      <td>6</td>\n      <td>Podcast</td>\n      <td>Walk</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2019-12-03 07:08:00</td>\n      <td>2019-12-03 07:20:00</td>\n      <td>12</td>\n      <td>Podcast</td>\n      <td>Drive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "# Make copy of dataframe to explore mental/physical activities\n",
    "act_1 = engage_3[[\"time_in\", \"time_out\", \"duration\", \"mental\", \"physical\"]].copy()\n",
    "act_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split up mental and physical\n",
    "\n",
    "Some records contain multiple mental and physical activities, which will need to be split up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "              time_in            time_out  duration  physical mental_0  \\\n0 2019-12-03 06:00:00 2019-12-03 06:19:00        19  Exercise  Podcast   \n1 2019-12-03 06:19:00 2019-12-03 06:37:00        18  Exercise  Podcast   \n2 2019-12-03 06:37:00 2019-12-03 07:02:00        25  Exercise  Podcast   \n3 2019-12-03 07:02:00 2019-12-03 07:08:00         6      Walk  Podcast   \n4 2019-12-03 07:08:00 2019-12-03 07:20:00        12     Drive  Podcast   \n\n  mental_1 mental_2 mental_3  \n0     None     None     None  \n1     None     None     None  \n2     None     None     None  \n3     None     None     None  \n4     None     None     None  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time_in</th>\n      <th>time_out</th>\n      <th>duration</th>\n      <th>physical</th>\n      <th>mental_0</th>\n      <th>mental_1</th>\n      <th>mental_2</th>\n      <th>mental_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2019-12-03 06:00:00</td>\n      <td>2019-12-03 06:19:00</td>\n      <td>19</td>\n      <td>Exercise</td>\n      <td>Podcast</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2019-12-03 06:19:00</td>\n      <td>2019-12-03 06:37:00</td>\n      <td>18</td>\n      <td>Exercise</td>\n      <td>Podcast</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2019-12-03 06:37:00</td>\n      <td>2019-12-03 07:02:00</td>\n      <td>25</td>\n      <td>Exercise</td>\n      <td>Podcast</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2019-12-03 07:02:00</td>\n      <td>2019-12-03 07:08:00</td>\n      <td>6</td>\n      <td>Walk</td>\n      <td>Podcast</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2019-12-03 07:08:00</td>\n      <td>2019-12-03 07:20:00</td>\n      <td>12</td>\n      <td>Drive</td>\n      <td>Podcast</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "# Split up mental\n",
    "mental_df = act_1[\"mental\"].str.split(\",\", expand=True)\n",
    "# Rename columns\n",
    "for i, col in enumerate(mental_df.columns):\n",
    "    mental_df = mental_df.rename(columns={i: f\"mental_{i}\"})\n",
    "# Concatenate back into main frame; drop original feature\n",
    "act_2 = pd.concat([act_1, mental_df], axis=1).drop(columns=[\"mental\"])\n",
    "act_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "              time_in            time_out  duration mental_0 mental_1  \\\n0 2019-12-03 06:00:00 2019-12-03 06:19:00        19  Podcast     None   \n1 2019-12-03 06:19:00 2019-12-03 06:37:00        18  Podcast     None   \n2 2019-12-03 06:37:00 2019-12-03 07:02:00        25  Podcast     None   \n3 2019-12-03 07:02:00 2019-12-03 07:08:00         6  Podcast     None   \n4 2019-12-03 07:08:00 2019-12-03 07:20:00        12  Podcast     None   \n\n  mental_2 mental_3 physical_0 physical_1 physical_2  \n0     None     None   Exercise       None       None  \n1     None     None   Exercise       None       None  \n2     None     None   Exercise       None       None  \n3     None     None       Walk       None       None  \n4     None     None      Drive       None       None  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time_in</th>\n      <th>time_out</th>\n      <th>duration</th>\n      <th>mental_0</th>\n      <th>mental_1</th>\n      <th>mental_2</th>\n      <th>mental_3</th>\n      <th>physical_0</th>\n      <th>physical_1</th>\n      <th>physical_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2019-12-03 06:00:00</td>\n      <td>2019-12-03 06:19:00</td>\n      <td>19</td>\n      <td>Podcast</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Exercise</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2019-12-03 06:19:00</td>\n      <td>2019-12-03 06:37:00</td>\n      <td>18</td>\n      <td>Podcast</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Exercise</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2019-12-03 06:37:00</td>\n      <td>2019-12-03 07:02:00</td>\n      <td>25</td>\n      <td>Podcast</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Exercise</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2019-12-03 07:02:00</td>\n      <td>2019-12-03 07:08:00</td>\n      <td>6</td>\n      <td>Podcast</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Walk</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2019-12-03 07:08:00</td>\n      <td>2019-12-03 07:20:00</td>\n      <td>12</td>\n      <td>Podcast</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Drive</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "# Split up physical\n",
    "physical_df = act_1[\"physical\"].str.split(\",\", expand=True)\n",
    "# Rename columns\n",
    "for i, col in enumerate(physical_df.columns):\n",
    "    physical_df = physical_df.rename(columns={i: f\"physical_{i}\"})\n",
    "# Concatenate back into main frame; drop original feature\n",
    "act_3 = pd.concat([act_2, physical_df], axis=1).drop(columns=[\"physical\"])\n",
    "act_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One place to start would be to just get a total sum of time spent on each activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Mental:\n  ('Sleep', 129453)\n  ('Converse', 72596)\n  ('Code', 49092)\n  ('Watch', 28160)\n  ('Podcast', 21496)\n  ('Audiobook', 21309)\n  ('Information', 21146)\n  ('Learn', 19914)\n  ('Think', 19283)\n  ('Write', 15077)\n\nPhysical:\n  ('Rest', 152607)\n  ('Sit', 86098)\n  ('Stand', 70127)\n  ('Drive', 13296)\n  ('Eat', 11113)\n  ('Cook', 8448)\n  ('Dress', 7028)\n  ('Dishes', 6124)\n  ('Exercise', 6086)\n  ('Dental hygiene', 5998)\n"
    }
   ],
   "source": [
    "# Get total sum of activities\n",
    "from collections import Counter\n",
    "\n",
    "# Create counter, loop thru records to sum\n",
    "mental_sums = Counter()\n",
    "physical_sums = Counter()\n",
    "\n",
    "# Iterate through all rows + lists within rows\n",
    "for row in act_1.itertuples(index=False):\n",
    "    # Split on comma, add time to each item\n",
    "    for w in row[3].split(\",\"):\n",
    "        mental_sums[w] += row[2]\n",
    "    for f in row[4].split(\",\"):\n",
    "        physical_sums[f] += row[2]\n",
    "    \n",
    "print(\"Mental:\")\n",
    "for mental in mental_sums.most_common(10):\n",
    "    print(f\"  {mental}\")\n",
    "print(\"\\nPhysical:\")\n",
    "for physical in physical_sums.most_common(10):\n",
    "    print(f\"  {physical}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Int64Index'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-4608bf7b32b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mact_3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time_in\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGrouper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"M\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-4.7.12/envs/savor_data/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   1721\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1723\u001b[0;31m         return SeriesGroupBy(\n\u001b[0m\u001b[1;32m   1724\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-4.7.12/envs/savor_data/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_grouper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             grouper, exclusions, obj = get_grouper(\n\u001b[0m\u001b[1;32m    526\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-4.7.12/envs/savor_data/lib/python3.8/site-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;31m# a passed-in Grouper, directly convert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m         \u001b[0mbinner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_grouper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-4.7.12/envs/savor_data/lib/python3.8/site-packages/pandas/core/resample.py\u001b[0m in \u001b[0;36m_get_grouper\u001b[0;34m(self, obj, validate)\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_grouper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0;31m# create the resampler and return our binner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_resampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_binner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-4.7.12/envs/savor_data/lib/python3.8/site-packages/pandas/core/resample.py\u001b[0m in \u001b[0;36m_get_resampler\u001b[0;34m(self, obj, kind)\u001b[0m\n\u001b[1;32m   1432\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mTimedeltaIndexResampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroupby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1434\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m   1435\u001b[0m             \u001b[0;34m\"Only valid with DatetimeIndex, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m             \u001b[0;34m\"TimedeltaIndex or PeriodIndex, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Int64Index'"
     ]
    }
   ],
   "source": [
    "act_3[\"time_in\"].groupby(pd.Grouper(freq=\"M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}