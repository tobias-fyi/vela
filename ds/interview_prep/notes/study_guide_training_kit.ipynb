{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study Guide: Training Kit\n",
    "\n",
    "Topics for DS interview prep, based on the Lambda Training Kit.\n",
    "\n",
    "Notes:\n",
    "\n",
    "* Not all topics are listedâ€”only the ones I think I should review\n",
    "  * Most topics are listed, as some I would like to review anyways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Unit 1: Statistics Fundamentals\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. Data Wrangling and Storytelling\n",
    "\n",
    "Exploratory Data Analysis (EDA)\n",
    "\n",
    "* Use basic Pandas functions for EDA\n",
    "* Generate basic graphs with Pandas\n",
    "\n",
    "Make Features\n",
    "\n",
    "* The purpose of feature engineering\n",
    "* Modify or create features using `df.apply()`\n",
    "* Work with dates and times in Pandas\n",
    "\n",
    "Join and Reshape Data\n",
    "\n",
    "* Concatenate and merge data with Pandas\n",
    "* Understand tidy data formatting\n",
    "* Melt and pivot data with Pandas\n",
    "\n",
    "Make Explanatory Visualizations\n",
    "\n",
    "* Identify misleading visualizations and fix them\n",
    "* Matplotlib\n",
    "  * Name the parts of a Matplotlib plot\n",
    "  * Differentiate between plt syntaxes\n",
    "  * Control basic visual aspects of plt plot to mimic popular plotting styles\n",
    "    * plot, plot stylesheet, title, subtitle\n",
    "    * axis labels, axis tick marks, background colors, text annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. Statistical Tests and Experiments\n",
    "\n",
    "Probability, Statistics, and Inference\n",
    "\n",
    "* Understand fundamental concepts of set theory and probability:\n",
    "  * Permutations\n",
    "  * Combinations\n",
    "  * Expected value\n",
    "  * Variance\n",
    "  * Binomial distribution\n",
    "  * Bernoulli trial\n",
    "* Explain how statistics can inform a practical and reliable understanding of data\n",
    "\n",
    "Sampling, Confidence Intervals, and Hypothesis Testing\n",
    "\n",
    "* Understand how sampling works\n",
    "  * Fundamental concept(s)\n",
    "    * Sample vs. population\n",
    "  * Common pitfalls\n",
    "* Use hypothesis testing to determine if a result is significant\n",
    "* Determine the level of confidence for a possible outcome\n",
    "\n",
    "Introduction to Bayesian Inference\n",
    "\n",
    "* Discuss differences between Bayesian and Frequentist statistics\n",
    "* Derive Bayes' theorem from the Law of Conditional Probability\n",
    "* Calculate Bayesian confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Linear Algebra\n",
    "\n",
    "Vectors and Matrices\n",
    "\n",
    "* Explain why linear algebra is important for data science\n",
    "* Vectors\n",
    "  * Graph them\n",
    "  * Identify dimensionality\n",
    "  * Calculate length\n",
    "  * Calculate dot product of two vectors\n",
    "* Matrices\n",
    "  * Identify dimensionality\n",
    "  * Multiply them\n",
    "  * Identify when matmul works\n",
    "  * Transpose\n",
    "  * Identify special matrices:\n",
    "    * Identity matrix\n",
    "    * Calculate the determinant and inverse\n",
    "* Use numpy to perform basic linear algebra operations\n",
    "\n",
    "Intermediate Linear Algebra\n",
    "\n",
    "* Visualize orthogonal projections in R^2\n",
    "* Understand the differences in standardization between variance, stdev, covariance, and correlation\n",
    "* Identify when two vectors or matrices are orthogonal\n",
    "  * Explain the intuitive implications of orthogonality\n",
    "* Unit vectors\n",
    "  * Rewrite any vector as a linear combination of scalars and unit vectors\n",
    "  * Explain what makes a vector a \"unit\" vector\n",
    "  * Know how to turn any vector into a unit vector\n",
    "* Identify linearly dependent vectors in both graphical and numeric representations\n",
    "* Calculate the rank of a matrix\n",
    "  * Use it to determine the span and basis of component vectors\n",
    "  \n",
    "Dimensionality Reduction Techniques\n",
    "\n",
    "* Recognize when `p > n` and explain why this leads to failure of certain ML models\n",
    "* Principal Component Analysis (PCA)\n",
    "  * Identify high-dimensionality data\n",
    "  * Use PCA to improve model performance\n",
    "* Understand limitations of projecting data onto an eigenvector subspace\n",
    "\n",
    "Clustering\n",
    "\n",
    "* Identify situations when unsupervised learning is necessary\n",
    "  * Select and apply appropriate clustering techniques\n",
    "* Use K-Means clustering and other centroid-based clustering algorithms\n",
    "* Articulate the \"No Free Lunch Principle\"\n",
    "  * Use it to guide the search for appropriate ML algorithm for a situation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Unit 1 Build Week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Unit 2: Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. Linear Models\n",
    "\n",
    "Regression 1\n",
    "\n",
    "* Begin with baselines for regression\n",
    "* Use scikit-learn for linear regression\n",
    "* Explain the coefficients from a linear regression\n",
    "\n",
    "Regression 2\n",
    "\n",
    "* Use scikit-learn for multiple regression\n",
    "* Understand how OLS minimizes SSE\n",
    "* Define overfitting/underfitting and the bias/variance tradeoff\n",
    "\n",
    "Ridge Regression\n",
    "\n",
    "* One-hot encoding of categorical features\n",
    "* Univariate feature selection\n",
    "* Explain intuition and interpretation of Ridge Regression\n",
    "* Use sklearn to fit and interpret Ridge Regression models\n",
    "\n",
    "Logistic Regression\n",
    "\n",
    "* Train/validate/test split\n",
    "* Begin with baselines for classification\n",
    "* Explain intuition and interpretation of Logistic Regression\n",
    "* Use sklearn to fit and interpret Logistic Regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. Kaggle Challenge\n",
    "\n",
    "Decision Trees\n",
    "\n",
    "* Clean data with outliers and missing values\n",
    "* Use scikit-learn pipelines\n",
    "* Use scikit-learn for decision trees\n",
    "* Get and interpret feature importances of a tree-based model\n",
    "* Understand why decision trees are useful to model non-linear, non-monotonic relationships and feature interactions\n",
    "\n",
    "Random Forests\n",
    "\n",
    "* Use scikit-learn for random forests\n",
    "* Ordinal encoding with high-cardinality categorical variables\n",
    "* Understand how categorical encodings affect trees differently than linear models\n",
    "* Understand how tree ensembles reduce overfitting compared to single tree with unlimited depth\n",
    "\n",
    "Cross-Validation\n",
    "\n",
    "* Do cross-validation with independent test set\n",
    "* Use scikit-learn for hyperparameter optimization\n",
    "\n",
    "Classification Metrics\n",
    "\n",
    "* Get and interpret a confusion matrix for classification models\n",
    "* Use classification metrics of precision and recall\n",
    "* Understand relationships between precision, recall, thresholds, and predicted probabilities\n",
    "* Use and understand the classification metric ROC AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Applied Modeling\n",
    "\n",
    "Define ML Problems\n",
    "\n",
    "* Choose a target to predict and check distribution\n",
    "* Choose an appropriate evaluation metric\n",
    "* Avoid leakage\n",
    "  * Test to train\n",
    "  * Target to features\n",
    "\n",
    "Wrangle ML Datasets\n",
    "\n",
    "* Explore and join tabular data for supervised machine learning\n",
    "\n",
    "Permutation and Boosting\n",
    "\n",
    "* Get permutation importances for model interpretation and feature selection\n",
    "* Use XGBoost for gradient boosting\n",
    "\n",
    "Model Interpretation\n",
    "\n",
    "* Visualize and interpret partial dependence plots\n",
    "* Explain individual predictions with Shapley values plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. Unit 2 Build: `print(fiction)`\n",
    "\n",
    "* Define a regression or classification problem, choose evaluation metrics, and begin with baselines\n",
    "* Fit and evaluate a linear model\n",
    "* Fit and evaluate a tree-based model\n",
    "* Communicate the modeling process and insights in writing\n",
    "* Make visualizations to explain predictive models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Unit 3: Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't really need to review anything in Unit 3!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Unit 4: Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. Natural Language Processing\n",
    "\n",
    "Introduction to NLP\n",
    "\n",
    "* Tokenize text\n",
    "* Remove stop words\n",
    "* Stem or lemmatize text\n",
    "\n",
    "Vector Representations\n",
    "\n",
    "* Represent a document as a vector\n",
    "* Query documents by similarity\n",
    "* Apply word embedding models to create document vectors\n",
    "\n",
    "Document Classification\n",
    "\n",
    "* Extract text features and use them in classification pipelines\n",
    "* Apply latent semantic indexing (LSI) to a document classification problem\n",
    "* Benchmark and compare various vectorization methods in doc classification tasks\n",
    "\n",
    "Topic Modeling\n",
    "\n",
    "* Describe the latent dirichlet allocation process\n",
    "* Implement a topic model using the gensim library\n",
    "* Interpret document topic distributions and summarize findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. Neural Network Foundations\n",
    "\n",
    "Perceptrons\n",
    "\n",
    "* Understand what a perceptron is and how it works\n",
    "\n",
    "Gradient Descent and Backpropagation\n",
    "\n",
    "* Compute backpropagation through hidden layers\n",
    "\n",
    "Neural Network Frameworks\n",
    "\n",
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Major Neural Network Architectures\n",
    "\n",
    "Recurrent Neural Networks and LSTM\n",
    "\n",
    "* Train a basic LSTM with TensorFlow\n",
    "* Use an LSTM to generate text\n",
    "\n",
    "Convolutional Neural Networks\n",
    "\n",
    "* Understand and run a basic CNN with Keras / TensorFlow\n",
    "* Use transfer learning to run a CNN for high-accuracy image classification\n",
    "\n",
    "AutoEncoders and Recommendation Systems\n",
    "\n",
    "AGI and the Future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('vela': pipenv)",
   "language": "python",
   "name": "python37664bitvelapipenvde09592071074af6a70ce3b1ce38af95"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
