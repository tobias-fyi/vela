{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20-07-03: Daily Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Daily practices\n",
    "\n",
    "* [ ] [Practice & learn](#Practice-&-learn)\n",
    "  * [x] Coding, algorithms & data structures\n",
    "  * [x] Data science: access, manipulation, analysis, visualization\n",
    "  * [ ] Engineering: SQL, PySpark, APIs, TDD, OOP\n",
    "  * [ ] Machine learning: Scikit-learn, TensorFlow, PyTorch\n",
    "  * [ ] Interview questions (out loud)\n",
    "* [ ] [Meta-data: reading & writing](#Meta-data:-reading-&-writing)\n",
    "  * [ ] Blog\n",
    "  * [ ] Social media discussions\n",
    "* [ ] [2-Hour Job Search](#2-Hour-Job-Search)\n",
    "  * [ ] LAMP List\n",
    "  * [ ] Online networking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Meta-data: reading & writing\n",
    "\n",
    "* Blog post\n",
    "* Social media discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blog Post: Image Segmentation\n",
    "\n",
    "Spent upwards of an hour working on the image segmentation blog post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Practice & learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Coding, algorithms & data structures\n",
    "\n",
    "* [x] [Remove duplicates from sorted array (easy)](https://leetcode.com/problems/remove-duplicates-from-sorted-array/)\n",
    "* [ ] [Permutations (medium)](https://leetcode.com/problems/permutations/)\n",
    "* [ ] [Generate parantheses (medium)](https://leetcode.com/problems/generate-parentheses/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Remove duplicates from sorted array (easy)](https://leetcode.com/problems/remove-duplicates-from-sorted-array/)\n",
    "\n",
    "* Given a sorted array nums, remove the duplicates in-place such that each element appear only once and return the new length.\n",
    "* Do not allocate extra space for another array, you must do this by modifying the input array in-place with O(1) extra memory.\n",
    "\n",
    "Example 1:\n",
    "\n",
    "    Given nums = [1,1,2],\n",
    "    Your function should return length = 2, with the first two elements of nums being 1 and 2 respectively.\n",
    "    It doesn't matter what you leave beyond the returned length.\n",
    "\n",
    "Example 2:\n",
    "\n",
    "    Given nums = [0,0,1,1,1,2,2,3,3,4],\n",
    "    Your function should return length = 5, with the first five elements of nums being modified to 0, 1, 2, 3, and 4 respectively.\n",
    "    It doesn't matter what values are set beyond the returned length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "def removeDuplicates(nums: List[int]) -> int:\n",
    "    if len(nums) == 0:\n",
    "        return 0\n",
    "    end_num = nums[-1]\n",
    "    if end_num == nums[0]:\n",
    "        return 1\n",
    "    for i in range(1, len(nums)):\n",
    "        while nums[i] == nums[i - 1]:\n",
    "            nums.append(nums.pop(i - 1))\n",
    "        if nums[i] == end_num:\n",
    "            return i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Test it out on various (edge) cases === #\n",
    "nums1 = [1, 1, 2]\n",
    "assert removeDuplicates(nums1) == 2\n",
    "nums2 = [0, 0, 1, 1, 1, 2, 2, 3, 3, 4]\n",
    "assert removeDuplicates(nums2) == 5\n",
    "nums3 = [1, 1]\n",
    "assert removeDuplicates(nums3) == 1\n",
    "nums4 = [1]\n",
    "assert removeDuplicates(nums4) == 1\n",
    "nums5 = [1, 1, 1]\n",
    "assert removeDuplicates(nums5) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Success\n",
    "\n",
    "* Runtime: 136 ms, faster than 19.28% of Python3 online submissions for Remove Duplicates from Sorted Array.\n",
    "* Memory Usage: 15.5 MB, less than 73.68% of Python3 online submissions for Remove Duplicates from Sorted Array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Data science\n",
    "\n",
    "* Access\n",
    "* Manipulation\n",
    "* Analysis\n",
    "* Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TV, Halftime Shows, Big Game\n",
    "\n",
    "> DataCamp Project\n",
    "\n",
    "##### Project Description\n",
    "\n",
    "Whether or not you like football, the Super Bowl is a spectacle. There's drama in the form of blowouts, comebacks, and controversy in the games themselves. There are the ridiculously expensive ads, some hilarious, others gut-wrenching, thought-provoking, and weird. The half-time shows with the biggest musicians in the world, sometimes riding giant mechanical tigers or leaping from the roof of the stadium. And in this project, you will find out how some of the elements of this show interact with each other. You will answer questions like:\n",
    "\n",
    "* What are the most extreme game outcomes?\n",
    "* How does the game affect television viewership?\n",
    "* How have viewership, TV ratings, and ad cost evolved over time?\n",
    "* Who are the most prolific musicians in terms of halftime show performances?\n",
    "\n",
    "This project gives you an opportunity to apply the skills from Intermediate Python for Data Science.\n",
    "\n",
    "The dataset used in this project was scraped and polished from Wikipedia. It is made up of three CSV files, one with game data, one with TV data, and one with halftime musician data for all 52 Super Bowls through 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Project notebook and datasets can be found in the [20-07-03-superbowl](./20-07-03-superbowl) directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Manipulation\n",
    "\n",
    "Working on a data manipulation course. To keep notes here, I'll use a dataset from the above mini-project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>super_bowl</th>\n",
       "      <th>network</th>\n",
       "      <th>avg_us_viewers</th>\n",
       "      <th>total_us_viewers</th>\n",
       "      <th>rating_household</th>\n",
       "      <th>share_household</th>\n",
       "      <th>rating_18_49</th>\n",
       "      <th>share_18_49</th>\n",
       "      <th>ad_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>NBC</td>\n",
       "      <td>103390000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.1</td>\n",
       "      <td>68</td>\n",
       "      <td>33.4</td>\n",
       "      <td>78.0</td>\n",
       "      <td>5000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>Fox</td>\n",
       "      <td>111319000</td>\n",
       "      <td>172000000.0</td>\n",
       "      <td>45.3</td>\n",
       "      <td>73</td>\n",
       "      <td>37.1</td>\n",
       "      <td>79.0</td>\n",
       "      <td>5000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>CBS</td>\n",
       "      <td>111864000</td>\n",
       "      <td>167000000.0</td>\n",
       "      <td>46.6</td>\n",
       "      <td>72</td>\n",
       "      <td>37.7</td>\n",
       "      <td>79.0</td>\n",
       "      <td>5000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>NBC</td>\n",
       "      <td>114442000</td>\n",
       "      <td>168000000.0</td>\n",
       "      <td>47.5</td>\n",
       "      <td>71</td>\n",
       "      <td>39.1</td>\n",
       "      <td>79.0</td>\n",
       "      <td>4500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>Fox</td>\n",
       "      <td>112191000</td>\n",
       "      <td>167000000.0</td>\n",
       "      <td>46.7</td>\n",
       "      <td>69</td>\n",
       "      <td>39.3</td>\n",
       "      <td>77.0</td>\n",
       "      <td>4000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   super_bowl network  avg_us_viewers  total_us_viewers  rating_household  \\\n",
       "0          52     NBC       103390000               NaN              43.1   \n",
       "1          51     Fox       111319000       172000000.0              45.3   \n",
       "2          50     CBS       111864000       167000000.0              46.6   \n",
       "3          49     NBC       114442000       168000000.0              47.5   \n",
       "4          48     Fox       112191000       167000000.0              46.7   \n",
       "\n",
       "   share_household  rating_18_49  share_18_49  ad_cost  \n",
       "0               68          33.4         78.0  5000000  \n",
       "1               73          37.1         79.0  5000000  \n",
       "2               72          37.7         79.0  5000000  \n",
       "3               71          39.1         79.0  4500000  \n",
       "4               69          39.3         77.0  4000000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv = pd.read_csv(\"20-07-03-superbowls/datasets/tv.csv\")\n",
    "tv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>super_bowl</th>\n",
       "      <th>network</th>\n",
       "      <th>avg_us_viewers</th>\n",
       "      <th>total_us_viewers</th>\n",
       "      <th>rating_household</th>\n",
       "      <th>share_household</th>\n",
       "      <th>rating_18_49</th>\n",
       "      <th>share_18_49</th>\n",
       "      <th>ad_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>NBC</td>\n",
       "      <td>103390000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.1</td>\n",
       "      <td>68</td>\n",
       "      <td>33.4</td>\n",
       "      <td>78.0</td>\n",
       "      <td>5000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>Fox</td>\n",
       "      <td>111319000</td>\n",
       "      <td>172000000.0</td>\n",
       "      <td>45.3</td>\n",
       "      <td>73</td>\n",
       "      <td>37.1</td>\n",
       "      <td>79.0</td>\n",
       "      <td>5000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>NBC</td>\n",
       "      <td>114442000</td>\n",
       "      <td>168000000.0</td>\n",
       "      <td>47.5</td>\n",
       "      <td>71</td>\n",
       "      <td>39.1</td>\n",
       "      <td>79.0</td>\n",
       "      <td>4500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>Fox</td>\n",
       "      <td>112191000</td>\n",
       "      <td>167000000.0</td>\n",
       "      <td>46.7</td>\n",
       "      <td>69</td>\n",
       "      <td>39.3</td>\n",
       "      <td>77.0</td>\n",
       "      <td>4000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>46</td>\n",
       "      <td>NBC</td>\n",
       "      <td>111346000</td>\n",
       "      <td>163500000.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>71</td>\n",
       "      <td>40.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   super_bowl network  avg_us_viewers  total_us_viewers  rating_household  \\\n",
       "0          52     NBC       103390000               NaN              43.1   \n",
       "1          51     Fox       111319000       172000000.0              45.3   \n",
       "3          49     NBC       114442000       168000000.0              47.5   \n",
       "4          48     Fox       112191000       167000000.0              46.7   \n",
       "6          46     NBC       111346000       163500000.0              47.0   \n",
       "\n",
       "   share_household  rating_18_49  share_18_49  ad_cost  \n",
       "0               68          33.4         78.0  5000000  \n",
       "1               73          37.1         79.0  5000000  \n",
       "3               71          39.1         79.0  4500000  \n",
       "4               69          39.3         77.0  4000000  \n",
       "6               71          40.5          NaN  3500000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of networks to include\n",
    "networks = [\"NBC\", \"Fox\"]\n",
    "# Filter for rows containing those networks\n",
    "tv_nets = tv[tv[\"network\"].isin(networks)]\n",
    "tv_nets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, most of it is simple review — not worth writing down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Engineering\n",
    "\n",
    "* SQL\n",
    "* PySpark\n",
    "* APIs\n",
    "* Test-driven development\n",
    "* Object-oriented practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a Sales Model Using SQL Techniques\n",
    "\n",
    "> Applied SQL Analytics\n",
    "\n",
    "In this activity, we will clean and prepare our data for analysis using SQL techniques. The data science team wants to build a new model to help predict which customers are the best prospects for remarketing. A new data scientist has joined their team and does not know the database well enough to pull a dataset for this new model. The responsibility has fallen to you to help the new data scientist prepare and build a dataset to be used to train a model. Write a query to assemble a dataset. Here are the steps to perform:\n",
    "\n",
    "1. Open a SQL client and connect to the database.\n",
    "2. Use `INNER JOIN` to join the `customers` table to the `sales` table.\n",
    "3. Use `INNER JOIN` to join the `products` table to the `sales` table.\n",
    "4. Use `LEFT JOIN` to join the `dealerships` table to the `sales` table.\n",
    "5. Now, return all columns of the `customers` table and the `products` table.\n",
    "6. Then, return the `dealership_id` column from the `sales` table, but fill in `dealership_id` in `sales` with `-1` if it is `NULL`.\n",
    "7. Add a column called `high_savings` that returns `1` if the sales amount was `500` less than `base_msrp` or lower. Otherwise, it returns `0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. `sales` and `customers` can be joined on the `customer_id` column\n",
    "\n",
    "```SQL\n",
    "SELECT *\n",
    "FROM sales s\n",
    "INNER JOIN customers c\n",
    "  ON c.customer_id = s.customer_id;\n",
    "```\n",
    "\n",
    "3. `sales` and `products` can be joined on `product_id`\n",
    "\n",
    "```SQL\n",
    "SELECT *\n",
    "FROM sales s\n",
    "INNER JOIN products p\n",
    "  ON p.product_id = s.product_id;\n",
    "```\n",
    "\n",
    "4. `sales` and `dealerships` can be joined on `dealership_id`\n",
    "\n",
    "```SQL\n",
    "SELECT *\n",
    "FROM sales s\n",
    "LEFT JOIN dealerships d\n",
    "  ON d.dealership_id = s.dealership_id;\n",
    "```\n",
    "\n",
    "Bringing all of those together (plus the proceeding steps):\n",
    "\n",
    "```SQL\n",
    "SELECT\n",
    "  c.*,\n",
    "  p.*,\n",
    "  COALESCE(s.dealership_id, -1),\n",
    "  CASE WHEN s.sales_amount < p.base_msrp - 500 THEN 1\n",
    "  ELSE 0 END as high_savings\n",
    "FROM sales s\n",
    "INNER JOIN customers c ON c.customer_id = s.customer_id\n",
    "INNER JOIN products p ON p.product_id = s.product_id\n",
    "LEFT JOIN dealerships d ON d.dealership_id = s.dealership_id;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Machine learning\n",
    "\n",
    "* Scikit-learn\n",
    "* TensorFlow / PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Interview questions\n",
    "\n",
    "> Answer common interview questions **_out loud_**.\n",
    "\n",
    "* Technical: DS, ML, SE\n",
    "* Behavioral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## 2-Hour Job Search\n",
    "\n",
    "* LAMP List\n",
    "* Online networking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('vela': pipenv)",
   "language": "python",
   "name": "python37664bitvelapipenvde09592071074af6a70ce3b1ce38af95"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
