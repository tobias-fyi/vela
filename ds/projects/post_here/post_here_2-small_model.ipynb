{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Here: The Subreddit Suggester\n",
    "\n",
    "# Notebook 2: Modeling\n",
    "\n",
    "> Small Model (limited dataset)\n",
    "\n",
    "### By _Tobias Reaper_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Notebook outline\n",
    "\n",
    "* [_Imports and Configuration_](#Imports-and-Configuration)\n",
    "* [Modeling](#Modeling)\n",
    "  * [Challenges](#Challenges)\n",
    "  * [Feature Selection](#Feature-Selection)\n",
    "  * [Vectorization](#Vectorization)\n",
    "  * [Baseline](#Baseline)\n",
    "  * [Multinomial Naive Bayes](#Multinomial-Naive-Bayes)\n",
    "* [Final Thoughts](#Final-Thoughts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === General imports === #\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import janitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ML imports === #\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "\n",
    "# === NLP Imports === #\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Configure === #\n",
    "# nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# Configure pandas display settings\n",
    "pd.options.display.max_colwidth = 200\n",
    "\n",
    "# Set random seed\n",
    "seed = 92"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91500, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stepparents</td>\n",
       "      <td>Ex Wants Toddler Son (2M) to Meet Her AP/SO - x-post from /r/divorce Quick background: My soon-to-be ex-wife (26F) and I (27M) have been separated for about 5 months now. She has been in a serious...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bigseo</td>\n",
       "      <td>Do we raise our pricing? I took a management role at an agency. We're way, way under $500/mo for SEO pricing - and I'm embarrassed to say that we're hurting for business. Seems to me that it's a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chemistry</td>\n",
       "      <td>Mac vs. PC? Hello, all! I am currently a senior in high school and in the fall I will be going to SUNY Geneseo, majoring in chemistry and minoring in mathematics. Geneseo requires it’s students to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>migraine</td>\n",
       "      <td>Beer as an aural abortive? Hiya folks,I've been a migraine sufferer pretty much my whole life. For me intense auras, numbness, confusion, the inability to speak or see is BY FAR the worst aspect o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MouseReview</td>\n",
       "      <td>Recommend office mouse I was hoping you folks could help me out. Here's my situation and requirements:* I don't play games at all* Budget $30.00 or less* Shape as close to old Microsoft Intellimou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit  \\\n",
       "0  stepparents   \n",
       "1       bigseo   \n",
       "2    chemistry   \n",
       "3     migraine   \n",
       "4  MouseReview   \n",
       "\n",
       "                                                                                                                                                                                                      text  \n",
       "0  Ex Wants Toddler Son (2M) to Meet Her AP/SO - x-post from /r/divorce Quick background: My soon-to-be ex-wife (26F) and I (27M) have been separated for about 5 months now. She has been in a serious...  \n",
       "1  Do we raise our pricing? I took a management role at an agency. We're way, way under $500/mo for SEO pricing - and I'm embarrassed to say that we're hurting for business. Seems to me that it's a s...  \n",
       "2  Mac vs. PC? Hello, all! I am currently a senior in high school and in the fall I will be going to SUNY Geneseo, majoring in chemistry and minoring in mathematics. Geneseo requires it’s students to...  \n",
       "3  Beer as an aural abortive? Hiya folks,I've been a migraine sufferer pretty much my whole life. For me intense auras, numbness, confusion, the inability to speak or see is BY FAR the worst aspect o...  \n",
       "4  Recommend office mouse I was hoping you folks could help me out. Here's my situation and requirements:* I don't play games at all* Budget $30.00 or less* Shape as close to old Microsoft Intellimou...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Load cleaned/pruned dataset === #\n",
    "rspct = pd.read_csv(\"assets/data/rspct_small.csv\", index_col=0)\n",
    "print(rspct.shape)\n",
    "rspct.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((65880, 2), (7320, 2), (18300, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Split up dataset into train and test === #\n",
    "train, test = train_test_split(rspct, test_size=0.2, random_state=seed)\n",
    "train, val = train_test_split(train, test_size=0.1, random_state=seed)\n",
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65880,) (7320,) (18300,)\n",
      "(65880,) (7320,) (18300,)\n"
     ]
    }
   ],
   "source": [
    "# === Split out feature/target === #\n",
    "X_train = train[\"text\"]\n",
    "X_val = val[\"text\"]\n",
    "X_test = test[\"text\"]\n",
    "\n",
    "y_train = train[\"subreddit\"]\n",
    "y_val = val[\"subreddit\"]\n",
    "y_test = test[\"subreddit\"]\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "print(y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 92, 140,  65,  90, 278,  65, 272, 212])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Encode the target using LabelEncoder === #\n",
    "# This process naively transforms each class of the target into a number\n",
    "le = LabelEncoder() # Instantiate a new encoder instance\n",
    "le.fit(y_train)  # Fit it on training label data\n",
    "\n",
    "# Transform both using the trained instance\n",
    "y_train = le.transform(y_train)\n",
    "y_val = le.transform(y_val)\n",
    "y_test  = le.transform(y_test)\n",
    "\n",
    "y_train[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization\n",
    "\n",
    "At first, the \"vocabulary\" derived from the corpus using the vectorizer was the largest object when serialized. Luckily, there are many options and parameters available to reduce its size.\n",
    "\n",
    "I decided to remove stopwords before vectorization in hopes that this would reduce the size of the vector vocabulary. To my initial surprise, removing the stop words (using [NLTK](https://www.nltk.org/)'s list) actually increased the size of the serialized vocab from 59mb to 76mb.\n",
    "\n",
    "After some consideration, I found this to be a reasonable result. I figured that many of the stop words are short (\"I\", \"me\", \"my\", etc.), and their removal caused the average length of words (and therefore bigrams as well) in the vocab to increase. While this may not account for the entirety of the difference, this provides some intuition as to why there is a difference.\n",
    "\n",
    "Although the vocab without stop words was larger, I ended up using it anyways because it provided an extra ~0.01 in the precision-at-k score of the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 179 stop words in the list.\n",
      "109 are 4 chars long or shorter.\n",
      "Average length is: 4.229050279329609.\n"
     ]
    }
   ],
   "source": [
    "# === Look at lengths of stop words === #\n",
    "lengths = []\n",
    "three_or_below = []\n",
    "for word in stop_words:\n",
    "    lengths.append(len(word))\n",
    "    if len(word) <= 4:\n",
    "        three_or_below.append(len(word))\n",
    "        \n",
    "print(f\"There are {len(stop_words)} stop words in the list.\")\n",
    "print(f\"{len(three_or_below)} are 4 chars long or shorter.\")\n",
    "print(f\"Average length is: {np.mean(lengths)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((65880, 150524), (7320, 150524), (18300, 150524))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Vectorize! === #\n",
    "# Extract features from the text data using bag-of-words method\n",
    "tfidf = TfidfVectorizer(\n",
    "#     max_features=100000,\n",
    "    min_df=5,\n",
    "    ngram_range=(1,2),\n",
    "    stop_words=stop_words,  # Use nltk's stop words\n",
    ")\n",
    "\n",
    "# Fit the vectorizer on the feature column to create vocab (doc-term matrix)\n",
    "vocab = tfidf.fit(X_train)\n",
    "\n",
    "# Get sparse document-term matrices\n",
    "X_train_sparse = vocab.transform(X_train)\n",
    "X_val_sparse = vocab.transform(X_val)\n",
    "X_test_sparse = vocab.transform(X_test)\n",
    "\n",
    "X_train_sparse.shape, X_val_sparse.shape, X_test_sparse.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "As mentioned previously, the size of the corpus means the dimensionality of the featureset after vectorization will be very high. I passed in 100,000 as the maximum number of features to the vectorizer, limiting the initial size of the vocab. However, the features would have to be reduced more before training the model, as it is generally not good practice to have a larger number of features (100,000) than observations (91,500).\n",
    "\n",
    "To reduce it down from that 100,000, I used a process called select k best, which does exactly what it sounds like: selects a certain number of the best features. The key aspect of this process is how to measure the value of the features; how to find which ones are the \"best\". The scoring function I used in this case is called [ch2](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html) (chi-squared).\n",
    "\n",
    "This function calculates chi-squared statistics between each feature and the target, measuring the dependence, or correlation, between them. The intuition here is that features which are more correlated with the target are more likely to be useful to the model.\n",
    "\n",
    "I played around with some different values for the maximum number of features to be selected. Ultimately, I was once again limited by the size of the free Heroku Dyno, and settled on 20,000. This allowed the deployment to go smoothly while retaining enough information for the model to have adequate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "27ddcca6c2af541e94133222961a83c11f54208e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((65880, 20000), (7320, 20000), (18300, 20000))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Feature Selection === #\n",
    "selector = SelectKBest(chi2, k=20000)\n",
    "\n",
    "selector.fit(X_train_sparse, y_train)\n",
    "\n",
    "X_train_select = selector.transform(X_train_sparse)\n",
    "X_val_select = selector.transform(X_val_sparse)\n",
    "X_test_select  = selector.transform(X_test_sparse)\n",
    "\n",
    "X_train_select.shape, X_val_select.shape, X_test_select.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model validation\n",
    "\n",
    "In this case, the model has a target that it is attempting to predict—a supervised problem. Therefore, the performance can be measured on validation and test sets.\n",
    "\n",
    "To test out the recommendations I copied some posts and put them through the prediction pipeline to see what kinds of subreddits were getting recommended. For the most part, the predictions were decent.\n",
    "\n",
    "The cases where the recommendations were a little less than ideal happened when I pulled example posts from subreddits that were not in the training data. The model generally did a good job recommending similar subreddits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline\n",
    "\n",
    "For the baseline model, I decided to go with a basic random forest. This choice was somewhat arbitrary, though I was curious to see how a random forest would do with such a high target cardinality (number of classes/categories).\n",
    "\n",
    "The baseline precision-at-k metrics for the random forest on the validation set were .54, .63, and .65, for 'k' of 1, 3, and 5, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "8d31738daa5d0382761477f16e79d1800ac6f730"
   },
   "outputs": [],
   "source": [
    "# === Evaluate performance using precision-at-k === #\n",
    "def precision_at_k(y_true, y_pred, k=5):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred = np.argsort(y_pred, axis=1)\n",
    "    y_pred = y_pred[:, ::-1][:, :k]\n",
    "    arr = [y in s for y, s in zip(y_true, y_pred)]\n",
    "    return np.mean(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "6d317a155229fa60c6241e7b8d2355fb1cba9d43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=32, n_estimators=200, n_jobs=-1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Baseline RandomForest model === #\n",
    "rfc = RandomForestClassifier(max_depth=32, n_jobs=-1, n_estimators=200)\n",
    "rfc.fit(X_train_select, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "6d317a155229fa60c6241e7b8d2355fb1cba9d43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([274, 139, 184,  78,  12, 177, 177, 216,  40,  31])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Create predictions for validation set === #\n",
    "y_pred_proba_rfc = rfc.predict_proba(X_val_select)\n",
    "\n",
    "# === For each prediction, find the index with the highest probability === #\n",
    "y_pred_rfc = np.argmax(y_pred_proba_rfc, axis=1)\n",
    "y_pred_rfc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "6d317a155229fa60c6241e7b8d2355fb1cba9d43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation scores:\n",
      "  precision@1 = 0.5401639344262295\n",
      "  precision@3 = 0.6314207650273224\n",
      "  precision@5 = 0.6545081967213114\n"
     ]
    }
   ],
   "source": [
    "# === Evaluate precision at k for validation === #\n",
    "print(\"Validation scores:\")\n",
    "print(\"  precision@1 =\", np.mean(y_val == y_pred_rfc))\n",
    "print(\"  precision@3 =\", precision_at_k(y_val, y_pred_proba_rfc, 3))\n",
    "print(\"  precision@5 =\", precision_at_k(y_val, y_pred_proba_rfc, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes\n",
    "\n",
    "Multinomial naive Bayes is a probabilistic learning method for multinomially distributed data, and one of two classic naive Bayes algorithms used for text classification. I decided to iterate with this algorithm because it is meant for text classification tasks.\n",
    "\n",
    "The precision-at-k metrics for the final Multinomial naive Bayes model on the validation set were .76, .88, and .9188, for 'k' of 1, 3, and 5, respectively. Performance on the test set was nearly identical: .75, .88, and .9159."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "6d317a155229fa60c6241e7b8d2355fb1cba9d43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Naive Bayes model === #\n",
    "nb = MultinomialNB(alpha=0.1)\n",
    "nb.fit(X_train_select, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "6d317a155229fa60c6241e7b8d2355fb1cba9d43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([274, 139, 255,  78,  12,  17, 151, 216,  40, 171])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Create predictions for validation set === #\n",
    "y_pred_proba_val = nb.predict_proba(X_val_select)\n",
    "\n",
    "# For each prediction, find index with highest probability\n",
    "y_pred_val = np.argmax(y_pred_proba_val, axis=1)\n",
    "y_pred_val[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation scores:\n",
      "  precision@1 = 0.7673497267759563\n",
      "  precision@3 = 0.8866120218579235\n",
      "  precision@5 = 0.9174863387978142\n"
     ]
    }
   ],
   "source": [
    "# === Evaluate precision at k for validation === #\n",
    "print(\"Validation scores:\")\n",
    "print(\"  precision@1 =\", np.mean(y_val == y_pred_val))\n",
    "print(\"  precision@3 =\", precision_at_k(y_val, y_pred_proba_val, 3))\n",
    "print(\"  precision@5 =\", precision_at_k(y_val, y_pred_proba_val, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "6d317a155229fa60c6241e7b8d2355fb1cba9d43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 97, 199, 116, 249,  43, 203,  41, 275,  96,  27])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Create predictions for test set === #\n",
    "y_pred_proba_test = nb.predict_proba(X_test_select)\n",
    "\n",
    "# For each prediction, find index with highest probability\n",
    "y_pred_test = np.argmax(y_pred_proba_test, axis=1)\n",
    "y_pred_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test scores:\n",
      "  precision@1 = 0.7575956284153006\n",
      "  precision@3 = 0.8867213114754099\n",
      "  precision@5 = 0.9176502732240437\n"
     ]
    }
   ],
   "source": [
    "# === Evaluate precision at k for test === #\n",
    "print(\"Test scores:\")\n",
    "print(\"  precision@1 =\", np.mean(y_test == y_pred_test))\n",
    "print(\"  precision@3 =\", precision_at_k(y_test, y_pred_proba_test, 3))\n",
    "print(\"  precision@5 =\", precision_at_k(y_test, y_pred_proba_test, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations\n",
    "\n",
    "The API should return a list of recommendations, not a single prediction. To accomplish this, I wrote a function that returns the top 5 most likely subreddits and their respective probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Function to serve predictions === #\n",
    "# The main functionality of the predict API endpoint\n",
    "\n",
    "def predict(title: str, submission_text: str, return_count: int = 5):\n",
    "    \"\"\"\n",
    "    Serve subreddit predictions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    title : string\n",
    "        Title of post.\n",
    "    submission_text : string\n",
    "        Selftext that needs a home.\n",
    "    return_count    : integer\n",
    "        The desired number of recommendations.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Python dictionary formatted as follows:\n",
    "        [{'subreddit': 'PLC', 'proba': 0.014454},\n",
    "         ...\n",
    "         {'subreddit': 'Rowing', 'proba': 0.005206}]\n",
    "    \"\"\"\n",
    "    # Concatenate title and post text\n",
    "    fulltext = str(title) + str(submission_text)\n",
    "    # Vectorize the post -> sparse doc-term matrix\n",
    "    post_sparse = vocab.transform([fulltext])\n",
    "    # Feature selection\n",
    "    post_select = selector.transform(post_sparse)\n",
    "    # Generate predicted probabilities from trained model\n",
    "    proba = nb.predict_proba(post_select)\n",
    "    # Wrangle into correct format\n",
    "    proba_dict = (pd\n",
    "                .DataFrame(proba, columns=[le.classes_])  # Classes as column names\n",
    "                .T  # Transpose so column names become index\n",
    "                .reset_index()  # Pull out index into a column\n",
    "                .rename(columns={\"level_0\": \"name\", 0: \"proba\"})  # Rename for aesthetics\n",
    "                .sort_values(by=\"proba\", ascending=False)  # Sort by probability\n",
    "                .iloc[:return_count]  # n-top predictions to serve\n",
    "                .to_dict(orient=\"records\")\n",
    "               )\n",
    "    proba_json = {\"predictions\": proba_dict}\n",
    "    \n",
    "    return proba_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'name': 'GERD', 'proba': 0.009900622287634142},\n",
       "  {'name': 'Allergies', 'proba': 0.009287774623361566},\n",
       "  {'name': 'ibs', 'proba': 0.009150308633162811},\n",
       "  {'name': 'AskAnthropology', 'proba': 0.009028660140513678},\n",
       "  {'name': 'fatpeoplestories', 'proba': 0.00851982441049019}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_science = \"\"\"Is there an evolutionary benefit to eating spicy food that lead to consumption across numerous cultures throughout history? Or do humans just like the sensation?\"\"\"\n",
    "\n",
    "post_science = \"\"\"I love spicy food and have done ever since I tried it. By spicy I mean HOT, like chilli peppers (we say spicy in England, I don't mean to state the obvious I'm just not sure if that's a global term and I've assumed too much before). I love a vast array of spicy foods from all around the world. I was just wondering if there was some evolutionary basis as to why spicy food managed to become some widely consumed historically. Though there seem to\n",
    "\n",
    "It way well be that we just like a tingly mouth, the simple things in life.\"\"\"\n",
    "\n",
    "science_recs = predict(title_science, post_science)\n",
    "science_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'name': 'lego', 'proba': 0.008418484170536294},\n",
       "  {'name': 'rccars', 'proba': 0.008112076951648648},\n",
       "  {'name': 'MechanicalKeyboards', 'proba': 0.0078335440606017},\n",
       "  {'name': 'fightsticks', 'proba': 0.007633958584830632},\n",
       "  {'name': 'Luthier', 'proba': 0.00716176615193545},\n",
       "  {'name': 'modeltrains', 'proba': 0.007088134228361153},\n",
       "  {'name': 'cade', 'proba': 0.007058109839673285},\n",
       "  {'name': 'vandwellers', 'proba': 0.006700262151491209},\n",
       "  {'name': 'cosplay', 'proba': 0.006536648725434882},\n",
       "  {'name': 'homestead', 'proba': 0.006166832450007183}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Test post from r/buildmeapc === #\n",
    "\n",
    "title_pc = \"\"\"Looking for help with a build\"\"\"\n",
    "\n",
    "post_pc = \"\"\"I posted my wants for my build about 2 months ago. Ordered them and when I went to build it I was soooooo lost. It took 3 days to put things together because I was afraid I would break something when I finally got the parts together it wouldn’t start, I was so defeated. With virtually replacing everything yesterday it finally booted and I couldn’t be more excited!\"\"\"\n",
    "\n",
    "post_pc_recs = predict(title_pc, post_pc, 10)\n",
    "post_pc_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'name': 'cscareerquestions', 'proba': 0.516989539243874},\n",
       "  {'name': 'devops', 'proba': 0.031462691062989795},\n",
       "  {'name': 'interviews', 'proba': 0.02846504725703069},\n",
       "  {'name': 'datascience', 'proba': 0.024227300545057697},\n",
       "  {'name': 'bioinformatics', 'proba': 0.017516176338177075}]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Example post from 'r/learnprogramming' === #\n",
    "\n",
    "post_title = \"\"\"What to do about java vs javascript\"\"\"\n",
    "\n",
    "post = \"\"\"I am a new grad looking for a job and currently in the process with a company for a junior backend engineer role. I was under the impression that the position was Javascript but instead it is actually Java. My general programming and \"leet code\" skills are pretty good, but my understanding of Java is pretty shallow. How can I use the next three days to best improve my general Java knowledge? Most resources on the web seem to be targeting complete beginners. Maybe a book I can skim through in the next few days?\n",
    "\n",
    "Edit:\n",
    "\n",
    "A lot of people are saying \"the company is a sinking ship don't even go to the interview\". I just want to add that the position was always for a \"junior backend engineer\". This company uses multiple languages and the recruiter just told me the incorrect language for the specific team I'm interviewing for. I'm sure they're mainly interested in seeing my understanding of good backend principles and software design, it's not a senior lead Java position.\"\"\"\n",
    "\n",
    "# === Test out the function === #\n",
    "post_pred = predict(post_title, post)  # Default is 5 results\n",
    "post_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'name': 'suggestmeabook', 'proba': 0.4070015062748489},\n",
       "  {'name': 'writing', 'proba': 0.14985778378113648},\n",
       "  {'name': 'eroticauthors', 'proba': 0.07159411817054702},\n",
       "  {'name': 'whatsthatbook', 'proba': 0.06062653422250441},\n",
       "  {'name': 'ComicBookCollabs', 'proba': 0.027277418056905547},\n",
       "  {'name': 'Malazan', 'proba': 0.019514923212723943},\n",
       "  {'name': 'TheDarkTower', 'proba': 0.017162701613834493},\n",
       "  {'name': 'DestructiveReaders', 'proba': 0.0151031907793204},\n",
       "  {'name': 'WoT', 'proba': 0.011165890302931272},\n",
       "  {'name': 'readyplayerone', 'proba': 0.007566597361383115}]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Test it out with another dummy post === #\n",
    "\n",
    "title_book = \"Looking for books with great plot twists\"\n",
    "\n",
    "# This one comes from r/suggestmeabook\n",
    "post2 = \"\"\"I've been dreaming about writing my own stort story for a while but I want to give it an unexpected ending. I've read lots of books, but none of them had the plot twist I want. I want to read books with the best plot twists, so that I can analyze what makes a good plot twist and write my own story based on that points. I don't like romance novels and I mostly enjoy sci-fi or historical books but anything beside romance novels would work for me, it doesn't have to be my type of novel. I'm open to experience after all. I need your help guys. Thanks in advance.\"\"\"\n",
    "\n",
    "# === This time with 10 results === #\n",
    "post2_pred = predict(title_book, post2, 10)\n",
    "post2_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model deployment\n",
    "\n",
    "As mentioned, the model, vocab, and feature selector were all serialized using Python's pickle module. In the Flask app, the pickled objects are loaded and ready for use, just like that.\n",
    "\n",
    "I will go over the details of how the Flask app was set up in a separate blog post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Create pickle func to make pickling (a little) easier === #\n",
    "\n",
    "def picklizer(to_pickle, filename, path):\n",
    "    \"\"\"\n",
    "    Creates a pickle file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    to_pickle : Python object\n",
    "        The trained / fitted instance of the \n",
    "        transformer or model to be pickled.\n",
    "    filename : string\n",
    "        The desired name of the output file,\n",
    "        not including the '.pkl' extension.\n",
    "    path : string or path-like object\n",
    "        The path to the desired output directory.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import pickle\n",
    "\n",
    "    # Create the path to save location\n",
    "    picklepath = os.path.join(path, filename)\n",
    "\n",
    "    # Use context manager to open file\n",
    "    with open(picklepath, \"wb\") as p:\n",
    "        pickle.dump(to_pickle, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Picklize! === #\n",
    "filepath = \"./assets/pickles\"  # Change this accordingly\n",
    "\n",
    "# Create directory if doesn't exist\n",
    "os.makedirs(filepath, exist_ok=True)\n",
    "\n",
    "# Export LabelEncoder as pickle\n",
    "picklizer(le, \"le.pkl\", filepath)\n",
    "\n",
    "# Export selector as pickle\n",
    "picklizer(selector, \"selector.pkl\", filepath)\n",
    "\n",
    "# Export vectorizer as pickle\n",
    "picklizer(vocab, \"vocab.pkl\", filepath)\n",
    "\n",
    "# Export naive bayes model as pickle\n",
    "picklizer(nb, \"nb.pkl\", filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Final Thoughts\n",
    "\n",
    "For me, the most important and valuable aspects of this project were mainly surrounding the challenge of scope management. I constantly had to ask myself, \"What is the best version of this I can create given our limitations?\"\n",
    "\n",
    "At first, I thought it would be feasible to predict all of the 1,000+ subreddits in the data, and wasted hours of valuable time attempting to do so. While I had tested various strategies of reducing the complexity of the model, the performance was rather terrible when it was trained on 100 or less examples of each of the complete list of subreddits.\n",
    "\n",
    "The data scientist who I primarily worked with (we had one data scientist in addition to him and one other machine learning engineer, both of whom did not contribute significantly to the project) kept telling me that I should try reducing the number of classes first, allowing for more examples of each class and fewer classes for the model to predict.\n",
    "\n",
    "Ultimately, this is the strategy that worked best, and I wasted valuable time by not listening to him the first few times he recommended that strategy. Good teamwork requires the members being humble and listening, something that I have taken to heart since the conclusion of this project.\n",
    "\n",
    "### Scope Management, Revisited\n",
    "\n",
    "As time was very short while building this initial recommendation API, there are many things that we wished we could have done but simply did not have the time. Here are a few of the more obvious improvements that could be made.\n",
    "\n",
    "The first, and most obvious one, is to simply deploy to a more powerful server, such as one hosted on AWS Elastic Beanstalk or EC2. This way, we could use the entire dataset to train an optimal model without worrying (as much) about memory limits.\n",
    "\n",
    "Second, I could use a Scikit-learn pipeline to validate and tune hyperparameters using cross-validation, instead of a separate validation set. Also, this pipeline could be serialized as a single large object, rather than as separate pieces (encoder, vectorizer, feature selector, and classifier). As a final note for this particular train of thought, [Joblib](https://joblib.readthedocs.io/en/latest/) could potentially provide more efficient serialization than the Pickle module, allowing a more complex pipeline to be deployed on the same server.\n",
    "\n",
    "Third, a model could've been trained to classify the input post first into a broad category. Then, some sort of model could be used to to classify into a specific subreddit within that broad category. I'm not sure about the feasibility of the second part of this idea, but thought it could be an interesting one to explore.\n",
    "\n",
    "Lastly, different classes and calibers of models could have been tested for use in the various steps in the pipeline. In this case, I'm referring primarily to using deep learning/neural networks. For example, word vectors could be generated with word embedding models such as Word2Vec. Or the process could be recreated with a library like PyTorch, and a framework like [FastText](https://github.com/facebookresearch/fastText/).\n",
    "\n",
    "I plan to explore at least some of these in separate blog posts.\n",
    "\n",
    "As always, thank you for reading! I'll see you in the next one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('vela': pipenv)",
   "language": "python",
   "name": "python37664bitvelapipenvde09592071074af6a70ce3b1ce38af95"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
