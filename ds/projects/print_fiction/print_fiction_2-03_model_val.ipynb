{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6K-Ijmo7VceT"
   },
   "source": [
    "# üëΩüëæ `print(fiction)` üìöüõ∏\n",
    "\n",
    "> #### A data science project by _Tobias Reaper_\n",
    "\n",
    "#### üìì Notebook 3: Modeling üß†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_K7zk62hIT4-"
   },
   "source": [
    "---\n",
    "\n",
    "### Notebook Outline\n",
    "\n",
    "[explanation of this notebook in context of project]\n",
    "\n",
    "* Intro\n",
    "* Imports and Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "`print(fiction)` is a solo project I worked on to explore the data on and around stories‚Äîspecifically, the stories contained in print books.\n",
    "\n",
    "I used Scrapy to scrape metadata for over 20,000 books from GoodReads and used it to train a gradient-boosted random forest classifier. The final version of the model classified books as either fiction or nonfiction with 88% accuracy.\n",
    "\n",
    "The dataset is freely available for download from GitHub or Kaggle (link to come).\n",
    "I built an interactive dashboard using Plotly Dash that can be used to tinker with the model parameters and view the resulting prediction in real time.\n",
    "\n",
    "You can find the current live version of the app here: [print(fiction)](http://print-fiction.herokuapp.com/)\n",
    "\n",
    "The notebooks detailing the entire process of data gathering, wrangling, modeling, and deployment, can be found here: [print(fiction) notebooks](https://github.com/tobias-fyi/print-fiction/tree/master/notebooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NCMU9Y5DVvT5"
   },
   "source": [
    "---\n",
    "\n",
    "### Imports and Configuration\n",
    "\n",
    "‚öôÔ∏èüì• "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "cOS1Wyo0VZQM",
    "outputId": "c8cf3f18-b0e1-4cf3-e6eb-8fda07f48def"
   },
   "outputs": [],
   "source": [
    "# === General Imports === #\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import randint, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sgtmOkO6IT5Q"
   },
   "outputs": [],
   "source": [
    "# === Configure === #\n",
    "%matplotlib inline\n",
    "pd.options.display.max_rows = 200\n",
    "pd.options.display.max_columns = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gGwq5WRwI6ty"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install category-encoders\n",
    "!pip install eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "f01v7xNdIT5W",
    "outputId": "c8c09332-0f42-488e-ca0f-0f601510be12"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tobias/.vega/vela-_qIiF1eP/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Tobias/.vega/vela-_qIiF1eP/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# === ML Imports === #\n",
    "\n",
    "# Preprocessing\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "\n",
    "# Model validation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Interpretations\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yInEDKOEIT5c"
   },
   "source": [
    "---\n",
    "\n",
    "## üìà Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "colab_type": "code",
    "id": "ndvQA9x5WtnB",
    "outputId": "c3f6ca83-af13-4502-dcb7-cf71cdcfffa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18344, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>language</th>\n",
       "      <th>series</th>\n",
       "      <th>1_rating_count</th>\n",
       "      <th>2_rating_count</th>\n",
       "      <th>3_rating_count</th>\n",
       "      <th>4_rating_count</th>\n",
       "      <th>5_rating_count</th>\n",
       "      <th>publish_year</th>\n",
       "      <th>publish_month</th>\n",
       "      <th>publish_day</th>\n",
       "      <th>fiction</th>\n",
       "      <th>republish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Book of Mormon: Another Testament of Jesus...</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>71355.0</td>\n",
       "      <td>5704.0</td>\n",
       "      <td>4.37</td>\n",
       "      <td>531.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>7520.0</td>\n",
       "      <td>2697.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>56654.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Prince</td>\n",
       "      <td>Niccol√≤ Machiavelli</td>\n",
       "      <td>229715.0</td>\n",
       "      <td>7261.0</td>\n",
       "      <td>3.81</td>\n",
       "      <td>140.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>5254.0</td>\n",
       "      <td>16827.0</td>\n",
       "      <td>61182.0</td>\n",
       "      <td>80221.0</td>\n",
       "      <td>66231.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Foundation Trilogy</td>\n",
       "      <td>Isaac Asimov</td>\n",
       "      <td>83933.0</td>\n",
       "      <td>1331.0</td>\n",
       "      <td>4.40</td>\n",
       "      <td>679.0</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "      <td>477.0</td>\n",
       "      <td>1521.0</td>\n",
       "      <td>9016.0</td>\n",
       "      <td>25447.0</td>\n",
       "      <td>47472.0</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title               author  \\\n",
       "0  The Book of Mormon: Another Testament of Jesus...            Anonymous   \n",
       "1                                         The Prince  Niccol√≤ Machiavelli   \n",
       "2                             The Foundation Trilogy         Isaac Asimov   \n",
       "\n",
       "   num_ratings  num_reviews  avg_rating  num_pages language  series  \\\n",
       "0      71355.0       5704.0        4.37      531.0  English       0   \n",
       "1     229715.0       7261.0        3.81      140.0  English       0   \n",
       "2      83933.0       1331.0        4.40      679.0  English       1   \n",
       "\n",
       "   1_rating_count  2_rating_count  3_rating_count  4_rating_count  \\\n",
       "0          7520.0          2697.0          2521.0          1963.0   \n",
       "1          5254.0         16827.0         61182.0         80221.0   \n",
       "2           477.0          1521.0          9016.0         25447.0   \n",
       "\n",
       "   5_rating_count  publish_year  publish_month  publish_day  fiction  \\\n",
       "0         56654.0        2013.0           10.0         22.0        0   \n",
       "1         66231.0        2003.0            6.0          1.0        0   \n",
       "2         47472.0        1974.0            1.0          1.0        1   \n",
       "\n",
       "   republish  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Load the dataset === #\n",
    "# This version was exported from the previous notebook\n",
    "# after doing some initial wrangling\n",
    "data_path = \"https://raw.githubusercontent.com/tobias-fyi/vela/master/ds/interview_prep/practice/print-fiction/assets/must_read_books-02.csv\"\n",
    "\n",
    "books = pd.read_csv(data_path, na_values=\"?\")\n",
    "print(books.shape)\n",
    "books.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "colab_type": "code",
    "id": "ynTpCxezIT5l",
    "outputId": "ed5090be-ec2a-438e-9d3f-d9b524086f12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                0\n",
       "author               0\n",
       "num_ratings          0\n",
       "num_reviews          0\n",
       "avg_rating           0\n",
       "num_pages          666\n",
       "language          1332\n",
       "series               0\n",
       "1_rating_count      83\n",
       "2_rating_count      83\n",
       "3_rating_count      83\n",
       "4_rating_count      83\n",
       "5_rating_count      83\n",
       "publish_year       282\n",
       "publish_month      282\n",
       "publish_day        282\n",
       "fiction              0\n",
       "republish            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Confirm null values were read in correctly === #\n",
    "books.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6YxTVzcUIT5s"
   },
   "source": [
    "---\n",
    "\n",
    "## Model validation\n",
    "\n",
    "* Split data into train, validation, and test sets\n",
    "* Choose an appropriate evaluation metric\n",
    "* Get a baseline accuracy (or precision/recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "KLQb9YurIT5u",
    "outputId": "bb38642f-6279-4971-ac5a-91a71502e44c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11740, 18), (2935, 18), (3669, 18))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Split data into train / val / test === #\n",
    "train, test = train_test_split(books, stratify=books[\"fiction\"], test_size=0.2, random_state=92)\n",
    "train, val = train_test_split(train, stratify=train[\"fiction\"], test_size=0.2, random_state=92)\n",
    "\n",
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "d80Z_YY-IT5y",
    "outputId": "f85f4b48-0679-49d9-8328-6ba49afe867f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11740,) (2935,) (3669,)\n",
      "(11740, 17) (2935, 17) (3669, 17)\n"
     ]
    }
   ],
   "source": [
    "# === Set up target and features === #\n",
    "target = \"fiction\"\n",
    "\n",
    "# Arrange y vector\n",
    "y_train = train[target]\n",
    "y_val = val[target]\n",
    "y_test = test[target]\n",
    "\n",
    "print(y_train.shape, y_val.shape, y_test.shape)\n",
    "\n",
    "# Arrange X matrices\n",
    "X_train = train.drop(columns=[target])\n",
    "X_val = val.drop(columns=[target])\n",
    "X_test = test.drop(columns=[target])\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "id": "ax4SYWEYIT52",
    "outputId": "d9e44b93-dc36-416e-c5b2-b63cd769c1e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    6145\n",
      "0    5595\n",
      "Name: fiction, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Target distribution === #\n",
    "print(y_train.value_counts())\n",
    "sns.distplot(y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Y1zfXpFIT5-"
   },
   "source": [
    "#### Majority class baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8-fMHHmbIT6A",
    "outputId": "4cf166ef-706e-43f1-ff68-f4045d554a11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5234241908006815"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Use mode as predictions === #\n",
    "maj = y_train.mode()[0]  # Mode is 1 (fiction)\n",
    "\n",
    "# Simply predict 1 for every training example\n",
    "y_pred_maj = [maj] * len(y_train)\n",
    "\n",
    "# Baseline accuracy\n",
    "accuracy_score(y_train, y_pred_maj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WJyObFatIT6F"
   },
   "source": [
    "#### Limited logistic baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-Jd35T12IT6H",
    "outputId": "f1eafe48-9822-4143-dd6f-4b01a6e11710"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11740, 3), (2935, 3), (3669, 3))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Use only a few features for this baseline === #\n",
    "base_features = [\n",
    "    \"num_reviews\",\n",
    "    \"avg_rating\",\n",
    "    \"num_pages\",\n",
    "]\n",
    "\n",
    "# Arrange X matrices\n",
    "X1_train = train[base_features]\n",
    "X1_val = val[base_features]\n",
    "X1_test = test[base_features]\n",
    "\n",
    "X1_train.shape, X1_val.shape, X1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "colab_type": "code",
    "id": "_MUpLWo5IT6L",
    "outputId": "98e2de7b-7acb-41de-c6da-d9888d0a38ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('imputer', SimpleImputer(strategy='median')),\n",
       "                ('logreg', LogisticRegression(random_state=92))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Baseline model === #\n",
    "pipe1 = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"logreg\", LogisticRegression(random_state=92)),\n",
    "])\n",
    "\n",
    "# Train base pipeline\n",
    "pipe1.fit(X1_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "JvLfVqdMIT6R",
    "outputId": "c7451b47-8043-449d-fba5-15fe998c187b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.6275979557069846\n"
     ]
    }
   ],
   "source": [
    "# === Made predictions to get validation accuracy === #\n",
    "y_pred1 = pipe1.predict(X1_val)\n",
    "\n",
    "# Compute accuracy\n",
    "print(\"Baseline accuracy:\", accuracy_score(y_val, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "oLxd7U0-IT6W",
    "outputId": "fdb1973a-a8b6-4e7b-c0d8-9304cd795baf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 821,  578],\n",
       "       [ 515, 1021]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Baseline confusion matrix === #\n",
    "confusion_matrix(y_val, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TP4_Zqm9IT6a"
   },
   "source": [
    "#### Default Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "QcqQAr_HIT6c",
    "outputId": "03aef88a-260e-43e4-cfb2-408deeb24294"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default random forest eval metrics:\n",
      "  Accuracy: 0.7342419080068143\n",
      "  F1 score: 0.7477360931435963\n"
     ]
    }
   ],
   "source": [
    "# === Default random forest model === #\n",
    "def_drop_columns = [\n",
    "    \"title\",\n",
    "    \"author\",\n",
    "    \"language\",\n",
    "]\n",
    "\n",
    "X2_train = X_train.drop(columns=def_drop_columns)\n",
    "X2_val = X_val.drop(columns=def_drop_columns)\n",
    "X2_test = X_test.drop(columns=def_drop_columns)\n",
    "\n",
    "rf1_pipe = Pipeline([\n",
    "    (\"encoder\", ce.OrdinalEncoder()),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"rfc\", RandomForestClassifier(random_state=92)),\n",
    "])\n",
    "\n",
    "# Train default random forest\n",
    "rf1_pipe.fit(X2_train, y_train)\n",
    "\n",
    "# Made predictions to get validation accuracy\n",
    "y_pred_rf1 = rf1_pipe.predict(X2_val)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(\"Default random forest eval metrics:\")\n",
    "print(\"  Accuracy:\", accuracy_score(y_val, y_pred_rf1))\n",
    "print(\"  F1 score:\", f1_score(y_val, y_pred_rf1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "zC0QPwcNIT6g",
    "outputId": "3380ef13-14bd-421e-ec56-8d4ec5456c05"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Evaluate default rf with confusion matrix === #\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "unique_labels(y_val)  # Create unique labels\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    labels = unique_labels(y_true)\n",
    "    columns = [f'Predicted {label}' for label in labels]\n",
    "    index = [f'Actual {label}' for label in labels]\n",
    "    table = pd.DataFrame(confusion_matrix(y_true, y_pred), \n",
    "                         columns=columns, index=index)\n",
    "    return sns.heatmap(table, annot=True, fmt='d', cmap='viridis')\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(y_val, y_pred_rf1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7uQ4SRFvIT6k"
   },
   "source": [
    "Alrighty then! With the (almost) full set of features and default hyperparameters the target can be predicted with ~73% accuracy. Although the target is not skewed very much, it is still skewed. Therefore, accuracy may not be the best way to evaluate the model. A better metric could be the F1 score. This is a little higher than the accuracy, clocking in at almost 75%.\n",
    "\n",
    "The F1 score is made up of the precision and recall. Actually, it can be interpreted of as the weighted average of precision and recall.\n",
    "\n",
    "This provides a better method of evaluating performance, because it takes into account false positives and false negatives. Accuracy only accounts for the model's correct predictions and mistakes, irrespective of _how_ the model made those mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "BQ-_O3VRIT6l",
    "outputId": "539d49f5-e6f2-45c4-f4c1-dfcd32656437"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7429305912596401\n"
     ]
    }
   ],
   "source": [
    "# === Calculate precision === #\n",
    "true_pos = 1156\n",
    "false_pos = 400\n",
    "precision = true_pos / (true_pos + false_pos)\n",
    "print(f\"Precision: {precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "xxBgEJ04IT6p",
    "outputId": "f284bdb4-2fd3-4cbe-99ba-dac7d0d4e0e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7526041666666666\n"
     ]
    }
   ],
   "source": [
    "# === Calculate recall === #\n",
    "true_pos = 1156\n",
    "false_neg = 380\n",
    "precision = true_pos / (true_pos + false_neg)\n",
    "print(f\"Precision: {precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "colab_type": "code",
    "id": "mRMKAvgsIT6t",
    "outputId": "258969da-b797-472d-c0f7-c75e73400397"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.71      0.72      1399\n",
      "           1       0.74      0.75      0.75      1536\n",
      "\n",
      "    accuracy                           0.73      2935\n",
      "   macro avg       0.73      0.73      0.73      2935\n",
      "weighted avg       0.73      0.73      0.73      2935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === Classification report === #\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_val, y_pred_rf1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EAKy3O32IT6w"
   },
   "source": [
    "Let's see what we can do to increase that score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qdxnY7AUIT6x"
   },
   "source": [
    "---\n",
    "\n",
    "## Iterate\n",
    "\n",
    "* [x] Engineer new features\n",
    "* [x] Feature pruning with permutation importance\n",
    "* [x] Use cross-validation (RandomizedSearchCV) to tune hyperparameters\n",
    "* [x] Try out different algorithms\n",
    "  * [x] KNearestClassifier\n",
    "  * [x] XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QHAQC5nIIT6z"
   },
   "source": [
    "### Feature Engineering\n",
    "\n",
    "When I initially started this project, I went through the process of validating and training a model or two that tried to predict the average rating of books. This was by far the most common target chosen by those who started Kaggle kernels using other GoodReads datasets. Although this may have the most obvious business value if I was a data scientist working for a book publisher, to me this wasn't a particularly interesting target to try to predict.\n",
    "\n",
    "I realized this when I hit a wall with my progress in improving the rating-predictor model. One reason was that I did not see any obvious useful features that could be engineered. However, once I found my way to the idea of predicting the fictionality of the books, the target drove the direction I took with my feature engineering. It was a great learning experience for me in engineering features toward the specific target that the model is trying to predict.\n",
    "\n",
    "Here are the feature ideas I came up with and engineered (all in short succession once the new target was chosen):\n",
    "\n",
    "- [x] Title begins with \"The\"\n",
    "- [x] Has subtitle: contains \":\"\n",
    "- [x] Title character count\n",
    "- [x] Title word count\n",
    "- [x] Title longest word\n",
    "- [x] Author number of names\n",
    "- [x] Author middle initial\n",
    "- [x] Ratings (stars) ratio (1 + 2 / 4 + 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7H71nRy8IT6z"
   },
   "outputs": [],
   "source": [
    "def engineer_features(data):\n",
    "    \"\"\"Engineer a handful of new features.\"\"\"\n",
    "    # Create new feature that is if the title begins with \"The\"\n",
    "    data[\"the_title\"] = data[\"title\"].str.startswith(\"The\")\n",
    "    # New feature - has_subtitle\n",
    "    data[\"has_subtitle\"] = data[\"title\"].str.contains(\":\")\n",
    "    # New feature - title character length\n",
    "    data[\"title_char_count\"] = data[\"title\"].apply(lambda x: len(x))\n",
    "    # New feature - title word count\n",
    "    data[\"title_word_count\"] = data[\"title\"].apply(lambda x: len(x.split()))\n",
    "    # New feature - title longest word\n",
    "    data[\"title_longest_word\"] = data[\"title\"].apply(lambda x: len(max(x.split(), key=len)))\n",
    "    # New feature - author number of names\n",
    "    data[\"author_name_count\"] = data[\"author\"].apply(lambda x: len(x.split()))\n",
    "    # New feature - author middle initial\n",
    "    pat = r\"\\w* (\\w. )+ \\w*\"\n",
    "    data[\"author_middle_initial\"] = data[\"author\"].str.contains(pat, regex=True)\n",
    "    # New feature - low/high rating ratio\n",
    "    data[\"rating_ratio\"] = (data[\"1_rating_count\"] + data[\"2_rating_count\"]) / (data[\"4_rating_count\"] + data[\"5_rating_count\"])\n",
    "    # Replace Boolean with binary\n",
    "    data = data.replace(to_replace={True: 1, False:0})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FMbgz_ncIT63"
   },
   "source": [
    "#### Same random forest with additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "7NetaoBmIT63",
    "outputId": "7eedd518-089b-4204-8928-bc5c498d0994"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tobias/.vega/vela-_qIiF1eP/lib/python3.7/site-packages/pandas/core/strings.py:1954: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default random forest eval metrics:\n",
      "  Accuracy: 0.7761499148211244\n",
      "  F1 score: 0.7884057971014492\n"
     ]
    }
   ],
   "source": [
    "# === Random forest model, new features === #\n",
    "X3_train = engineer_features(X_train)\n",
    "X3_val = engineer_features(X_val)\n",
    "X3_test = engineer_features(X_test)\n",
    "\n",
    "rf2_pipe = Pipeline([\n",
    "    (\"encoder\", ce.OrdinalEncoder()),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"rfc\", RandomForestClassifier(random_state=92)),\n",
    "])\n",
    "\n",
    "# Train default random forest\n",
    "rf2_pipe.fit(X3_train, y_train)\n",
    "\n",
    "# Made predictions to get validation accuracy\n",
    "y_pred_rf2 = rf2_pipe.predict(X3_val)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(\"Default random forest eval metrics:\")\n",
    "print(\"  Accuracy:\", accuracy_score(y_val, y_pred_rf2))\n",
    "print(\"  F1 score:\", f1_score(y_val, y_pred_rf2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ugp45Y9fIT67"
   },
   "source": [
    "Got an extra ~5% out of those new features!\n",
    "\n",
    "And that is with the default RandomForestClassifier hyperparameters and the SimpleImputer. For the next iteration, I will try using the IterativeImputer, then utilize RandomizedSearchCV to tune the hyperparameters and conduct cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UuMEKWgQ08rS"
   },
   "source": [
    "### Feature Importances\n",
    "\n",
    "It is likely that some of the features do not help the model make correct predictions. Indeed, some may even be worse than that: they could add noise that makes the model perform worse.\n",
    "\n",
    "To address this potential problem, I'm going to find the feature importances using a method called permutation importance. Basically, this method will go through each of the features, replacing their data with random noise generated from the distribution of the original data. The performance of the model will be evaluated and compared with the score using all of the original data to find the effect of each feature on the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-3jQF7VZ08rX"
   },
   "outputs": [],
   "source": [
    "# === Transformer pipeline === #\n",
    "# Use the same (fitted) steps from main pipeline\n",
    "transformers = Pipeline([\n",
    "    (\"encoder\", rf2_pipe.named_steps[\"encoder\"]),\n",
    "    (\"imputer\", rf2_pipe.named_steps[\"imputer\"]),\n",
    "])\n",
    "\n",
    "# Encode and impute\n",
    "X3_train_transformed = transformers.transform(X3_train)\n",
    "X3_val_transformed = transformers.transform(X3_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "colab_type": "code",
    "id": "ajoeqOPJ1U4L",
    "outputId": "28c524ee-ef0b-4e37-9045-cf64ab48d8b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PermutationImportance(estimator=RandomForestClassifier(random_state=92),\n",
       "                      random_state=42, scoring='f1')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Instantiate and fit the permuter === #\n",
    "permuter = PermutationImportance(\n",
    "    rf2_pipe.named_steps[\"rfc\"], \n",
    "    scoring='f1', \n",
    "    n_iter=5, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "permuter.fit(X3_val_transformed, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "colab_type": "code",
    "id": "sTccpQkRYaLW",
    "outputId": "d0f5587c-bb3c-4ae0-8b83-2f16242f3b29"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0307\n",
       "                \n",
       "                    &plusmn; 0.0021\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                has_subtitle\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 82.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0264\n",
       "                \n",
       "                    &plusmn; 0.0116\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                avg_rating\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.30%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0197\n",
       "                \n",
       "                    &plusmn; 0.0066\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                4_rating_count\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.52%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0193\n",
       "                \n",
       "                    &plusmn; 0.0031\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                publish_year\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 87.70%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0153\n",
       "                \n",
       "                    &plusmn; 0.0059\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                num_ratings\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.39%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0124\n",
       "                \n",
       "                    &plusmn; 0.0039\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                series\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.89%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0116\n",
       "                \n",
       "                    &plusmn; 0.0071\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                1_rating_count\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.10%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0096\n",
       "                \n",
       "                    &plusmn; 0.0048\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                num_pages\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.31%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0078\n",
       "                \n",
       "                    &plusmn; 0.0099\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                num_reviews\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.70%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0073\n",
       "                \n",
       "                    &plusmn; 0.0091\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                3_rating_count\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.43%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0062\n",
       "                \n",
       "                    &plusmn; 0.0075\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                title_char_count\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.60%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0060\n",
       "                \n",
       "                    &plusmn; 0.0043\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                5_rating_count\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0031\n",
       "                \n",
       "                    &plusmn; 0.0048\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                rating_ratio\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.44%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0016\n",
       "                \n",
       "                    &plusmn; 0.0024\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                language\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.48%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0008\n",
       "                \n",
       "                    &plusmn; 0.0059\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                the_title\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.59%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0007\n",
       "                \n",
       "                    &plusmn; 0.0056\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                2_rating_count\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.82%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0005\n",
       "                \n",
       "                    &plusmn; 0.0024\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                title_longest_word\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.03%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0004\n",
       "                \n",
       "                    &plusmn; 0.0025\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                republish\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.14%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0003\n",
       "                \n",
       "                    &plusmn; 0.0020\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                author_name_count\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.77%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0001\n",
       "                \n",
       "                    &plusmn; 0.0002\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                author_middle_initial\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 99.45%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0002\n",
       "                \n",
       "                    &plusmn; 0.0040\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                publish_month\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 98.76%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0006\n",
       "                \n",
       "                    &plusmn; 0.0041\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                author\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 98.52%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0007\n",
       "                \n",
       "                    &plusmn; 0.0030\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                title_word_count\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 98.47%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0008\n",
       "                \n",
       "                    &plusmn; 0.0009\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                title\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 96.31%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0027\n",
       "                \n",
       "                    &plusmn; 0.0030\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                publish_day\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Get permutation importances === #\n",
    "feature_names = X3_val.columns.tolist()\n",
    "pd.Series(permuter.feature_importances_, feature_names).sort_values(ascending=False)\n",
    "\n",
    "eli5.show_weights(\n",
    "    permuter, \n",
    "    top=None, # Show permutation importances for all features\n",
    "    feature_names=feature_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above table, I should see either no change or a small increase in the model's performance by removing `publish_month` and `author_middle_initial`. I'm going to try removing those and training the model again.\n",
    "\n",
    "As for the rest of the features, I find it interesting to see what features have the largest positive effect on the model's predictive power. From this table, I can see that the majority of the benefit I got from engineering the new features came from the `has_subtitle` feature. This feature, according to the permutation importance table, is the most important predictor by quite a long shot and accounted for 0.04 simply indicates whether the title of the book has a colon in it. My intuition was that having a subtitle is very common for nonfiction books, not so much for fiction.\n",
    "\n",
    "One other engineered feature that seems to be a good predictor is `title_char_count`, or title character count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default random forest eval metrics:\n",
      "  Accuracy: 0.7839863713798978\n",
      "  F1 score: 0.7965340179717587\n"
     ]
    }
   ],
   "source": [
    "# === Random forest model, new features === #\n",
    "more_drop_cols = [\n",
    "    \"author_middle_initial\",\n",
    "    \"publish_month\",\n",
    "]\n",
    "\n",
    "# New features are already engineered\n",
    "X4_train = X3_train.drop(columns=more_drop_cols)\n",
    "X4_val   = X3_val.drop(columns=more_drop_cols)\n",
    "X4_test  = X3_test.drop(columns=more_drop_cols)\n",
    "\n",
    "rf3_pipe = Pipeline([\n",
    "    (\"encoder\", ce.OrdinalEncoder()),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"rfc\", RandomForestClassifier(random_state=92)),\n",
    "])\n",
    "\n",
    "# Train default random forest\n",
    "rf3_pipe.fit(X4_train, y_train)\n",
    "\n",
    "# Made predictions to get validation accuracy\n",
    "y_pred_rf3 = rf3_pipe.predict(X4_val)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(\"Default random forest eval metrics:\")\n",
    "print(\"  Accuracy:\", accuracy_score(y_val, y_pred_rf3))\n",
    "print(\"  F1 score:\", f1_score(y_val, y_pred_rf3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that removing the features indicated to have negative or no feature importance actually had a small negative effect on the model's performance. That result in hand, I'm going to leave those features in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default random forest eval metrics:\n",
      "  Accuracy: 0.7647860452439357\n",
      "  F1 score: 0.7783200616491139\n"
     ]
    }
   ],
   "source": [
    "# === How does it perform on the test data? === #\n",
    "y_pred_test_rf2 = rf2_pipe.predict(X3_test)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(\"Default random forest eval metrics:\")\n",
    "print(\"  Accuracy:\", accuracy_score(y_test, y_pred_test_rf2))\n",
    "print(\"  F1 score:\", f1_score(y_test, y_pred_test_rf2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jDCfJc9CIT68"
   },
   "source": [
    "### Cross-validation + Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "z-kOYJMtIT68",
    "outputId": "40e6ca0b-0954-48b3-d28f-87b288762442"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tobias/.vega/vela-_qIiF1eP/lib/python3.7/site-packages/pandas/core/strings.py:1954: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# === Engineer the new features === #\n",
    "# Start from original dataset, because data\n",
    "# will only be split into train and test\n",
    "books2 = engineer_features(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "ZBSTSbgCIT7B",
    "outputId": "67743040-d120-4515-ef48-cef5915a9a62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18344, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>language</th>\n",
       "      <th>series</th>\n",
       "      <th>1_rating_count</th>\n",
       "      <th>2_rating_count</th>\n",
       "      <th>3_rating_count</th>\n",
       "      <th>4_rating_count</th>\n",
       "      <th>5_rating_count</th>\n",
       "      <th>publish_year</th>\n",
       "      <th>publish_month</th>\n",
       "      <th>publish_day</th>\n",
       "      <th>fiction</th>\n",
       "      <th>republish</th>\n",
       "      <th>the_title</th>\n",
       "      <th>has_subtitle</th>\n",
       "      <th>title_char_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>title_longest_word</th>\n",
       "      <th>author_name_count</th>\n",
       "      <th>author_middle_initial</th>\n",
       "      <th>rating_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Book of Mormon: Another Testament of Jesus...</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>71355.0</td>\n",
       "      <td>5704.0</td>\n",
       "      <td>4.37</td>\n",
       "      <td>531.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>7520.0</td>\n",
       "      <td>2697.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>56654.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.174301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Prince</td>\n",
       "      <td>Niccol√≤ Machiavelli</td>\n",
       "      <td>229715.0</td>\n",
       "      <td>7261.0</td>\n",
       "      <td>3.81</td>\n",
       "      <td>140.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>5254.0</td>\n",
       "      <td>16827.0</td>\n",
       "      <td>61182.0</td>\n",
       "      <td>80221.0</td>\n",
       "      <td>66231.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title               author  \\\n",
       "0  The Book of Mormon: Another Testament of Jesus...            Anonymous   \n",
       "1                                         The Prince  Niccol√≤ Machiavelli   \n",
       "\n",
       "   num_ratings  num_reviews  avg_rating  num_pages language  series  \\\n",
       "0      71355.0       5704.0        4.37      531.0  English       0   \n",
       "1     229715.0       7261.0        3.81      140.0  English       0   \n",
       "\n",
       "   1_rating_count  2_rating_count  3_rating_count  4_rating_count  \\\n",
       "0          7520.0          2697.0          2521.0          1963.0   \n",
       "1          5254.0         16827.0         61182.0         80221.0   \n",
       "\n",
       "   5_rating_count  publish_year  publish_month  publish_day  fiction  \\\n",
       "0         56654.0        2013.0           10.0         22.0        0   \n",
       "1         66231.0        2003.0            6.0          1.0        0   \n",
       "\n",
       "   republish  the_title  has_subtitle  title_char_count  title_word_count  \\\n",
       "0          1          1             1                53                 9   \n",
       "1          1          1             0                10                 2   \n",
       "\n",
       "   title_longest_word  author_name_count  author_middle_initial  rating_ratio  \n",
       "0                   9                  1                      0      0.174301  \n",
       "1                   6                  2                      0      0.150773  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Take a look === #\n",
    "print(books2.shape)\n",
    "books2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "sBErEAJ-IT7F",
    "outputId": "300deed8-2951-4c7a-a8b2-87519f083375"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14675, 26), (3669, 26))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Split data into train / test === #\n",
    "train, test = train_test_split(books2, stratify=books2[\"fiction\"], test_size=0.2, random_state=92)\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Id90Q2BwIT7M",
    "outputId": "c5112a16-4bc8-406e-cd06-1783d6b2f547"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14675,) (3669,)\n",
      "(14675, 20) (3669, 20)\n"
     ]
    }
   ],
   "source": [
    "# === Set up target and features === #\n",
    "# No val this time bc using cross-validation\n",
    "target = \"fiction\"\n",
    "\n",
    "drop_cols = [  # Columns not useful to model\n",
    "    \"title\",\n",
    "    \"author\",\n",
    "    \"language\",\n",
    "#     \"publish_month\",\n",
    "    \"publish_day\",\n",
    "    \"author_middle_initial\",\n",
    "]\n",
    "\n",
    "# Arrange y vector\n",
    "y_train = train[target]\n",
    "y_test = test[target]\n",
    "\n",
    "print(y_train.shape, y_test.shape)\n",
    "\n",
    "# Arrange X matrices\n",
    "X_train = train.drop(columns=[target] + drop_cols)\n",
    "X_test = test.drop(columns=[target] + drop_cols)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "cKyaHruHIT7P",
    "outputId": "99b35f01-6d49-4883-c5c5-338da999a464"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  25 | elapsed:   18.8s remaining:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:   20.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters {'imputer__imputation_order': 'random', 'imputer__initial_strategy': 'median', 'imputer__max_iter': 19, 'imputer__n_nearest_features': 4, 'imputer__tol': 0.02223640657375538, 'rfc__max_depth': 21, 'rfc__min_samples_split': 0.00799211859966853, 'rfc__n_estimators': 205}\n",
      "F1 score 0.7849781869334655\n"
     ]
    }
   ],
   "source": [
    "# === Random forest, Part 3 === #\n",
    "# Tune hyperparameters using cross-validation\n",
    "\n",
    "rf3_pipe = Pipeline([\n",
    "    (\"encoder\", ce.OrdinalEncoder()),\n",
    "    (\"imputer\", IterativeImputer(random_state=92)),\n",
    "    (\"rfc\", RandomForestClassifier(random_state=92)),\n",
    "])\n",
    "\n",
    "rf3_params = {\n",
    "    \"imputer__initial_strategy\": [\"median\", \"most_frequent\"], \n",
    "    \"imputer__max_iter\": randint(16, 40),\n",
    "    \"imputer__tol\": uniform(0.001, 0.05),\n",
    "    \"imputer__n_nearest_features\": randint(2, 10),\n",
    "    \"imputer__imputation_order\": [\"ascending\", \"roman\", \"random\"],\n",
    "    \"rfc__n_estimators\": randint(80, 300), \n",
    "    \"rfc__max_depth\": randint(6, 32),\n",
    "    \"rfc__min_samples_split\": uniform(0, 1), \n",
    "}\n",
    "\n",
    "# Define the search using parameter distros above\n",
    "rf3_search = RandomizedSearchCV(\n",
    "    rf3_pipe, \n",
    "    param_distributions=rf3_params, \n",
    "    n_iter=5,\n",
    "    cv=5, \n",
    "    scoring='f1',\n",
    "    verbose=10, \n",
    "    return_train_score=True, \n",
    "    n_jobs=-1,\n",
    "    random_state=92,\n",
    ")\n",
    "\n",
    "# Train default random forest\n",
    "rf3_search.fit(X_train, y_train)\n",
    "\n",
    "# Best combination of hyperparameters and their resulting f1 score\n",
    "print(\"Best hyperparameters\", rf3_search.best_params_)\n",
    "print(\"F1 score\", rf3_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1mdZBVeRIT7U"
   },
   "source": [
    "That score is actually not as good as the default random forest was, without cross-validation. It could also be that the best estimator from this search would outperform the previous one when predicting the test data. Or, it could be that the parameters and their ranges I'm searching are not optimal.\n",
    "\n",
    "Another reason could be that I simply did not provide enough of a search window. That is, I could try increasing the number of iterations that the search goes through while testing out parameter combinations.\n",
    "\n",
    "That score is still pretty close though. I'm going to try out some other algorithms now, starting with nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QRvblD9KIT7V"
   },
   "source": [
    "### Nearest Neighbors\n",
    "\n",
    "Nearest neighbors model with KNeighborsClassifier algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "cJ-rTHI9IT7V",
    "outputId": "5d8555f3-a0a8-4142-cc97-5ef763fc70f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  25 | elapsed:   15.7s remaining:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:   17.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters {'imputer__imputation_order': 'roman', 'imputer__initial_strategy': 'median', 'imputer__max_iter': 27, 'imputer__n_nearest_features': 7, 'imputer__tol': 0.015464012740496254, 'nn__algorithm': 'ball_tree', 'nn__leaf_size': 47, 'nn__n_neighbors': 19, 'nn__weights': 'uniform'}\n",
      "F1 score 0.697427625975729\n"
     ]
    }
   ],
   "source": [
    "# === Nearest Neighbors === #\n",
    "\n",
    "nn_pipe = Pipeline([\n",
    "    (\"encoder\", ce.OrdinalEncoder()),\n",
    "    (\"imputer\", IterativeImputer(random_state=92)),\n",
    "    (\"nn\", KNeighborsClassifier()),\n",
    "])\n",
    "\n",
    "nn_params = {\n",
    "    \"imputer__initial_strategy\": [\"median\", \"most_frequent\"], \n",
    "    \"imputer__max_iter\": randint(16, 40),\n",
    "    \"imputer__tol\": uniform(0.001, 0.05),\n",
    "    \"imputer__n_nearest_features\": randint(2, 10),\n",
    "    \"imputer__imputation_order\": [\"ascending\", \"roman\", \"random\"],\n",
    "    \"nn__n_neighbors\": randint(2, 20), \n",
    "    \"nn__weights\": [\"uniform\", \"distance\"],\n",
    "    \"nn__algorithm\": [\"ball_tree\", \"kd_tree\"],\n",
    "    \"nn__leaf_size\": randint(20, 50),\n",
    "}\n",
    "\n",
    "# Define the search using parameter distros above\n",
    "nn_search = RandomizedSearchCV(\n",
    "    nn_pipe, \n",
    "    param_distributions=nn_params, \n",
    "    n_iter=5,\n",
    "    cv=5, \n",
    "    scoring=\"f1\",\n",
    "    verbose=10, \n",
    "    return_train_score=True, \n",
    "    n_jobs=-1,\n",
    "    random_state=92,\n",
    ")\n",
    "\n",
    "# Train default random forest\n",
    "nn_search.fit(X_train, y_train)\n",
    "\n",
    "# Best combination of hyperparameters and their resulting f1 score\n",
    "print(\"Best hyperparameters\", nn_search.best_params_)\n",
    "print(\"F1 score\", nn_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QXBIGtq8IT7Y"
   },
   "source": [
    "It seems that Random Forest is quite a bit better of an algorithm for this problem than k-nearest neighbors. Therefore, I won't be moving forward with nearest neighbors.\n",
    "\n",
    "The last algorithm I'll try is a gradient-boosted decision tree classifier from XGBoost: `XGBClassifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5_kdsJbZKSND"
   },
   "source": [
    "### Gradient Boosting\n",
    "\n",
    "Training a gradient-boosted decision tree using [XGBoost](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn).\n",
    "\n",
    "Though I don't have a record of every single iteration of the below classifier search, the method I used to tune is to basically look at the values of each parameter, and moved the search range to more closely fit around those values.\n",
    "\n",
    "I was surprised to find that my initial attempts at training the `XGBClassifier` had about the same performance as the default random forest with the newly-engineered features.\n",
    "\n",
    "As I mentioned above, one hypothesis of what was causing the discrepancy (or lack thereof: I assumed gradient-boosting would increase the performance, which maybe wasn't a sound assumption), could be the simple fact that the randomized search doesn't cover every possibility. To test this, I increased the number of iterations and let 'er rip!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "colab_type": "code",
    "id": "K7HKTPfwIT7Z",
    "outputId": "df0c183f-6322-4db0-dac3-02479ed67588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   20.2s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   39.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  5.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score 0.7942245127829319\n",
      "Best hyperparameters:\n",
      "imputer__imputation_order: ascending\n",
      "imputer__initial_strategy: median\n",
      "imputer__max_iter: 31\n",
      "imputer__n_nearest_features: 3\n",
      "imputer__tol: 0.03492326452711587\n",
      "xgb__learning_rate: 0.10726406674881385\n",
      "xgb__max_depth: 27\n",
      "xgb__n_estimators: 100\n"
     ]
    }
   ],
   "source": [
    "# === XGBoost Classifier === #\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb1_pipe = Pipeline([\n",
    "    (\"encoder\", ce.OrdinalEncoder()),\n",
    "    (\"imputer\", IterativeImputer(random_state=92)),\n",
    "    (\"xgb\", XGBClassifier(random_state=92)),\n",
    "])\n",
    "\n",
    "xgb1_params = {\n",
    "    \"imputer__initial_strategy\": [\"median\", \"most_frequent\"], \n",
    "    \"imputer__max_iter\": randint(16, 45),\n",
    "    \"imputer__tol\": uniform(0.02, 0.04),\n",
    "    \"imputer__n_nearest_features\": randint(2, 10),\n",
    "    \"imputer__imputation_order\": [\"ascending\", \"roman\", \"random\"],\n",
    "    \"xgb__n_estimators\": randint(80, 160), \n",
    "    \"xgb__max_depth\": randint(18, 48),\n",
    "    \"xgb__learning_rate\": uniform(0.05, .5),\n",
    "}\n",
    "\n",
    "# Define the search using parameter distros above\n",
    "xgb1_search = RandomizedSearchCV(\n",
    "    xgb1_pipe, \n",
    "    param_distributions=xgb1_params, \n",
    "    n_iter=10,\n",
    "    cv=4,\n",
    "    scoring=\"f1\",\n",
    "    verbose=10, \n",
    "    return_train_score=True, \n",
    "    n_jobs=-1,\n",
    "    random_state=92,\n",
    ")\n",
    "\n",
    "# Train default random forest\n",
    "xgb1_search.fit(X_train, y_train)\n",
    "\n",
    "# Best combination of hyperparameters and their resulting f1 score\n",
    "print(\"F1 score\", xgb1_search.best_score_)\n",
    "print(\"Best hyperparameters:\")\n",
    "for param, val in xgb1_search.best_params_.items():\n",
    "    print(  f\"{param}: {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FecTx0zMVKGG"
   },
   "source": [
    "### More Random Forests\n",
    "\n",
    "Even with 40 total fits (4 cross-validation folds, 10 iterations) the gradient-boosted classifier did not really outperform the random forest by any significant margin. Given the additional complexity and computation required for an XGBoost model, I'm going to use the random forest classifier instead.\n",
    "\n",
    "To continue testing the hypothesis that my initial number of iterations was too low for the search to converge on a good combination of hyperparameters, I'm going to train more random forests. This time, I'm going to try running the random search with a higher number of iterations. If that seems promising, I'm going to further tune the hyperparameters and look into any additional hyperparameters that might be good to include in the tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "4IMFloUxIT7g",
    "outputId": "c1dd6928-fdf6-4c24-8baa-86455ecc27f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   24.7s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   30.7s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   38.6s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:   59.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score 0.7897015809090806\n",
      "Best hyperparameters:\n",
      "imputer__imputation_order: ascending\n",
      "imputer__initial_strategy: median\n",
      "imputer__max_iter: 12\n",
      "imputer__tol: 0.029121541514263292\n",
      "rfc__max_depth: 12\n",
      "rfc__min_impurity_decrease: 0.00010629484293753989\n",
      "rfc__min_samples_split: 11\n",
      "rfc__n_estimators: 195\n"
     ]
    }
   ],
   "source": [
    "# === Random forest, Part 4 === #\n",
    "rf4_pipe = Pipeline([\n",
    "    (\"encoder\", ce.OrdinalEncoder()),\n",
    "    (\"imputer\", IterativeImputer(random_state=92, n_nearest_features=3)),\n",
    "    (\"rfc\", RandomForestClassifier(random_state=92)),\n",
    "])\n",
    "\n",
    "rf4_params = {\n",
    "    \"imputer__initial_strategy\": [\"median\", \"most_frequent\"], \n",
    "    \"imputer__max_iter\": randint(8, 20),\n",
    "    \"imputer__tol\": uniform(0.01, 0.04),\n",
    "    \"imputer__imputation_order\": [\"ascending\", \"roman\", \"random\"],\n",
    "    \"rfc__n_estimators\": randint(140, 200), \n",
    "    \"rfc__max_depth\": randint(6, 18),\n",
    "    \"rfc__min_samples_split\": randint(6, 14), \n",
    "    \"rfc__min_impurity_decrease\": uniform(0, .01), \n",
    "}\n",
    "\n",
    "# Define the search using parameter distros above\n",
    "rf4_search = RandomizedSearchCV(\n",
    "    rf4_pipe, \n",
    "    param_distributions=rf4_params, \n",
    "    n_iter=15,\n",
    "    cv=5, \n",
    "    scoring='f1',\n",
    "    verbose=10,\n",
    "    return_train_score=True, \n",
    "    n_jobs=-1,\n",
    "    random_state=92,\n",
    ")\n",
    "\n",
    "# Train default random forest\n",
    "rf4_search.fit(X_train, y_train)\n",
    "\n",
    "# Best combination of hyperparameters and their resulting f1 score\n",
    "print('F1 score', rf4_search.best_score_)\n",
    "print('Best hyperparameters:')\n",
    "for param, val in rf4_search.best_params_.items():\n",
    "    print(  f\"{param}: {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest 4 eval metrics:\n",
      "  Accuracy: 0.7639683837557918\n",
      "  F1 score: 0.7825213460572576\n"
     ]
    }
   ],
   "source": [
    "# === How does it perform on the test data? === #\n",
    "y_pred_test_rf4 = rf4_search.predict(X_test)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(\"Random forest 4 eval metrics:\")\n",
    "print(\"  Accuracy:\", accuracy_score(y_test, y_pred_test_rf4))\n",
    "print(\"  F1 score:\", f1_score(y_test, y_pred_test_rf4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Get feature importances === #\n",
    "rf4 = rf4_search.best_estimator_[\"rfc\"]\n",
    "importances = pd.Series(rf4.feature_importances_, X_train.columns)\n",
    "\n",
    "# Plot feature importances\n",
    "n = 20\n",
    "plt.figure(figsize=(10,n/2))\n",
    "plt.title(f'Top {n} features')\n",
    "importances.sort_values()[-n:].plot.barh(color='grey');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RwBBzF7x1In2"
   },
   "source": [
    "---\n",
    "\n",
    "## Results and Interpretation\n",
    "\n",
    "I tried many different combinations of different hyperparameters and the best F1 score I was able to achieve was just north of .79. Even with all of my tuning, I never beat the F1 score that was achieved with the random forest classifier using default hyperparameters.\n",
    "\n",
    "One final step to be taken before deployment is to inspect the predictions that the model made on the test set, looking at the predicted probabilities that resulted in each of the predictions. By looking at the predicted probabilities, I can look at instances when the model was sure or unsure of its predictions, and if those predictions were correct or not.\n",
    "\n",
    "This can provide some insight into the reasons for the model being incorrect, which could be valuable information to have, particularly when attempting to interpret (the results of) the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Title and indexes to match with pred_proba === #\n",
    "title_id_train = X_train.reset_index()[[\"index\", \"title\"]]\n",
    "title_id_test = X_test.reset_index()[[\"index\", \"title\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indexes as an id field to match up on later\n",
    "train_id = X_train.reset_index()[\"index\"]\n",
    "test_id = X_test.reset_index()[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1042\n",
       "1    10779\n",
       "2    10072\n",
       "3    15540\n",
       "4    13007\n",
       "Name: index, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC for class 1:\n",
      "0.8461619555985452\n"
     ]
    }
   ],
   "source": [
    "# === ROC AUC + predicted probabilities === #\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Process the test data\n",
    "transformers_2 = Pipeline([\n",
    "    (\"encoder\", rf4_search.best_estimator_[\"encoder\"]),\n",
    "    (\"imputer\", rf4_search.best_estimator_[\"imputer\"]),\n",
    "])\n",
    "\n",
    "# Encode and impute\n",
    "X_test_transform = transformers_2.transform(X_test)\n",
    "class_index = 1\n",
    "\n",
    "# Make predictions with the trained gradient boosted classifier\n",
    "y_pred_proba_rf4 = rf4_search.predict_proba(X_test_transform)[:, class_index]\n",
    "\n",
    "# ROC AUC score ranges from 0-1; higher is better\n",
    "print(f'Test ROC AUC for class {class_index}:')\n",
    "print(roc_auc_score(y_test, y_pred_proba_rf4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>series</th>\n",
       "      <th>1_rating_count</th>\n",
       "      <th>2_rating_count</th>\n",
       "      <th>3_rating_count</th>\n",
       "      <th>4_rating_count</th>\n",
       "      <th>5_rating_count</th>\n",
       "      <th>publish_year</th>\n",
       "      <th>publish_month</th>\n",
       "      <th>republish</th>\n",
       "      <th>the_title</th>\n",
       "      <th>has_subtitle</th>\n",
       "      <th>title_char_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>title_longest_word</th>\n",
       "      <th>author_name_count</th>\n",
       "      <th>rating_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1042</td>\n",
       "      <td>112871.0</td>\n",
       "      <td>4674.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>317.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1593.0</td>\n",
       "      <td>5439.0</td>\n",
       "      <td>24255.0</td>\n",
       "      <td>41993.0</td>\n",
       "      <td>39591.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.086193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10779</td>\n",
       "      <td>364.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3.97</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.106061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10072</td>\n",
       "      <td>49.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.18</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15540</td>\n",
       "      <td>150.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.87</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.019608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13007</td>\n",
       "      <td>19322.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>4.09</td>\n",
       "      <td>268.0</td>\n",
       "      <td>1</td>\n",
       "      <td>285.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>3758.0</td>\n",
       "      <td>5984.0</td>\n",
       "      <td>8309.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.088925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  num_ratings  num_reviews  avg_rating  num_pages  series  \\\n",
       "0   1042     112871.0       4674.0        4.00      317.0       0   \n",
       "1  10779        364.0         47.0        3.97      431.0       0   \n",
       "2  10072         49.0         12.0        4.18      294.0       0   \n",
       "3  15540        150.0         14.0        3.87      200.0       1   \n",
       "4  13007      19322.0        213.0        4.09      268.0       1   \n",
       "\n",
       "   1_rating_count  2_rating_count  3_rating_count  4_rating_count  \\\n",
       "0          1593.0          5439.0         24255.0         41993.0   \n",
       "1            12.0            16.0            72.0           134.0   \n",
       "2             0.0             3.0            10.0            11.0   \n",
       "3             0.0             2.0            46.0            71.0   \n",
       "4           285.0           986.0          3758.0          5984.0   \n",
       "\n",
       "   5_rating_count  publish_year  publish_month  republish  the_title  \\\n",
       "0         39591.0        1997.0            9.0          1          0   \n",
       "1           130.0        2016.0            5.0          1          0   \n",
       "2            25.0        1994.0            6.0          0          0   \n",
       "3            31.0        1994.0            9.0          0          0   \n",
       "4          8309.0        1993.0            9.0          1          0   \n",
       "\n",
       "   has_subtitle  title_char_count  title_word_count  title_longest_word  \\\n",
       "0             0                29                 6                   7   \n",
       "1             0                18                 3                   8   \n",
       "2             0                16                 3                   8   \n",
       "3             0                16                 3                   6   \n",
       "4             1                40                 6                  11   \n",
       "\n",
       "   author_name_count  rating_ratio  \n",
       "0                  2      0.086193  \n",
       "1                  2      0.106061  \n",
       "2                  2      0.083333  \n",
       "3                  2      0.019608  \n",
       "4                  2      0.088925  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Reset index of test set to get column to match on === #\n",
    "X_test = X_test.reset_index()\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3669, 21), (3669,), (3669,), (3669,))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, test_id.shape, y_pred_proba_rf4.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>fiction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1042</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10779</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10072</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15540</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  fiction\n",
       "0   1042        1\n",
       "1  10779        0\n",
       "2  10072        0\n",
       "3  15540        1\n",
       "4  13007        1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.reset_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3669, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pred_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1042</td>\n",
       "      <td>0.911425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10779</td>\n",
       "      <td>0.511888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10072</td>\n",
       "      <td>0.192328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15540</td>\n",
       "      <td>0.552947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13007</td>\n",
       "      <td>0.550052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  pred_proba\n",
       "0   1042    0.911425\n",
       "1  10779    0.511888\n",
       "2  10072    0.192328\n",
       "3  15540    0.552947\n",
       "4  13007    0.550052"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Compare true / pred === #\n",
    "\n",
    "# Create new dataframe to compare the predictions to the actual\n",
    "df = pd.DataFrame({\n",
    "    'index': test_id,\n",
    "    'pred_proba': y_pred_proba_rf4,\n",
    "})\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3669, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pred_proba</th>\n",
       "      <th>fiction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1042</td>\n",
       "      <td>0.911425</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10779</td>\n",
       "      <td>0.511888</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10072</td>\n",
       "      <td>0.192328</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15540</td>\n",
       "      <td>0.552947</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13007</td>\n",
       "      <td>0.550052</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  pred_proba  fiction\n",
       "0   1042    0.911425        1\n",
       "1  10779    0.511888        0\n",
       "2  10072    0.192328        0\n",
       "3  15540    0.552947        1\n",
       "4  13007    0.550052        1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.merge(y_test.reset_index())\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3669, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pred_proba</th>\n",
       "      <th>fiction</th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>series</th>\n",
       "      <th>1_rating_count</th>\n",
       "      <th>2_rating_count</th>\n",
       "      <th>3_rating_count</th>\n",
       "      <th>4_rating_count</th>\n",
       "      <th>5_rating_count</th>\n",
       "      <th>publish_year</th>\n",
       "      <th>publish_month</th>\n",
       "      <th>republish</th>\n",
       "      <th>the_title</th>\n",
       "      <th>has_subtitle</th>\n",
       "      <th>title_char_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>title_longest_word</th>\n",
       "      <th>author_name_count</th>\n",
       "      <th>rating_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1042</td>\n",
       "      <td>0.911425</td>\n",
       "      <td>1</td>\n",
       "      <td>112871.0</td>\n",
       "      <td>4674.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>317.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1593.0</td>\n",
       "      <td>5439.0</td>\n",
       "      <td>24255.0</td>\n",
       "      <td>41993.0</td>\n",
       "      <td>39591.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.086193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10779</td>\n",
       "      <td>0.511888</td>\n",
       "      <td>0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3.97</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.106061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10072</td>\n",
       "      <td>0.192328</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.18</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15540</td>\n",
       "      <td>0.552947</td>\n",
       "      <td>1</td>\n",
       "      <td>150.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.87</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.019608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13007</td>\n",
       "      <td>0.550052</td>\n",
       "      <td>1</td>\n",
       "      <td>19322.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>4.09</td>\n",
       "      <td>268.0</td>\n",
       "      <td>1</td>\n",
       "      <td>285.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>3758.0</td>\n",
       "      <td>5984.0</td>\n",
       "      <td>8309.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.088925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  pred_proba  fiction  num_ratings  num_reviews  avg_rating  \\\n",
       "0   1042    0.911425        1     112871.0       4674.0        4.00   \n",
       "1  10779    0.511888        0        364.0         47.0        3.97   \n",
       "2  10072    0.192328        0         49.0         12.0        4.18   \n",
       "3  15540    0.552947        1        150.0         14.0        3.87   \n",
       "4  13007    0.550052        1      19322.0        213.0        4.09   \n",
       "\n",
       "   num_pages  series  1_rating_count  2_rating_count  3_rating_count  \\\n",
       "0      317.0       0          1593.0          5439.0         24255.0   \n",
       "1      431.0       0            12.0            16.0            72.0   \n",
       "2      294.0       0             0.0             3.0            10.0   \n",
       "3      200.0       1             0.0             2.0            46.0   \n",
       "4      268.0       1           285.0           986.0          3758.0   \n",
       "\n",
       "   4_rating_count  5_rating_count  publish_year  publish_month  republish  \\\n",
       "0         41993.0         39591.0        1997.0            9.0          1   \n",
       "1           134.0           130.0        2016.0            5.0          1   \n",
       "2            11.0            25.0        1994.0            6.0          0   \n",
       "3            71.0            31.0        1994.0            9.0          0   \n",
       "4          5984.0          8309.0        1993.0            9.0          1   \n",
       "\n",
       "   the_title  has_subtitle  title_char_count  title_word_count  \\\n",
       "0          0             0                29                 6   \n",
       "1          0             0                18                 3   \n",
       "2          0             0                16                 3   \n",
       "3          0             0                16                 3   \n",
       "4          0             1                40                 6   \n",
       "\n",
       "   title_longest_word  author_name_count  rating_ratio  \n",
       "0                   7                  2      0.086193  \n",
       "1                   8                  2      0.106061  \n",
       "2                   8                  2      0.083333  \n",
       "3                   6                  2      0.019608  \n",
       "4                  11                  2      0.088925  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Merge the rest of the features back in === #\n",
    "df = df.merge(\n",
    "     X_test,\n",
    "     how='left'\n",
    ")\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3625, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pred_proba</th>\n",
       "      <th>fiction</th>\n",
       "      <th>author</th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>language</th>\n",
       "      <th>short_stories</th>\n",
       "      <th>publish_year</th>\n",
       "      <th>1_rating_count</th>\n",
       "      <th>2_rating_count</th>\n",
       "      <th>3_rating_count</th>\n",
       "      <th>4_rating_count</th>\n",
       "      <th>5_rating_count</th>\n",
       "      <th>in_series</th>\n",
       "      <th>has_charlist</th>\n",
       "      <th>has_setting</th>\n",
       "      <th>char_x_setting</th>\n",
       "      <th>the_title</th>\n",
       "      <th>has_subtitle</th>\n",
       "      <th>title_char_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>author_name_count</th>\n",
       "      <th>rating_ratio_1_5</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7999</td>\n",
       "      <td>0.994971</td>\n",
       "      <td>1</td>\n",
       "      <td>John Connolly</td>\n",
       "      <td>4085.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>3.97</td>\n",
       "      <td>451.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>1304.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.083814</td>\n",
       "      <td>Bad Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16674</td>\n",
       "      <td>0.231404</td>\n",
       "      <td>0</td>\n",
       "      <td>Mila Gray</td>\n",
       "      <td>7054.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>4.19</td>\n",
       "      <td>373.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>2294.0</td>\n",
       "      <td>3291.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.067681</td>\n",
       "      <td>Come Back to Me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2684</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0</td>\n",
       "      <td>Gene Baur</td>\n",
       "      <td>1318.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>4.29</td>\n",
       "      <td>320.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>681.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.051960</td>\n",
       "      <td>Farm Sanctuary: Changing Hearts and Minds Abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11632</td>\n",
       "      <td>0.994077</td>\n",
       "      <td>1</td>\n",
       "      <td>J. Bernlef</td>\n",
       "      <td>7718.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>3.87</td>\n",
       "      <td>160.0</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>0</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>381.0</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>3534.0</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.089398</td>\n",
       "      <td>Hersenschimmen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12886</td>\n",
       "      <td>0.885394</td>\n",
       "      <td>0</td>\n",
       "      <td>Shannon Morton</td>\n",
       "      <td>264.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.59</td>\n",
       "      <td>226.0</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>Tempted by Evil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  pred_proba  fiction          author  num_ratings  num_reviews  \\\n",
       "0   7999    0.994971        1   John Connolly       4085.0        243.0   \n",
       "1  16674    0.231404        0       Mila Gray       7054.0        925.0   \n",
       "2   2684    0.000045        0       Gene Baur       1318.0        129.0   \n",
       "3  11632    0.994077        1      J. Bernlef       7718.0        305.0   \n",
       "4  12886    0.885394        0  Shannon Morton        264.0         30.0   \n",
       "\n",
       "   avg_rating  num_pages language  short_stories  publish_year  \\\n",
       "0        3.97      451.0  English              0        2005.0   \n",
       "1        4.19      373.0  English              0        2014.0   \n",
       "2        4.29      320.0  English              0        2008.0   \n",
       "3        3.87      160.0    Dutch              0        1985.0   \n",
       "4        3.59      226.0  English              0        2012.0   \n",
       "\n",
       "   1_rating_count  2_rating_count  3_rating_count  4_rating_count  \\\n",
       "0            61.0           186.0           891.0          1643.0   \n",
       "1           121.0           257.0          1091.0          2294.0   \n",
       "2            16.0            41.0           164.0           416.0   \n",
       "3           103.0           381.0          1820.0          3534.0   \n",
       "4            18.0            30.0            64.0            83.0   \n",
       "\n",
       "   5_rating_count  in_series  has_charlist  has_setting  char_x_setting  \\\n",
       "0          1304.0          0             1            1               1   \n",
       "1          3291.0          1             0            0               0   \n",
       "2           681.0          0             0            0               0   \n",
       "3          1880.0          0             1            1               1   \n",
       "4            69.0          1             0            0               0   \n",
       "\n",
       "   the_title  has_subtitle  title_char_count  title_word_count  \\\n",
       "0          0             0                 7                 2   \n",
       "1          0             0                15                 4   \n",
       "2          0             1                64                10   \n",
       "3          0             0                14                 1   \n",
       "4          0             0                15                 3   \n",
       "\n",
       "   author_name_count  rating_ratio_1_5  \\\n",
       "0                  2          0.083814   \n",
       "1                  2          0.067681   \n",
       "2                  2          0.051960   \n",
       "3                  2          0.089398   \n",
       "4                  2          0.315789   \n",
       "\n",
       "                                               title  \n",
       "0                                            Bad Men  \n",
       "1                                    Come Back to Me  \n",
       "2  Farm Sanctuary: Changing Hearts and Minds Abou...  \n",
       "3                                     Hersenschimmen  \n",
       "4                                    Tempted by Evil  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Merge the titles back in === #\n",
    "df = df.merge(\n",
    "     title_id_test,\n",
    "     how='left'\n",
    ")\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p8MrKRFRIT7o"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GujxCzg8IT7r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qCUPn-XuIT7w"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QGXwE6_OIT7z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cmVOAg53IT71"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "print_fiction_2-03_modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
