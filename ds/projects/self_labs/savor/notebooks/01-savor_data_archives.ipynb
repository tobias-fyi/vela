{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Savor Data\n",
    "\n",
    "> Taking advantage of my own big data.\n",
    "\n",
    "A data-driven project by [Tobias Reaper](https://github.com/tobias-fyi/)\n",
    "\n",
    "## Part 1: Archives\n",
    "\n",
    "Working with data from previous versions of the Savor data model.\n",
    "\n",
    "* Load data from archive CSVs\n",
    "* Transform, clean, and concatenate\n",
    "* Insert into local Postgres database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Savor is a project based on an idea that I first had in 2016. At the time I was working as a consultant for an enterprise resource planning (ERP) software company. I worked intimately with manufacturers to integrate our system into their business, with the goal of optimizing their manufacturing processes. I became fascinated by the idea of tracking things to such a degree, and began to imagine what it would be like to have a similar type of system that would optimize my life.\n",
    "\n",
    "I'm also very into journaling, and the two seemed like a great combination to me. Soon I came to the idea of having a real-time journal, where I can easily and quickly document my experiences, thoughts, interactions as they happen (or as close to as is realistic).\n",
    "\n",
    "This was before I started my journey into development and data science, so I didn't have the knowledge or skill to build the app myself...yet! I found a web app called Airtable that was perfect for my needs at the time, providing an intuitive interface to a set of relational databases in the cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === General imports === #\n",
    "from os import environ\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import janitor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Set up environment variables === #\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "env_path = Path.cwd().parents[0] / \".env\"\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# Get path to archive data\n",
    "archive_path = Path(environ.get(\"ARCHIVE_PATH\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Configuration === #\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%matplotlib inline\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Archived Data Wrangling and Concatenation\n",
    "\n",
    "I have four separate archived datasets, mainly due to the fact that Airtable's free tier supposedly only goes up to something like 1-2,000 records per base.\n",
    "\n",
    "Every time I started a new one, I changed the data model — sometimes a lot, sometimes a little. What that means for me now is I get to go back and figure out a way of combining them all into a single, consistent structure that will be compatible with my newest data model.\n",
    "\n",
    "The four archives cover the following time periods (and number of records):\n",
    "\n",
    "* `2018-01-28 - 2018-11-28 (1,209)`\n",
    "* `2018-10-09 - 2019-02-08 (1,454)`\n",
    "* `2019-02-08 - 2019-06-07 (2,866)`\n",
    "* `2019-06-01 - 2019-12-03 (8,406)`\n",
    "\n",
    "So in total, there are 13,935 records covering a period of ~22 months. However, I do believe there are a few holes in there where I did not track my time. I'll be exploring all of this while cleaning the data up enough to concatenate together into a single, consistent dataset.\n",
    "\n",
    "The important fields that I want in the final dataframe are:\n",
    "\n",
    "* time_in\n",
    "* time_out\n",
    "* duration (will be re-calculated based on timestamps)\n",
    "* activity (also called \"What\")\n",
    "* notes\n",
    "* tags (I'll be converting \"project\" and certain activities into tags, as that is how those items are tracked in the current model)\n",
    "\n",
    "Some (potentially more advanced) things to be done to this later on:\n",
    "\n",
    "* Extract names and places from notes to fill those columns where possible in archived data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "\n",
    "* [ ] Look for records where `time_in` > `time_out`\n",
    "* [ ] Look for records where `duration` is very large\n",
    "* [ ] Recalculate `duration` after concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. 2018-01-28 - 2018-11-28 (AKA the Beginning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1205, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_in</th>\n",
       "      <th>time_out</th>\n",
       "      <th>activity</th>\n",
       "      <th>tags</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-28 18:00:00</td>\n",
       "      <td>2018-01-28 19:08:00</td>\n",
       "      <td>DJ Practice</td>\n",
       "      <td>General Music</td>\n",
       "      <td>Kaliope Mix approx half done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-28 14:00:00</td>\n",
       "      <td>2018-01-28 15:00:00</td>\n",
       "      <td>Practice Instrument(s)</td>\n",
       "      <td>General Music</td>\n",
       "      <td>Acoustic Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-03 10:00:00</td>\n",
       "      <td>2018-02-03 13:00:00</td>\n",
       "      <td>Arrangement</td>\n",
       "      <td>Seigyn</td>\n",
       "      <td>Worked on Dark City VIP vocals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              time_in            time_out                activity  \\\n",
       "0 2018-01-28 18:00:00 2018-01-28 19:08:00             DJ Practice   \n",
       "1 2018-01-28 14:00:00 2018-01-28 15:00:00  Practice Instrument(s)   \n",
       "2 2018-02-03 10:00:00 2018-02-03 13:00:00             Arrangement   \n",
       "\n",
       "            tags                           notes  \n",
       "0  General Music    Kaliope Mix approx half done  \n",
       "1  General Music                 Acoustic Guitar  \n",
       "2         Seigyn  Worked on Dark City VIP vocals  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === 2018-01-28 - 2018-11-28 === #\n",
    "# This one starts at the very beginning!\n",
    "asset_path = archive_path / \"2018\" / \"2018_11_Activitybox.Archive.csv\"\n",
    "\n",
    "# Load into dataframe, use pyjanitor to clean column names\n",
    "df1_18_11 = (pd.read_csv(asset_path)\n",
    "             .clean_names()[[\"time_in\", \"time_out\", \"what\", \"project\", \"notes\"]]\n",
    "             .copy()\n",
    "             # Drop rows where null: duration, time_in/out\n",
    "             .dropna(axis=0, subset=[\"time_in\", \"time_out\"])\n",
    "             # Remaining nulls are in `notes` - fill with empty string\n",
    "             .fillna(value=\"\")\n",
    "             # Convert timestamps to datetime\n",
    "             .change_type(\"time_in\", \"datetime64[ns]\")\n",
    "             .change_type(\"time_out\", \"datetime64[ns]\")\n",
    "             .rename_columns({\"project\": \"tags\", \"what\": \"activity\"})\n",
    "            )\n",
    "\n",
    "print(df1_18_11.shape)\n",
    "df1_18_11.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time_in     0\n",
       "time_out    0\n",
       "activity    0\n",
       "tags        0\n",
       "notes       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at nulls\n",
    "df1_18_11.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_in</th>\n",
       "      <th>time_out</th>\n",
       "      <th>activity</th>\n",
       "      <th>tags</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2018-02-26 10:40:00</td>\n",
       "      <td>2018-02-26 11:30:00</td>\n",
       "      <td>Reading</td>\n",
       "      <td>Personal</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2018-03-01 20:15:00</td>\n",
       "      <td>2018-03-01 21:33:00</td>\n",
       "      <td>Exercise</td>\n",
       "      <td>Personal</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2018-03-08 19:00:00</td>\n",
       "      <td>2018-03-08 20:30:00</td>\n",
       "      <td>Arrangement</td>\n",
       "      <td>Seigyn</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2018-03-09 03:12:00</td>\n",
       "      <td>2018-03-09 11:13:00</td>\n",
       "      <td>Sleep</td>\n",
       "      <td>Personal</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2018-03-18 02:45:00</td>\n",
       "      <td>2018-03-18 03:17:00</td>\n",
       "      <td>Brush/Floss</td>\n",
       "      <td>Personal</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                time_in            time_out     activity      tags notes\n",
       "72  2018-02-26 10:40:00 2018-02-26 11:30:00      Reading  Personal      \n",
       "100 2018-03-01 20:15:00 2018-03-01 21:33:00     Exercise  Personal      \n",
       "118 2018-03-08 19:00:00 2018-03-08 20:30:00  Arrangement    Seigyn      \n",
       "120 2018-03-09 03:12:00 2018-03-09 11:13:00        Sleep  Personal      \n",
       "167 2018-03-18 02:45:00 2018-03-18 03:17:00  Brush/Floss  Personal      "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at some of the null notes - look fine to me\n",
    "df1_18_11[df1_18_11[\"notes\"] == \"\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time_in     datetime64[ns]\n",
       "time_out    datetime64[ns]\n",
       "activity            object\n",
       "tags                object\n",
       "notes               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_18_11.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Look for records where `time_in` > `time_out`\n",
    "# I know there's at least one (that could be fixed relatively easily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. 2018-10-09 - 2019-02-08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2018-10-09 - 2019-02-08 === #\n",
    "asset_path = archive_path / \"2019-02\" / \"2019-02-08_Journal_Complete.csv\"\n",
    "\n",
    "df1_19_02 = (pd.read_csv(asset_path, skiprows=1)\n",
    "             .clean_names()[[\"time_in\", \"time_out\", \"what\", \"project\", \"notes\"]]\n",
    "             .copy()\n",
    "             .dropna(axis=0, subset=[\"time_in\"])\n",
    "             # Convert timestamps to datetime\n",
    "             .change_type(\"time_in\", \"datetime64[ns]\")\n",
    "             .change_type(\"time_out\", \"datetime64[ns]\")\n",
    "             .rename_columns({\"project\": \"tags\", \"what\": \"activity\"})\n",
    "            )\n",
    "\n",
    "print(df1_19_02.shape)\n",
    "df1_19_02.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time_in       0\n",
       "time_out      8\n",
       "activity      0\n",
       "tags          0\n",
       "notes       378\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_19_02.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These nulls in `time_out` can be filled in using `time_in`\n",
    "df1_19_02[df1_19_02[\"time_out\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. 2019-02-08 - 2019-06-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2019-02-08 - 2019-06-07 === #\n",
    "asset_path = archive_path / \"2019-06\" / \"SassyJo-Journal-View.csv\"\n",
    "\n",
    "# Load journal into dataframe and take a look\n",
    "df_19_06 = (pd.read_csv(asset_path)\n",
    "            .clean_names()[[\"time_in\", \"time_out\", \"activity\", \"project_lookup\", \"notes\"]]\n",
    "            .copy()  # To prevent slice warning\n",
    "            # Convert timestamps to datetime\n",
    "            .change_type(\"time_in\", \"datetime64[ns]\")\n",
    "            .change_type(\"time_out\", \"datetime64[ns]\")\n",
    "            .rename_columns({\"project_lookup\": \"tags\"})\n",
    "           )\n",
    "\n",
    "print(df_19_06.shape)\n",
    "df_19_06.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time_in        0\n",
       "time_out       1\n",
       "activity       3\n",
       "tags           6\n",
       "notes       1863\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bummer about all those nulls\n",
    "df_19_06.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill null `notes` with empty string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. 2019-06-01 - 2019-12-03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8406, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_in</th>\n",
       "      <th>time_out</th>\n",
       "      <th>activity</th>\n",
       "      <th>tags</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-01 03:34:00</td>\n",
       "      <td>2019-06-01 10:30:00</td>\n",
       "      <td>Sleep</td>\n",
       "      <td>Health—Physical</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-01 10:30:00</td>\n",
       "      <td>2019-06-01 10:39:00</td>\n",
       "      <td>Resting</td>\n",
       "      <td>Health—Physical</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-01 10:39:00</td>\n",
       "      <td>2019-06-01 10:44:00</td>\n",
       "      <td>Social_Media</td>\n",
       "      <td>Community</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-01 10:44:00</td>\n",
       "      <td>2019-06-01 10:54:00</td>\n",
       "      <td>Shower</td>\n",
       "      <td>Health—Physical</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-01 10:54:00</td>\n",
       "      <td>2019-06-01 10:58:00</td>\n",
       "      <td>Dress</td>\n",
       "      <td>In_Between</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              time_in            time_out      activity             tags notes\n",
       "0 2019-06-01 03:34:00 2019-06-01 10:30:00         Sleep  Health—Physical   NaN\n",
       "1 2019-06-01 10:30:00 2019-06-01 10:39:00       Resting  Health—Physical   NaN\n",
       "2 2019-06-01 10:39:00 2019-06-01 10:44:00  Social_Media        Community   NaN\n",
       "3 2019-06-01 10:44:00 2019-06-01 10:54:00        Shower  Health—Physical   NaN\n",
       "4 2019-06-01 10:54:00 2019-06-01 10:58:00         Dress       In_Between   NaN"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === 2019-06-01 - 2019-12-03 === #\n",
    "# Last archived dataset\n",
    "asset_path = archive_path / \"2019-12\" / \"19-12-03-journal.csv\"\n",
    "\n",
    "# Load journal and take a look\n",
    "df1_19_12 = (pd.read_csv(asset_path)\n",
    "            .clean_names()[[\"time_in\", \"time_out\", \"activity\", \"project_lookup\", \"notes\"]]\n",
    "            .copy()  # To prevent slice warning\n",
    "            # Convert timestamps to datetime\n",
    "            .change_type(\"time_in\", \"datetime64[ns]\")\n",
    "            .change_type(\"time_out\", \"datetime64[ns]\")\n",
    "            .rename_columns({\"project_lookup\": \"tags\"})\n",
    "           )\n",
    "print(df1_19_12.shape)\n",
    "df1_19_12.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time_in     datetime64[ns]\n",
       "time_out    datetime64[ns]\n",
       "activity            object\n",
       "tags                object\n",
       "notes               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_19_12.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time_in       23\n",
       "time_out    6997\n",
       "activity      26\n",
       "tags          26\n",
       "notes       5078\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOTS of nulls to deal with here!\n",
    "df1_19_12.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('vela': pipenv)",
   "language": "python",
   "name": "python37664bitvelapipenvde09592071074af6a70ce3b1ce38af95"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
